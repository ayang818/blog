{"pages":[],"posts":[{"title":"[DevOps] 使用Azure pipeline + Github为你的应用构建CI/CD流水线","text":"2020/11 upd ：文章应该咕咕咕了，但是具体内容可以参照我的视频 DevOps系列篇 - 1. DevOps是什么？DevOps的主要流程？ DevOps系列篇 - 2. 使用Docker将一个最简Web应用容器化 微软官方devops教程 什么是 DevOps ？什么是 CI/CD 流水线？这个问题由于网上已经有很多很好的文章了，所以我这里就不再详细写了。大家可以自行参考。什么是DevOps？什么是 CI/CD 流水线？ 我归纳一下， DevOps是敏捷开发的一种主流实现方式，相比于传统的瀑布模型，DevOps为我们快速开发应用，快速发布应用，快速部署应用提供了一种方法论。 DevOps中大致有如下几个环节 Version Control （版本控制） Continuous Integration（持续集成） Continuous Delivery （持续交付） Continuout Deployment（持续部署） 如何为你的应用搭建完整的 CI/CD 流水线在这篇文章中，我们将使用 Git + Github + Docker + Azure pipeline 的组合来完成一个简单的 node 服务端应用的自动化流水线的搭建。 创建一个node应用 初始化项目 npm init 安装typescript npm install -g typescript 初始化为TypeScript应用 tsc --init 安装我们需要的 express 依赖 npm install express @types/express 编写一个最简单的Web应用 TODO","link":"/DevOps-使用Azure-pipeline为你的应用构建CI-CD流水线/"},{"title":"[DevOps] 如何写一个可快速构建镜像的Dockerfile脚本","text":"本文不针对刚接触Docker和DevOps的初学者，一些初级资料可以查阅——https://yeasy.gitbooks.io/docker_practice/introduction/what.html 在一个CI/CD工作流中，我们在本地修改代码并提交后，CI系统会自动构建我们的代码并运行单元测试来验证本次提交的可行性。而这个构建很多时候为了屏蔽平台以及环境的差异性，往往会使用Docker来构建。构建一个Docker image绕不开的话题就是Dockerfile脚本该怎么写。不同的项目事实上编写的Dockerfile遇到的痛点往往不一样。本文针对的痛点是——构建速度慢。针对这个问题，我们首先得了解一下Docker build中的cache机制。 Docker build中的cache机制我们知道在构建一个Docker image的时候，Dockerfile中每一条命令执行完后，都是会构造出一层新的layer附加到镜像上。但是这样的话，我的每个Docker image大小都差不多有500M左右，那么来个50个左右一款入门级服务器岂不是就存不下了？ 事实上在构建一个新的镜像或者拉取一个新的镜像的时候，由于我们是分层逐步构建，所以在构建每一层的时候，Docker都会检验这一层是否已经存在了？如果这一层已经存在了，那么他就会复用已经构建好或者拉取好的该层，也就不必花时间重复构建了，自然也不会重复占用内存。 但是这里有一个问题，Docker是如何判断一个即将被构建但是还没有被构建的镜像已经存在的呢？这个判断已经存在的标准是什么？ cache机制是如何实现的如果你熟悉Docker的话，Docker的镜像实际上是由镜像层文件系统内容和镜像Json文件组成，每一个Docker镜像都含有一个唯一的16进制12位的image id。这是下面的基础 假设我有这样一个Dockerfile From centos:7RUN yum update -yRUN echo \"echo 'hello world'\" &gt;&gt; /usr/share/starter.shRUN chmod u+x /usr/share/starter.shENTRYPOINT ['/user/share/starter.sh'] 对于这样一个Dockerfile来说。 假设以下内容为上述Dockerfile的第一次构建 有一个入口命令叫做 From，我们通常会引用一个父镜像来作为即将构建的镜像的基础环境。这个父镜像有一个唯一的image id和唯一对应的json文件。这个时候我们执行 docker build 命令时，Docker Daemon就会获取centos:7的镜像ID，并提取这个centos:7这个镜像json文件中的内容，作为新的镜像的基础json内容，并把该镜像作为构建 run yum update -y 该层的基础。 接着我们来到了 RUN yum update -y 这条命令，这条命令base在From命令之上，他会对文件系统的内容做一次更新，所有被更新的文件，都会保留在新构建的镜像层。并且在现有json的Cmd属性中更新一条 yum ipdate -y 命令。这样就完成了一条非From命令的构建。其实就是产生了一个新的镜像。新的镜像是上一条命令产生镜像的子镜像。centos:7就是第二条命令构建出镜像的父镜像。 所以有了这么一个想法——我们是否可以在构建 Dockerfile 一条命令之前，就知道即将构建出的新的镜像的形态呢？ 我们通过对第一次构建的分析，大致知道了，标志一个镜像有以下三个特点。 父镜像的ID。 父镜像向自己构建时，修改的Json文件内容，在上述例子中就是Cmd属性中增添了一条新的 yum update -y 命令。 镜像层文件系统的更新，对应上述例子就是运行 yum update -y 后文件系统的更新。 由于第三点是更新后的，在我们没有构建出镜像时无法比较。所以我们其实可以认为，在下一次执行上述Dockerfile的第二条命令前，假如 有一个镜像的父镜像为 centos:7。 有一个镜像的json文件相比父镜像也只在Cmd属性中添加了 yum update -y 命令。 那么我们就可以认为即将构造出的镜像已经存在，可以使用已经构造好了的缓存，无需重复构建了。 其实这么一波分析下来，我们已经大致知道了cache机制是这么工作的了：在执行命令构造一个镜像前，遍历本地所有镜像，若发现有镜像与即将构建出的镜像一致（这里的判定就是通过1，2两点判断的）时，将找到的镜像作为 cache 镜像，复用 cache 镜像作为构建结果。 这种树状的镜像关系决定了，如果我修改了第N次命令，那么所有&gt;N的命令都无法使用缓存，因为从第N个分支开始他们就不存在一棵已有的枝干上了。 但是其实如果仔细想还是有问题的。如果我有如下Dockerfile From centos:7RUN yum update -yCOPY starter.sh /user/share/starter.shENTRYPOINT ['/user/share/starter.sh'] starter.sh 是我在外部的一个文件，我的第三条命令没有变，但是 starter.sh 中的内容却变了，这个时候单单按照上面的分析，我们是可以继续使用构建好了的cache的。如果这样的话我们修改了starter.sh的内容，但是最后打包出来的镜像运行结果却不是我们修改后的预期，所以这是不合法的。 对于这些根据文件内容来决定表现结果的命令，Docker 采用的方式是对这些文件内容做一个checksum（校验和），如果所有校验和相同，则判断可以使用缓存。若是文件有变动，则不可以使用缓存。 RUN 命令存在外部依赖，对于第二个 yum update -y 命令来说，随着时间的推移，外部的软件源会越来越多，不同时间点执行的虽然都是相同命令，但是更新的文件数量却不一样。对于这种情况，我们可以使用参数 --no-cache 确保获取最新的外部依赖，命令为docker build --no-cache -t image_name 。 利用Docker build 中的cache机制来加速Docker image的构建 什么场景下需要加速Docker image的构建呢？ 举个生产环境中的例子： 我们有一个maven项目对应的Dockerfile（未使用cache机制） FROM maven:3-jdk-8-alpineCOPY ./ /appWORKDIR /appRUN mvn clean install# 解决时区错误问题RUN ln -snf /usr/share/zoneinfo/${TZ} /etc/localtime &amp;&amp; echo ${TZ} &gt; /etc/timezoneARG JAR_FILE=kugga-starter/target/*.jarCOPY ${JAR_FILE} app.jarENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"app.jar\"] 对于这样一个maven项目，我们在运行 mvn clean install 时，会先查看本地是否有依赖包，然后再查看远程仓库是否有依赖包，最后是查看中央仓库。在本地运行 mvn clean install 会非常快，因为要是本地没有，从远程下了之后，之后每一次执行都是从本地来导包，不需要长时间的网络I/O等待时间。但是在镜像中构建时，每一次构建镜像都是即开即用即弃的，这意味着每一次构建容器都需要花费大量时间在下载依赖包上。我的一些项目在不利用cache机制写Dockerfile前，构建一次镜像需要半个小时，这真的一点都不敏捷。 那么如何利用好Docker的缓存机制呢来解决这个每次构建都需要下载依赖包的问题呢？ 我们其实有 2 个原则 把需要变动频率高的文件才可以执行的命令往后放，这样不会让缓存机制失效。（这里其实特别像数据库中的事务操作准则，在一个事务中，执行时间长的操作需要尽可能放后，这样这条耗时长的操作影响的行持有行锁时间才会短） 利用变动频率少的文件，来做掉可以影响耗时的工作。让其可以利用缓存。 有了上述两个原则，我们分析一个maven项目，maven项目中变更较少的其实就是 pom.xml 文件，而耗时较长的下载依赖包其实也就是由 pom.xml 来决定的。 那么其实我们可以先把根目录下的 pom.xml 文件复制到一个新的文件夹中，假设是 /lib，如果是个多模块的maven项目，就在 /lib 下创建和子模块同名文件夹，然后将子模块的pom.xml 复制进去 ，最后在 /lib 下执行 mvn clean install。 这样的话。我们利用了改变较少的 pom.xml 就下载好了项目需要的所有依赖包到本地了。并且这个镜像是可以被缓存下来并再次利用的。 接下来我们再在项目路径下运行mvn clean install，这个时候由于依赖包已经在本地已经下载好了，所以漫长的网络I/O等待，就可以直接编译了。 我们修改后的 pom.xml 如下 FROM maven:3-jdk-8-alpine# 工作目录ENV HOME=/app# 用于构建缓存层的临时目录ENV LIB=/app/lib# 替换maven配置COPY mvn_setting.xml /usr/share/maven/conf/settings.xml# 构建镜像缓存依赖层RUN mkdir -p $LIB \\ &amp;&amp; mkdir -p $LIB/kugga-netty \\ &amp;&amp; mkdir -p $LIB/kugga-services \\ &amp;&amp; mkdir -p $LIB/kugga-starter \\ &amp;&amp; mkdir -p $LIB/kugga-utils# copy pom.xml和子模块的pom.xml 到 新的目录COPY pom.xml $LIB/pom.xmlCOPY kugga-netty/pom.xml $LIB/kugga-netty/pom.xmlCOPY kugga-services/pom.xml $LIB/kugga-services/pom.xmlCOPY kugga-starter/pom.xml $LIB/kugga-starter/pom.xmlCOPY kugga-utils/pom.xml $LIB/kugga-utils/pom.xmlWORKDIR $LIBRUN mvn clean install# --------------- 直到这里，只要pom.xml文件不变动，就可以一直使用缓存，无需重复构建 ----------------COPY /. $HOMEWORKDIR $HOMERUN mvn clean install# 解决时区错误问题ENV TZ=Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/${TZ} /etc/localtime &amp;&amp; echo ${TZ} &gt; /etc/timezoneARG JAR_FILE=kugga-starter/target/*.jarRUN cp ${HOME}/${JAR_FILE} ${HOME}/app.jarENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"/app/app.jar\"] 有了我们优化过后的 Dockerfile 文件，构建镜像的时间从半小时缩短到了两分钟。这才叫敏捷！类似于需要花大量时间在下载依赖包的项目其实都可以采用类似的解决方案，只要遵循上面的两点原则即可。","link":"/DevOps-如何写一个可快速构建镜像的Dockerfile脚本/"},{"title":"JQuery: 开箱即用的js库","text":"1.基本使用要使用首先要先引入CDN &lt;script src=\"https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js\"&gt;&lt;/script&gt; 使用超级简单，通常是这样的格式 $(\"\").action(function() {}) 即先选择，后监听事件，然后的形式 2.选择器选择器有三种 元素选择器 $(\"TagName\") id选择器 $(\"#id\") 类选择器 $(\".class\") 3.常见DOM(Document Object Model)事件 鼠标事件 键盘事件 表单事件 文档/窗口事件 click(点击) keypress(按键盘) submit load dbclick(双击) keydown change resize mouseenter(鼠标穿过元素) keyup focus(获得光标焦点) scroll mouseleave(鼠标离开元素) blur unload hover(光标悬停,两次操作) 4.JQuery效果 hide() 元素隐藏 show() 元素显示 toggle(fast/slow/1000, callback) 元素的隐藏和显示切换 fadeIn() 淡入 fadeOut() 淡出 fadeToggle() 淡入淡出切换 fadeTo(speed, opacity, callback) 渐变到不透明度 slideDown() 向下滑动 slideUp() 向上滑动 slideToggle() 上下滑动切换 5.JQuery捕获 text() 设置或返回所选元素的文本内容 html() 设置或返回所选元素的内容（包括 HTML 标记） val() 设置或返回表单字段的值 attr() 用于获取属性值。 6.JQuery添加元素 append() 在被选元素的结尾插入内容（仍然该元素的内部）。 prepend() 在被选元素的开头插入内容。 after() 被选元素之后插入内容 before() 在被选元素之前插入内容 var txt1=\"&lt;b&gt;Useful &lt;/b&gt;\"; // 使用 HTML 创建元素var txt2=$(\"&lt;i&gt;&lt;/i&gt;\").text(\"js-- \"); // 使用 jQuery 创建元素var txt3 = document.createElement(\"big\"); // 使用 DOM 创建元素txt3.innerHTML=\"jQuery!\";$(\"p\").after(txt1,txt2,txt3); // 在图片后添加文本 7.JQuery删除元素 remove() 删除被选元素及其子元素 empty() 删除被选元素的子元素 8.JQuery AJAX AJAX load(URL, data, callback) 从服务器加载数据，并把返回的数据放入被选元素中 $.get(URL, callback) 通过 HTTP GET 请求从服务器上请求数据 $.post(URL, data, callback) 通过 HTTP POST 请求向服务器提交数据","link":"/JQuery-开箱即用的js库/"},{"title":"Java中的锁优化(1)","text":"部分内容参考《深入理解Java虚拟机》第五部分——高效并发 锁优化高效并发是JDK1.5-JDK1.6的一个重要改进，HotSpot虚拟机团队在开发这个版本的时候花了大量的精力去实现各种锁优化技术，比如适应性自旋，锁消除，锁粗化，轻量级锁和偏向锁等，这些技术都是为了在线程之间更加高效的共享数据，以及解决竞争问题。这篇文章将以概念介绍为主。 自旋锁与自适应自旋我们知道往往在讨论锁的互斥同步的时候，其对性能最大的损耗就是阻塞的实现，挂起线程和回复线程都要进入操作系统内核态完成。然而其实有些阻塞只是很短的时间，没有必要挂起线程，所以这个时候可以选择让线程进入一个忙循环，知道阻塞条件结束，这就是所谓的自旋锁，关于自旋的代码可以参照我的这篇文章——Java原子性操作以及不如来手写一个简单锁，由于自旋是不断重试的过程，要是一直重试失败，就会造成CPU资源浪费，所以自旋需要设置次数；而所谓自适应自旋就是指根据前一次在同一个锁上的自旋时间，以及锁的拥有者的状态来判断自旋次数或是否自旋，这些在JDK1.6中都已经帮我们实现了。 锁消除锁消除指虚拟机既时编译器在运行时，会对被检测到不可能存在共享数据竞争的锁进行锁消除，例如下面一段代码 public class LockClean { public static void main(String[] args) { String s1 = \"1\"; String s2 = \"2\"; String s3 = \"3\"; String string = concatString(s1, s2, s3); System.out.println(string); } public static String concatString(String s1, String s2, String s3) { return s1 + s2 + s3; }} 这段代码看上去没有任何同步措施，但是我们知道，String是一个final类，是不可改变的，加的操作是通过StringBuilder或StringBuffer的append()来实现的，你可以看一下使用java反编译出来的结果。而StringBuffer其实是一个线程安全类，他的每个方法都有synchronized修饰。但是事实上所有的StringBuffer对象都只会在调用该方法的线程中，无法逃逸到其它线程，所以其实是不会有竞态条件的，这个锁就可以被安全的擦除掉，这就是锁消除。 锁粗化在阿里巴巴Java开发手册中有这样的话 高并发时，同步调用需要去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。 说明： 尽可能使加锁的代码块工作量尽量小，避免在锁代码块中调用RPC方法 就是说锁的粒度要尽可能小，但是并不需要为了锁的粒度小而频繁加锁。Java虚拟机会检测一些零碎的连续操作对同一个对象加锁的代码，见他们的锁合并，这就是锁粗化。","link":"/Java中的锁优化-1/"},{"title":"Java对象的发布与逸出&&线程封闭机制","text":"Java对象的发布与逸出发布一个对象的意思是指，是对象能够在当前作用域外的代码中使用。比如Unsafe包中没有暴露一个对外的构造器，它使用的是现在类内部创建一个对象的引用，然后return 回这个引用的方式。 private static final Unsafe theUnsafe = new Unsafe();@CallerSensitivepublic static Unsafe getUnsafe() { Class&lt;?&gt; caller = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(caller.getClassLoader())) throw new SecurityException(\"Unsafe\"); return theUnsafe;} 内部的可变状态逸出(不要这么做)但是其实发布一个对象的时候，在该对象的非私有域的引用的所有对象都会同样被发布，比如下面的代码 class UnsafeState { private String[] states = new String[] {\"11\",\"22\"}; public String[] getStates() {return states;}} 发布的String[]对象中引用的String也一起被发布了。这样就会出现问题，因为任何调用者都可以修改这个数组的内容。这样就会导致误用的风险。 隐式的this引用逸出下面代码展示了在使用构造器的时候，对象还没有发布，this就已经逸出了的栗子 public class ThisEscape { public ThisEscape() { source.registerListener( new EventListener() { public void onEvent(Event e){ // 这里引用了ThisEscape类的引用 dosomething(e) } } ) }} 避免this引用逸出使用工厂模式可以解决这个问题 public class SafeListener { private final EventListener listener; private SafeListener() { listener = new EventListener() { public void onEvent(Event e){ // 这里引用了ThisEscape类的引用 dosomething(e); } } } public static SafeListener ListenserFactory() { SafeListener safe = new SafeListener(); source.registerListener(safe.listener); return safe; }} 线程封闭Ad-hoc 线程封闭Ad-hoc线程封闭是指维护线程封闭性的职责完全由程序实现，其实这种封闭非常脆弱的。不管是volatile还是局部变量，其实都无法将某个属性封闭在某一个目标线程上。 栈封闭我把它理解为线程操作栈封闭，当多个线程访问一个方法时，线程会拷贝基本类型的局部变量，到县城自己的操作栈中，由于不会涉及到类中的全局变量，所以线程之间不会互相影响。(我不清楚是不是会引用非基本类型的局部变量，我对此打算找时间进一步探索一下) ThreadLocal类维持线程封闭性的更规范方法时使用ThreadLocal，这个类能使线程中的某个值与保存值的对象相关联，ThreadLock提供了get和set等访问接口，这些访问方法与每个使用该变量的线程都存有一份独立的副本，因此get方法得到的总是在当前线程调用set的最新值。下面的例子演示了通过把JDBC的连接保存到ThreadLocal对象中，每个创建的线程都会有自己的连接，这就起到了一个简单的连接池的作用 package ThreadClose;import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;import java.util.Properties;public class ThreadLocalTest { private static String DB_URL = \"&lt;你自己的数据库URL&gt;\"; private static String USERNAME = \"&lt;数据库用户名&gt;\"; private static String PASSWORD = \"&lt;数据库密码&gt;\"; private static Properties dataMap = new Properties(); // 使用ThreadLocal维持线程封闭性 private static ThreadLocal&lt;Connection&gt; connectHolder = new ThreadLocal&lt;&gt;() { // 重写initialValue，设置初始值 @Override public Connection initialValue() { try { dataMap.setProperty(\"user\", USERNAME); dataMap.setProperty(\"password\", PASSWORD); return DriverManager.getConnection(DB_URL, dataMap); } catch (SQLException e) { e.printStackTrace(); } return null; } }; public static Connection getConnection() { // get方法到这个线程的Value Connection connection = connectHolder.get(); return connection; }} 为了验证不同线程得到的Connection不同，我又写了如下代码 package ThreadClose;import java.sql.Connection;import java.sql.SQLException;public class ThreadLocalVerify { public static void main(String[] args) throws InterruptedException, SQLException { Connection connection = ThreadLocalTest.getConnection(); System.out.println(System.identityHashCode(connection)); Thread.sleep(2000); new Thread(() -&gt; { Connection connection1 = ThreadLocalTest.getConnection(); System.out.println(System.identityHashCode(connection1)); }).start(); }}","link":"/Java对象的发布与逸出/"},{"title":"Java原子性操作以及不如来手写一个简单锁","text":"从i++问题的引入在多线程编程中我们经常会看到这样一份代码 实现的计数器代码 public class Counter { volatile int i = 0; public void add() { i++; } public int getValue() { return this.i; }} 六个线程下的实现的+1 public class AyangCounterTest { public static void main(String[] args) throws InterruptedException{ Counter counter = new Counter(); for (int i = 0; i &lt; 6; i++) { new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { counter.add(); } } }).start(); } Thread.sleep(6000); System.out.println(counter.getValue()); }} 大家都知道这段代码的答案其实不是60000，打印出来的结果是不确定的，但是为什么呢？ 原子性操作我们可以看一下上面的代码的反编译出来的结果，来看看i++在多线程中到底发生了什么，运行 javap -p -v Counter.class 我们看到反编译出来的是这样的 public void add(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 8: 0 line 9: 10 其中i++被反编译成了四条机器指令 2: getfield5: iconst_16: iadd7: putfield &emsp;&emsp;我们先思考i变量在JVM内存中是怎么储存的，JVM分为共享的堆内存这里就存放着counter这个计数器对象，也就是说i这个类变量就在这个共享的堆内存中。&emsp;&emsp;而每个线程又有它们的线程工作内存，这个对于线程之间是私有的。我们接着继续看看这四条机器码getfield是先把i这个变量从公共堆内存中提到线程工作内存中的操作栈中，iconst_1就是往操作栈中压入一个1，接着iadd就是将栈中的两个值弹出并相加，最后putfield就是将相加后的值从线程工作空间放回公共堆内存，这就完成了一次一个线程中的i++。所以我们试想多个线程同时进行i++的时候，出现了这样的情况，举个栗子 i = 0线程A &gt; 提取到A线程的工作区内存 &gt; .... &gt; 放回堆内存 线程B &gt; 提取到B线程的工作区内存 &gt; ..... &gt; 放回堆内存 也就是说在一个线程获取i值但又没有来的及更新i值的时候，另一个线程又获取了i值，显然这个线程获取到的i值不是我们理想状况下的i值，这就导致了放回堆内存的时候导致重复而覆盖，这就是一个i++失效的一个过程。 也就是说我们在多线程的情况下并不能这么直接写i++，我们需要原子性操作来帮助我们达成目的。 原子性操作原子性操作的核心特征其实就是，把一次操作视为一个整体，而资源在这次操作中保持一致！而原子性操作很重要的一个知识点就是CAS CAS（Compare and Swap）顾名思义，CAS的意思就是比较加交换，这个属于硬件同步用语，处理器提供了基本内存操作的原子性保证。CAS操作需要输入两个值，期望操作的旧数据的值，以及一定操作后的值。在CAS操作期间，他会对输入旧值和旧值的原始引用内存地址的偏移量(OffSet)计算出的内存地址中的值进行对比，若没有发生变化，才会交换成新值。CAS返回一个布尔类型，若是交换失败，则进行自旋，重新进行一次CAS操纵，知道交换成功为止。对于以上的int操作，java提供了一个类sun.misc.Unsafe，其中就有conpareAndSwapInt()方法实现了CAS，但是这个类无法直接使用，你需要通过反射得到这个类的实例。 不如自己来实现一把锁其实许多锁的机制也就是通过CAS作为基础实现的我自己也写了一把简单的AyangLock锁QAQ，基于一个线程队列，加上原子性引用实现，代码如下 import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.LockSupport;/** * AyangLock */public class AyangLock implements Lock { AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); private LinkedBlockingQueue&lt;Thread&gt; waiter = new LinkedBlockingQueue&lt;&gt;(); @Override public boolean tryLock() { // if (owner.get() == null) { // owner = waiter. // } // return false; return owner.compareAndSet(null, Thread.currentThread()); } @Override public void lock() { if (!tryLock()) { waiter.offer(Thread.currentThread()); // 自旋 for (;;) { Thread head = waiter.peek(); if (head == Thread.currentThread()) { if (!tryLock()) { // 挂起线程 // wait / notify 需要配合synchronized在这里不可行 LockSupport.park(); } else { // 抢锁成功 waiter.poll(); return; } } else { // 线程挂起 LockSupport.park(); } } } } public boolean tryUnlock() { if (owner.get() != Thread.currentThread()) { throw new IllegalMonitorStateException(); } else { return owner.compareAndSet(Thread.currentThread(), null); } } @Override public void unlock() { if (tryUnlock()) { Thread th = waiter.peek(); if (th != null) { // unpark是唤醒线程 LockSupport.unpark(th); } } } @Override public void lockInterruptibly() throws InterruptedException { } @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return false; } @Override public Condition newCondition() { return null; }} 好了，现在试着将i++使用我的AyangLock加锁 import java.util.concurrent.locks.Lock;/** * Main */public class AyangCounterTest { public static void main(String[] args) throws InterruptedException{ Lock ayangLock = new AyangLock(); Counter counter = new Counter(); for (int i = 0; i &lt; 6; i++) { new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { ayangLock.lock(); counter.add(); ayangLock.unlock(); } } }).start(); } Thread.sleep(6000); System.out.println(counter.getValue()); }} 答案就是60000啦！","link":"/Java原子性操作以及简单的锁的实现-1/"},{"title":"Java中的对象锁(Monitor)","text":"Java中的对象锁说到对象锁，要与之对比就不得不讲到类锁。在写单例模式的时候其实经常会用在双重校验锁中用到类锁，如下面的代码 public ClassLock { priavte volatiled ClassLock classLock; private ClassLock() { // init } public ClassLock getInstance() { if (classLock == null) { synchronized (ClassLock.class) { if (classLock == null) { classLock = new ClassLock(); } } } return classLock; }} 可以看到在上面的代码中我们是对一整个类进行加锁，包括直接在方法签名上使用synchronized关键字，这都是属于类锁的范畴。因为在调用一个类的实例的时候，当运行其中一个加锁的方法时，其他加锁的方法是不可以执行的。也就是说一个类其实只有一个类锁，它锁住的对象是一个类。但是对象锁不一样，一个类中可以有多个对象，也就是说对象锁在一个类的实例中不止一个, 而每个对象都可以成为一个Monitor。对象锁往往用于多个线程之间的协作，与之配套的工具是synchronized，wait，notify，notifyAll。 各自作用 synchronized作用(这个其实已经说烂了，这里不多写) 多用于多线程间的同步加锁操作 wait()的作用和注意点 不同于Thread.currentThread.wait()的作用，这个wait()方法属于Object中的内容，同样notify，notifyAll也都是Object的内容。 wait()总是在一个可以跳出的循环中被调用，调用后它会一直挂起获取当前对象锁的线程，并释放对象锁。调用wait的线程也会被添加到对象的等待队列中。wait调用会一直持续到被同一个对象的notifyAll被调用唤醒或notify随机唤醒此线程。 wait()必须在synchronized同步块中使用，因为要使用对象的wait的方法，就必须先获得对象锁 notifyAll()与notify() notify就是随机选择对象等待队列中的某个线程，并将其添加到入口队列，处于入口队列中的线程就会竞争对象锁，获取对象锁的线程就会继续运行。 notifyAll()会添加所有等待队列中的线程到入口队列。相比来说notifyAll更加常用。 例子下面的例子来自LeetCode 1117. H2O 生成，题意可以点开来自己看题面，我使用Semaphore和对象锁都实现了一遍，然后模拟了整个过程——多个线程调用一个对象中的两个方法，一个方法打印H，一个方法打印O，两个方法中使用对象锁进行协调通信，达到输出HHO……的效果。代码如下 package Lock;public class ObjectLock { private static Runnable releaseO = () -&gt; { System.out.print(\"O\"); }; private static Runnable releaseH = () -&gt; { System.out.print(\"H\"); }; private static H2O h2O = new H2O(); private static String inputStr = \"OOHHHHOHH\"; public static void main(String[] args) { for (int i = 0; i &lt; inputStr.length(); i++) { if (\"O\".equals(Character.toString(inputStr.charAt(i)))) { new Thread(() -&gt; { try { h2O.oxygen(releaseO); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } else if (\"H\".equals(Character.toString(inputStr.charAt(i)))) { new Thread(() -&gt; { try { h2O.hydrogen(releaseH); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } } }}class H2O { private static final Object LOCK = new Object(); private int HCounter = 0; H2O() { } void hydrogen(Runnable releaseHydrogen) throws InterruptedException { synchronized(LOCK) { while(HCounter &gt;= 2) { LOCK.wait(); } releaseHydrogen.run(); this.HCounter++; LOCK.notifyAll(); } } void oxygen(Runnable releaseOxygen) throws InterruptedException { synchronized(LOCK) { while(HCounter &lt; 2) { LOCK.wait(); } releaseOxygen.run(); this.HCounter = 0; LOCK.notifyAll(); } }}","link":"/Java中的对象锁/"},{"title":"# SOME TIPS #","text":"计算机里有一句很著名的话，叫 “没有什么是增加一个层解决不了的，如果有，那就再抽一层”。今天想到了一个比较理论的解释，代码里随着业务的膨胀，接入的业务也来越多，不同系统间的交互也越来越多。","link":"/SOME-TIPS/"},{"title":"Vector和ArrayList的线程安全性&&浅析ArrayList源码","text":"一个例子出发下面的一个例子展示了ArrayList的非线程安全，以及ArrayList的错误检查机制 public class VectorSimpleTest { public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException {// Vector&lt;Integer&gt; list = new Vector&lt;&gt;(); ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 100; i++) { list.add(i); } new Thread(() -&gt; { while (!list.isEmpty()) { Integer index = list.size() - 1; Integer integer = list.get(index); System.out.println(\"Read\"+integer); System.out.println(list); } }).start(); new Thread(() -&gt; { while (!list.isEmpty()) { Integer index = list.size() - 1; System.out.println(\"Remove\"+list.get(index)); list.remove(index); } }).start(); Method checkForComodification = ArrayList.class.getDeclaredMethod(\"checkForComodification\"); checkForComodification.setAccessible(true); checkForComodification.invoke(list); }} 这段代码会报一个错误 ConcurrentModificationException ，就是说在修改这个实例的时候出现了意外，错误的原因很简单，就是多个线程在一个arrayList对象上工作没有同步。这个意外是由 ArrayList$Itr.checkForComodification 抛出的，这个方法的源码如下 final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException();} 可以关注modCount这个变量，这个变量继承于AbstractList中 protected transient int modCount = 0; 就名字来看，我们就可以知道，这个方法其实就是用来检查ArrayList更改次数的，就好像一个简单的版本管理工具，他那里有一个实例给你备份了正确的版本历史(Github远程仓库)，但是有一次你提交了一个错误的版本(本地版本push到远端)，arrayList发现了你提交的版本号和他那里记录的版本历史不一致，就会给你抛异常。我们通过查看这个方法的调用就可以知道 public E next()public void remove()public void forEachRemaining()public E previous()public void set()public void add() 以上的方法都会调用一次检查。解决的办法其实也很简单，只要把ArrayList换成Vector就可以了，Vector在这种场景下是可以维持好他本身的原子性的，因为vector内置的会让modCount++的方法都是加了synchronized关键字的。synchronized会对vector的Class加一把互斥锁来保证数据的同步。但是使用了Vector就一定可以保证数据同步吗？ 同步容器Vector的非线程安全因素public class SafeContainer {// private static ArrayList&lt;Integer&gt; vector = new ArrayList&lt;&gt;(); private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); private static SafeContainer safeContainer = new SafeContainer(); public static SafeContainer safeContainerFactory() { vector.add(1); vector.add(2); return safeContainer; } public Integer changeLast() { int lastIndex = vector.size() - 1; System.out.println(vector.get(lastIndex)); Integer remove = vector.remove(lastIndex); return remove; } public boolean isEmpty() { return vector.isEmpty(); } public Integer deleteLast() { int size = vector.size() - 1; System.out.println(vector.get(size)); Integer integer = vector.get(size); return integer; } public static void main(String[] args) { SafeContainer safeContainer = SafeContainer.safeContainerFactory(); new Thread(() -&gt; { while (!safeContainer.isEmpty()) { System.out.println(safeContainer.deleteLast()); } }).start(); new Thread(() -&gt; { while (!safeContainer.isEmpty()) { System.out.println(safeContainer.changeLast()); } }).start(); }} 以上的代码使用了工厂模式对Vector进行了封装，并封装了两个方法，看起来这个类使用了Vector也是线程安全的，但是运行起来却有概率报 ArrayIndexOutOfBoundsException ，其实是因为safeContainer在使用getLast获取最后一位值的时候，又调用了deleteLast，于是vector的size就又减了1，所以导致下标逸出。这其实就是因为synchronized的作用域仅限于vector对象，无法对SafeContainer类进行同步。这个机制就需要我们自行加锁，修改代码 public class SafeContainer {// private static ArrayList&lt;Integer&gt; vector = new ArrayList&lt;&gt;(); private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); private static SafeContainer safeContainer = new SafeContainer(); public static SafeContainer safeContainerFactory() { vector.add(1); vector.add(2); return safeContainer; } public synchronized Integer deleteLast() { int lastIndex = vector.size() - 1; System.out.println(vector.get(lastIndex)); Integer remove = vector.remove(lastIndex); return remove; } public synchronized boolean isEmpty() { return vector.isEmpty(); } public synchronized Integer getLast() { int size = vector.size() - 1; System.out.println(vector.get(size)); Integer integer = vector.get(size); return integer; } public synchronized static void main(String[] args) { SafeContainer safeContainer = SafeContainer.safeContainerFactory(); new Thread(() -&gt; { while (!safeContainer.isEmpty()) { System.out.println(safeContainer.getLast()); } }).start(); new Thread(() -&gt; { while (!safeContainer.isEmpty()) { System.out.println(safeContainer.deleteLast()); } }).start(); }} 这样无论是ArrayList还是Vector都可以在这段代码里正常同步运行了。","link":"/Vector和ArrayList的线程安全性/"},{"title":"Leetcode的几道有意思的多线程题","text":"前记最近一直在看Java的多线程编程,但苦于这东西有点过于偏向理论,结果今天上了Leetcode上看了下,发现居然有多线程相关的题目，(虽然只有五题),顺便放个链接吧，题目链接。题目感觉就是让你使用一些同步工具类或者锁或其他机制来完成要求，挺有意思的. 1114. 按序打印这个我的做法就是直接使用两个CountDownLatch, 根据运行顺序一层层解开不同的CountDownLatch, 代码如下 class Foo { private CountDownLatch latchSecond = new CountDownLatch(2); private CountDownLatch latchThird = new CountDownLatch(3); public Foo() { } public void first(Runnable printFirst) throws InterruptedException { // printFirst.run() outputs \"first\". Do not change or remove this line. printFirst.run(); latchSecond.countDown(); latchThird.countDown(); } public void second(Runnable printSecond) throws InterruptedException { latchSecond.countDown(); latchSecond.await(); // printSecond.run() outputs \"second\". Do not change or remove this line. printSecond.run(); latchThird.countDown(); } public void third(Runnable printThird) throws InterruptedException { latchThird.countDown(); latchThird.await(); // printThird.run() outputs \"third\". Do not change or remove this line. printThird.run(); }} 1115. 交替打印FooBar这题题意是让我们在多线程下轮流打印”foo”和”bar”两个字符串, 所以分析一下两个线程其实都只有一种运作方式,就是各自轮流打印”foo”或”bar”, 就好像红绿灯一样(没有黄灯), 这个时候我的想法一开始是继续用直接用一个volatile变量做是否标记, 这样还可以做到无锁. 但是不知道为啥Leetcode一直显示超时, emmm 所以后来我换了信号量Semaphore来解决, 代码如下 class FooBar { private int n; private final Semaphore semFoo = new Semaphore(1); private final Semaphore semBar = new Semaphore(0); private volatile boolean flag = true; public FooBar(int n) { this.n = n; } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i &lt; n; i++) { semFoo.acquire(); // printFoo.run() outputs \"foo\". Do not change or remove this line. printFoo.run(); semBar.release(); } } public void bar(Runnable printBar) throws InterruptedException { for (int i = 0; i &lt; n; i++) { semBar.acquire(); // printBar.run() outputs \"bar\". Do not change or remove this line. printBar.run(); semFoo.release(); } }} 1116. 打印零与奇偶数这道题和上道题超级类似, 只是中间多了个0, 这个就更像我们平时红绿灯的场景了, 0就像黄灯, 交替出现在红灯绿灯之间. 思路一样, 也是通过Semaphore解决, 代码如下 class ZeroEvenOdd { private int n; private Semaphore semZero = new Semaphore(1); private Semaphore semEven = new Semaphore(0); private Semaphore semOdd = new Semaphore(0); private int evenTimes; private int oddTimes; public ZeroEvenOdd(int n) { this.n = n; evenTimes = n/2; oddTimes = n%2 == 0 ? n/2 : n/2+1; } // printNumber.accept(x) outputs \"x\", where x is an integer. public void zero(IntConsumer printNumber) throws InterruptedException { for (int i = 1; i &lt;= n; i++) { semZero.acquire(); printNumber.accept(0); if (i%2 == 1) { semOdd.release(); } else { semEven.release(); } } } public void even(IntConsumer printNumber) throws InterruptedException { for(int i = 0, j = 2; i &lt; evenTimes; i++,j+=2) { semEven.acquire(); printNumber.accept(j); semZero.release(); } } public void odd(IntConsumer printNumber) throws InterruptedException { for (int i = 0,j = 1; i &lt; oddTimes; i++,j+=2) { semOdd.acquire(); printNumber.accept(j); semZero.release(); } }} 1195. 交替打印字符串题目的意思就是让我们接受一个数字，然后从1遍历到这个数字，看被三整除还是被五整除，还是被三被五都整除。然后按需输出，有多个线程对其进行读取，所以要保证输出顺序，思路也是使用Semaphore对其进行阻塞操作，代码如下(又臭又长)， class FizzBuzz { private int n; private volatile int start = 1; private Semaphore semFizzBuzz = new Semaphore(1); private Semaphore semFizz = new Semaphore(0); private Semaphore semBuzz = new Semaphore(0); private Semaphore semNone = new Semaphore(0); public FizzBuzz(int n) { this.n = n; } // printFizz.run() outputs \"fizz\". public void fizz(Runnable printFizz) throws InterruptedException { while(true) { semFizz.acquire(); if (start &gt; n) { semBuzz.release(); semNone.release(); semFizzBuzz.release(); break; } if (start%3 == 0) { printFizz.run(); start++; semFizzBuzz.release(); } else { semBuzz.release(); } } } // printBuzz.run() outputs \"buzz\". public void buzz(Runnable printBuzz) throws InterruptedException { while(true) { semBuzz.acquire(); if (start &gt; n) { semFizz.release(); semNone.release(); semFizzBuzz.release(); break; } if (start%5 == 0) { printBuzz.run(); start++; semFizzBuzz.release(); } else { semNone.release(); } } } // printFizzBuzz.run() outputs \"fizzbuzz\". public void fizzbuzz(Runnable printFizzBuzz) throws InterruptedException { while(true) { semFizzBuzz.acquire(); if (start &gt; n) { semFizz.release(); semBuzz.release(); semNone.release(); break; } if (start%3 == 0 &amp;&amp; start%5 == 0) { printFizzBuzz.run(); if (start == n) { start++; semFizz.release(); semBuzz.release(); semNone.release(); break; } start++; semFizzBuzz.release(); } else { semFizz.release(); } } } // printNumber.accept(x) outputs \"x\", where x is an integer. public void number(IntConsumer printNumber) throws InterruptedException { while(true) { semNone.acquire(); if (start &gt; n) { semFizz.release(); semBuzz.release(); semFizzBuzz.release(); break; } printNumber.accept(start); start++; semFizzBuzz.release(); } }} 还有刚刚想出来的一种思路是无锁结构，由于每个数字在四个线程中其实只会执行一次，所以只要使用volatile保证可见性即可，代码如下 class FizzBuzz { private int n; private volatile int index = 1; public FizzBuzz(int n) { this.n = n; } // printFizz.run() outputs \"fizz\". public void fizz(Runnable printFizz) throws InterruptedException { for (; index &lt;= n ; ) { if (index%3 == 0 &amp;&amp; index%5!=0 &amp;&amp; index &lt;= n) { printFizz.run(); index ++; } } } // printBuzz.run() outputs \"buzz\". public void buzz(Runnable printBuzz) throws InterruptedException { for (;index &lt;= n;) { if (index%5 == 0 &amp;&amp; index%3 != 0 &amp;&amp; index &lt;= n) { printBuzz.run(); index ++; } } } // printFizzBuzz.run() outputs \"fizzbuzz\". public void fizzbuzz(Runnable printFizzBuzz) throws InterruptedException { for (; index &lt;= n;) { if (index%5 == 0 &amp;&amp; index%3 == 0 &amp;&amp; index &lt;= n) { printFizzBuzz.run(); index ++; } } } // printNumber.accept(x) outputs \"x\", where x is an integer. public void number(IntConsumer printNumber) throws InterruptedException { for (;index &lt;= n; ) { if (index%5 != 0 &amp;&amp; index%3 != 0 &amp;&amp; index &lt;= n) { printNumber.accept(index); index ++; } } }} 1117. H2O 生成这道题目的难度居然是困难，但是感觉做起来挺简单的，用Semaphore或者ObjectMonitor都可以做，放两种代码 ObjectMonitor class H2O { private Object lock = new Object(); private volatile int hNum = 0; public H2O() { } public void hydrogen(Runnable releaseHydrogen) throws InterruptedException { synchronized(lock) { while (hNum &gt;= 2) { lock.wait(); } releaseHydrogen.run(); hNum ++; lock.notifyAll(); } // releaseHydrogen.run() outputs \"H\". Do not change or remove this line. } public void oxygen(Runnable releaseOxygen) throws InterruptedException { synchronized (lock) { while (hNum &lt; 2) { lock.wait(); } releaseOxygen.run(); hNum = 0; lock.notifyAll(); } // releaseOxygen.run() outputs \"H\". Do not change or remove this line. }} Semaphore class H2O { private Semaphore o = new Semaphore(0); private Semaphore h = new Semaphore(2); public H2O() { } public void hydrogen(Runnable releaseHydrogen) throws InterruptedException { h.acquire(1); // releaseHydrogen.run() outputs \"H\". Do not change or remove this line. releaseHydrogen.run(); o.release(1); } public void oxygen(Runnable releaseOxygen) throws InterruptedException { o.acquire(2); // releaseOxygen.run() outputs \"H\". Do not change or remove this line. releaseOxygen.run(); h.release(2); }}","link":"/Leetcode的几道有意思的多线程题/"},{"title":"Ayang818","text":"我是杨丰畅，常用网名 ayang818、chengyi0818，杭州电子科技大学在读，22 年毕业。高中半文科选手大学却读了计算机，ACM 夭折却仍热爱算法，喜欢画画却搞不定前端，对解决问题富有极大热情却经常解决不了。略熟悉 Java，写过 Python，Js，Kotlin。语言对我来说只是工具，我想用语言来解决一些有意思的问题。这也是我选择计算机的初衷。 联系方式 Email : chengyi0818@foxmail.com WeChat : yfc2000818 （添加好友请注明：姓名+来意+得知微信号的地方） 我的一些链接 Github : https://github.com/ayang818 LeetCode : https://leetcode-cn.com/u/ayang818/ BiliBili : https://space.bilibili.com/35953658","link":"/about/"},{"title":"csrf那些事","text":"","link":"/csrf那些事/"},{"title":"使用Jetpack的Architecture工具降低Android开发中的耦合度","text":"简单项目示例地址——https://github.com/ayang818/AndroidRookie写这篇文章并不是因为要转android了（从大一上的时候光速学了三天，糊弄了一下android课的作业后就再没写过了QAQ），而是最近看到一篇关于在android使用MVC，MVP，MVVM的架构方法的文章，感觉写的很好，就想来自己试一试android的几种解耦方法，触类旁通嘛~。此处也花了几个小时顺便快速学了一下android和其算是趋势的jetpack，故作此博客。 在编写Android代码的时候很容易在一个activity中就编写出耦合度特别高的代码，导致项目不利于维护。下面是几种常见的解决方案解决方案： 1. UIData与activity耦合 2. 使用ViewModel将Model和Activity解耦 3. 使用观察者模式（LiveData）主动刷新页面 4. 使用DataBinding进一步解决Controller和View之间的耦合 下面我们就会使用ViewModel，LiveData，DataBinding来实现页面的解耦。 使用ViewModel解除数据和界面之间的代码耦合 myViewModel = new ViewModelProvider(this).get(MyViewModel.class); ViewModel将UI中的数据抽离出来，统一维护。这样不会产生由于activity的摧毁（例如旋转屏幕）导致数据丢失的问题。 使用ViewModel + LiveData实现数据自动刷新代码示例public class ViewModelWithLifeData extends ViewModel { private MutableLiveData&lt;Integer&gt; likedNumber; public ViewModelWithLifeData() { likedNumber = new MutableLiveData&lt;&gt;(); likedNumber.setValue(0); } public void addLikedNumber(int num) { likedNumber.setValue(likedNumber.getValue() + num); } public MutableLiveData&lt;Integer&gt; getLikedNumber() { return likedNumber; }} @Overrideprotected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); textView = findViewById(R.id.textView); likeButton = findViewById(R.id.imageButton); dislikeButton = findViewById(R.id.imageButton2); viewModel = new ViewModelProvider(this).get(ViewModelWithLifeData.class); // 观察者模式，设定回调 viewModel.getLikedNumber().observe(this, (likedNumber) -&gt; { textView.setText(String.valueOf(likedNumber)); }); likeButton.setOnClickListener((v) -&gt; { viewModel.addLikedNumber(1); }); dislikeButton.setOnClickListener((v) -&gt; { viewModel.addLikedNumber(-1); });} 使用DataBinding来完全解耦Model-View-Controller首先在模块的build.gradle脚本的android.defaultConfig中加入，表示开启数据绑定模式 dataBinding { enabled true} 然后创建ViewModel public class ViewModelWithLifeData extends ViewModel { private MutableLiveData&lt;Integer&gt; likedNumber; public ViewModelWithLifeData() { likedNumber = new MutableLiveData&lt;&gt;(); likedNumber.setValue(0); } public void addLikedNumber(int num) { likedNumber.setValue(likedNumber.getValue() + num); } public MutableLiveData&lt;Integer&gt; getLikedNumber() { return likedNumber; }} 在activity中只需要编写Controller相关代码 public class MainActivity extends AppCompatActivity { ViewModelWithLifeData viewModel; ActivityMainBinding bd; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); viewModel = new ViewModelProvider(this).get(ViewModelWithLifeData.class); // 绑定activity和其对应的xml bd = DataBindingUtil.setContentView(this, R.layout.activity_main); // DataBinding绑定对应ViewModel bd.setData(viewModel); // 设置生命周期的拥有者, 设置数据的监听 bd.setLifecycleOwner(this); }} 然后将activity的xml修改成binding模式，主要区别在加入了一对layout标签和一 对data标签，接着就可以通过xml来解决少量的视图逻辑，此处类似于数据的回绑 &lt;data&gt; &lt;variable name=\"data\" type=\"com.ayang818.livedata.ViewModelWithLifeData\" /&gt;&lt;/data&gt;......&lt;TextView ... android:text=\"@{String.valueOf(data.likedNumber)}\" /&gt;&lt;ImageButton ... android:onClick=\"@{() -&gt; data.addLikedNumber(1)}\" /&gt; 这样我们用jetpack提供的architecture工具来完成M-V-C之间的解耦，项目也会更易于维护。","link":"/android-jetpack-architecture/"},{"title":"hive sql 调优","text":"hive 其实是用 sql 来开发的 mapreduce 任务，其中的一些有优化技巧和 sql 优化也有相同的地方 在经过一周的 sql boy 历练以后，写 sql 的水平也算是更上一层楼了 虽然说hive 跑的都是t-1的离线数据，不怎么需要在意运行时间，但是比较 yarn 集群资源有限，使用尽量少的资源来完成尽量多的工作也是很棒的！这里总结一下一些 hql 优化上的技巧 1. 所有分区表都需要指定分区查询 -- 反例select id, user_id from partition_table_name; -- 执行起来会很慢，因为需要扫描所有分区-- 正例select id,user_id from partition_table_name where date = '${date}' -- 只扫描制定的 date 分区 2. 不要偷懒使用 * 查全部数据字段，需要什么字段拿什么 对于一些大宽表来说，可能有七八十个字段，但是实际上只用到了其中两三个字段，造成了严重的资源浪费 -- 反例select su.star_id, au.user_id, au.device_idfrom star_user_profile as sujoin ( select * from aweme_user_profile -- aweme_user_profile 可能有上百个字段 where date = ${date} and user_id &gt; 0 ) as au on au.user_id = su.core_user_id; -- 正例 select su.star_id, au.user_id, au.device_idfrom star_user_profile as sujoin ( select user_id, device_id from aweme_user_profile where date = ${date} and user_id &gt; 0 ) as au on au.user_id = su.core_user_id; 3. 分区条件都放到表后，join 前 -- 反例select ui.id, ui.user_id, ui.device_id, di.device_brandfrom partition_user_profile_info as ui left join partition_device_info as dion di.device_id = ui.device_id and di.device_id &gt; 0where ui.date = '${date}' and di.date = '${date}'-- 正例select ui.id, ui.user_id, ui.device_id, di.device_brandfrom (select id, user_id, device_id from partition_user_profile_info where date = '${date}') as uileft join (select device_id, device_brand from partition_device_info where date = '${date}') as dion di.device_id = ui.device_id 4. join时，改表的条件紧跟当前表，不要join一堆表后都放到一个on里面 -- 反例select g.star_id, g.gender_distribution, a.age_distribution, p.province_distribution, c.city_distribution, d.device_brand_distribution, unix_timestamp() as update_timefrom p_gender_dist as gjoin p_age_dist as a join p_province_dist as p join p_city_dist as cjoin p_device_brand_dist as d on g.core_user_id = a.core_user_id and a.core_user_id = p.core_user_id and p.core_user_id = c.core_user_id and c.core_user_id = d.core_user_id -- 正例select g.star_id, g.gender_distribution, a.age_distribution, p.province_distribution, c.city_distribution, d.device_brand_distribution, unix_timestamp() as update_timefrom p_gender_dist as gjoin p_age_dist as a on g.core_user_id = a.core_user_idjoin p_province_dist as p on a.core_user_id = p.core_user_idjoin p_city_dist as c on p.core_user_id = c.core_user_idjoin p_device_brand_dist as d on c.core_user_id = d.core_user_id 5. hive 参数调优 啥都比不过官方文档系列~ 在碰到一些临时表特别大的场景下，可能会产生某个 任务 内存不够的场景，添加内存参数；对于一些任务oom之后，会不断重试失败，浪费很多时间 set spark.driver.memory = 80g;set spark.executor.memory = 80g;set spark.driver.maxResultSize=16g; -- default 1g yarn的资源分配 https://zhuanlan.zhihu.com/p/335881182 yarn -&gt; nodemanager -&gt; container set spark.vcore.boost.ratio = 1; 利用好重试机制 set spark.shuffle.io.maxRetries=1; set spark.shuffle.io.retryWait=0s; set spark.network.timeout=120s; 使用 external shuffle service 提高性能 set spark.shuffle.hdfs.enabled 6. sql 的严谨性 一条记录里经常会有各种空字段，记得对空字段进行处理 -- 反例concat(\":\", tmp.province, cast(tmp.cnt as string))-- 正例concat_ws(\":\", case when tmp.province is NULL or tmp.province=\"\" then \"unknown\" else tmp.province end, cast(tmp.cnt as string)) 做数据统计的时候，不要过分信任数据的准确性，需要自己做一层判断，例如 -- 反例(select author_id, item_id, user_id from aweme_user_item_info) as item_reach;-- 正例(select author_id, item_id, user_id from aweme_user_item_info where item_id &gt; 0) as item_reach -- 排除 item_id = 0 的脏数据 其他常用函数 获取group by 后每一组对该列的排位。使用场景举例：获取所有博主的最近 2 条微博 table: author_item_dict author_id weibo_id create_time 1 23489032 1615217421 1 12309780 1615217419 2 43242511 1615217418 1 45435346 1615217422 select author_id, weibo_idfrom ( select author_id, weibo_id, row_number over(partition by author_id order by create_time) as rn from author_item_dict ) as ai where ai.rn &gt;= 2 result: author_id weibo_id 1 12309780 1 23489032 2 43242511","link":"/hive-sql/"},{"title":"deepin20使用快捷键启用/禁用触控板","text":"背景 从windows切换到deepin，并将deepin作为日常主力系统 外出工作，没有外接键盘，需要使用笔记本电脑自带的软键盘 deepin20或者说linux的失去焦点策略为单击，比如在你打字输入的时候，只要点击一下输入框外面的部分，光标就会消失，失去焦点；而windows的失焦策略为双击，需要点击两下才会失去焦点。（两者在使用输入法时实测） 由于（3）的存在，只要打字时不小心碰到触摸板一下，就会失去焦点，并且丢失还在输入的内容，非常麻烦 deepin v20中只有在设置中关闭触控板的选项，并没有快捷键 解决方案 物理解决：随身自带一个外接键盘，这样就不会误触了。 编写shell，映射快捷键 创建一个内容如下的shell，命名为touchpad.sh，内容为 #!/bin/shenable=$(gsettings get com.deepin.dde.touchpad touchpad-enabled)if [ $enable = true ];then gsettings set com.deepin.dde.touchpad touchpad-enabled falsefiif [ $enable = false ];thengsettings set com.deepin.dde.touchpad touchpad-enabled true 将其移动到 /usr/bin/ 目录下，运行 mv touchpad.sh /user/bin 给这个脚本执行权限 sudo chmod 744 /usr/bin/touchpad.sh 设置 -&gt; 键盘与语言 -&gt; 快捷键 -&gt; 新建快捷键，在命令选项中选择 /usr/bin/touchpad.sh，快捷键自己设置。 这样就可以通过自己设置的快捷键一键切换触控板使用/禁用状态了，当你需要进行文字输入时，按下快捷键，禁用触控板。结束输入的时候，再按一次快捷键，使用触控板。","link":"/deepin-touchpad-fix/"},{"title":"浅析Java强大的动态Instrumention能力","text":"前言在前面的博客中，我写过一句话，叫做 Java世界里的一切东西都是在拼Java命令行参数 如果你使用IDEA，并且在运行 Java 代码时观察过 IDEA 帮我们拼出来的命令行参数，举个例子 D:\\jdk8\\jdk1.8.0_232\\bin\\java.exe &quot;\\&quot;-javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 201.4865.12\\lib\\idea_rt.jar=61840:C:\\Program Files\\JetBrains\\IntelliJ IDEA 201.4865.12\\bin\\&quot;&quot; -Dfile.encoding=UTF-8 -classpath ( 省略一系列依赖Jar包 ) C:\\Users\\25959\\Desktop\\test\\target\\classes com.ayang818.test.Test 这是我运行一个很简单的程序，IDEA 帮我们拼出来的命令行参数，其中 -Dfile.encoding 和 -classpath 我们都很熟悉，一个是指定编码方式，另一个是指定 classpath 路径。但是有一个我们可能很陌生的参数，叫做 -javaagent ， agent 翻译成中文是代理的意思。于是我开始了一天的探究过程。 过程首先我追踪了上面的代码中 -javaagent 后面的Jar包。 C:\\Program Files\\JetBrains\\IntelliJ IDEA 201.4865.12\\lib\\idea_rt.jar 这里申明一下，我使用的 IDEA 版本是 201.4865.12 EAP版本，属于内测版类型。如果有想自己探究一下的同学，发现代码不一样，可能是版本的问题。 首先解压这个Jar包 jar xvf idea_rt.jar 然后打开解压后的目录。目录结构如下 首先查看 MANIFEST.MF 文件下的内容（这里就开始涉及到Instrument的内容了），有一个字段如下。 Premain-Class: com.intellij.rt.execution.application.AppMainV2$Agent 这个字段叫做 Premain-Class ，我们知道在运行Java程序的时候，都会有一个 main 方法，这和我们的猜想相符合，我们的猜想就是 IDEA 在编译运行程序之前（pre）做了一些什么事情。我们顺着包名进到这个类读一读源码来一探究竟。 public static class Agent { public Agent() { } public static void premain(String args, Instrumentation i) { AppMainV2.premain(args); }} Agent 这个类是 AppMainV2 类下的一个静态内部类。它的 premain 方法调用了 AppMainV2 的 premain 方法。值得注意的是，Agent 的 premain方法中有一个 Instrumentation 类型的参数，这个待会再提。顺着源码找下去，找到 AppMainV2 的 premain 方法。 public static void premain(String args) { try { int p = args.indexOf(58); if (p &lt; 0) { throw new IllegalArgumentException(\"incorrect parameter: \" + args); } boolean helperLibLoaded = loadHelper(args.substring(p + 1)); int portNumber = Integer.parseInt(args.substring(0, p)); startMonitor(portNumber, helperLibLoaded); } catch (Throwable var4) { System.err.println(\"Launcher failed - \\\"Dump Threads\\\" and \\\"Exit\\\" actions are unavailable (\" + var4.getMessage() + ')'); }} 首先AppMainV2 的 premain 方法，对传入的参数做了一个分割，58转化为 char 类型是 : ，观察 IDEA 启动时通过 -javaagent 传入的参数 -javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 201.4865.12\\lib\\idea_rt.jar=61840:C:\\Program Files\\JetBrains\\IntelliJ IDEA 201.4865.12\\bin\\&quot;&quot; 可以知道 args.substring(p + 1) // C:\\Program Files\\JetBrains\\IntelliJ IDEA 201.4865.12\\bin\\\"\" 是 IDEA 的路径 args.substring(0, p) // 61840 是启动时的端口号。 private static boolean loadHelper(String binPath) { String osName = System.getProperty(\"os.name\").toLowerCase(Locale.ENGLISH); if (osName.startsWith(\"windows\")) { String arch = System.getProperty(\"os.arch\").toLowerCase(Locale.ENGLISH); File libFile = new File(binPath, arch.equals(\"amd64\") ? \"breakgen64.dll\" : \"breakgen.dll\"); if (libFile.isFile()) { System.load(libFile.getAbsolutePath()); return true; } } return false;} 查看 loadHelper 方法，可以看到这里是在加载 操作系统信息，以及通过处理器的位数来 load 不同的 .dll 文件 (C# 中类似 jar 包的东西)。 然后看到 startMonitor 方法 private static void startMonitor(final int portNumber, final boolean helperLibLoaded) { Thread t = new Thread(\"Monitor Ctrl-Break\") { public void run() { try { Socket client = new Socket(\"127.0.0.1\", portNumber); try { BufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream(), \"US-ASCII\")); try { while(true) { String msg = reader.readLine(); if (msg == null || \"TERM\".equals(msg)) { return; } if (\"BREAK\".equals(msg)) { if (helperLibLoaded) { AppMainV2.triggerControlBreak(); } } else if (\"STOP\".equals(msg)) { System.exit(1); } } } finally { reader.close(); } } finally { client.close(); } } catch (Exception var14) { } } }; t.setDaemon(true); t.start();} 这些代码都很简单，这段代码创建了一个守护进程，在这个进程中创建了一个 Socket 用来监听 Java 进程运行的端口，然后接受 Java 进程端口发出来的一些信息，比如程序输出，异常堆栈等等，然后输出到 IDEA 的命令行中，这也非常好理解。 这就是这段 IDEA 帮我们传入的 -javaagent 参数做的事情，它做的事情非常像 AOP（面向切面编程）。我们在写 Java 的时候通过动态代理来实现 AOP ，从而实现不在功能模块中添加代码，就可以对这个功能增加辅助功能的工作，比如 记录方法运行时间、输出日志等。-javaagent 也做到了这件事，它使用的是 Java 5中的 Instrumentation 机制。 Instrumentation 能力说实话，我没找到 Instrumentation 的准确翻译，我把它翻译作 插装 —— 在主程序前，插入一些新的能力。 前面说，Instrumentation 和 AOP 很想，这样的特性实际上提供了一种虚拟机级别支持的 AOP 实现方式，使得开发者无需对 JDK 做任何升级和改动，就可以实现某些 AOP 的功能了。 Instrumentation 的最大作用，就是类定义动态改变和操作。在 Java SE 5 及其后续版本当中，开发者可以在一个普通 Java 程序（带有 main 函数的 Java 类）运行时，通过 – javaagent参数指定一个特定的 jar 文件（包含 Instrumentation 代理）来启动 Instrumentation 的代理程序。 在 Java SE 5 当中，开发者可以让 Instrumentation 代理在 main 函数运行前执行。简要说来就是如下几个步骤： 编写 premain 函数 public static void premain(String agentArgs, Instrumentation inst); 在这个 premain 函数中，开发者可以进行对类的各种操作。 agentArgs 是 premain 函数得到的程序参数，随同 “– javaagent”一起传入。与 main 函数不同的是，这个参数是一个字符串而不是一个字符串数组，如果程序参数有多个，程序将自行解析这个字符串。 Inst 是一个 java.lang.instrument.Instrumentation 的实例，由 JVM 自动传入。java.lang.instrument.Instrumentation 是 instrument 包中定义的一个接口，也是这个包的核心部分，集中了其中几乎所有的功能方法，例如类定义的转换和操作等等。 打包 Jar 文件 将这个 Java 类打包成一个 jar 文件，并在其中的 manifest 属性当中加入” Premain-Class”来指定步骤 1 当中编写的那个带有 premain 的 Java 类。（可能还需要指定其他属性以开启更多功能），这和我们之前看 IDEA 里的代码目录结构是一样的。 运行 用如下方式运行带有 Instrumentation 的 Java 程序： java -javaagent:jar 文件的位置 [= 传入 premain 的参数 ] 对 Java 类文件的操作，可以理解为对一个 byte 数组的操作（将类文件的二进制字节流读入一个 byte 数组）。开发者可以在“ClassFileTransformer”的 transform 方法当中得到，操作并最终返回一个类的定义（一个 byte 数组）。这方面，Apache 的 BCEL 开源项目提供了强有力的支持，读者可以在参考文章 Java SE 5 特性 Instrumentation 实践 中看到一个 BCEL 和 Instrumentation 结合的例子。 具体关于替换字节码的操作，其实也不算难，但是这里就不是本文的重点了。 关于 Java 6 中一些新功能，比如虚拟机启动后的动态 Instrument （alibaba 著名的开源项目 arthas 很多功能，比如说热更新代码，虚拟机监控等等都是基于此开发），这篇文章就不再赘述。 参考文章 1. JAVA 拾遗 –Instrument 机制 2. Java SE 6 新特性Instrumentation 新功能 3. Alibaba-Arthas","link":"/java-instrument/"},{"title":"javascript中的浏览器操作","text":"学习JavaScript的初衷其实我是一个后端选手，但是缺了前端，后端性能再怎么好，总是无法具象化体现。而工作室里现在差不多感觉只有我一个在做Web开发，所以也不得不成为一位前后端全干代码狗啦😁。 浏览器对象1.windowwindow对象不但充当全部作用域，而且表示浏览器窗口。window对象有innerHeight对象和innerHeight，可以获取浏览器的内部宽度和高度 2.navigatornavigator对象对象表示浏览器的信息，最常用的属性包括 navigator.appName 浏览器名称 navigator.appVersion 浏览器版本 navigator.language 浏览器语言 navigator.platform 浏览器系统类型 navigator.userAgent 浏览器设置的User-Agent字串 下面代码是使用短路运算符得到网页宽度的方法 var width = window.innerWidth || document.body.clientWidth; 3.screenscreen对象表示屏幕的信息，常用的属性有 screen.width 屏幕宽度 screen.height 屏幕高度，px为单位 screen.colorDepth 返回颜色位数 4.location location对象表示当前页面的URl信息 location.href 获取当前url location.protocol location.host location.port location.pathname location.search location.hash location.reload() 刷新页面 location.assign(“url”) 重定向到一个网页 5.docementdocument对象表示当前页面。由于HTML在浏览器中以DOM形式表示为树形结构，document对象就是整个DOM树的根节点。 // 修改标题document.title = '快回来嗷!'; 常用方法 document.getElementById() document.getElementByTagName() document.cookie 获取当前页面的cookie 为了解决这个问题cookie信息泄露问题，服务器在设置Cookie时可以使用httpOnly，设定了httpOnly的Cookie将不能被JavaScript读取。这个行为由浏览器实现，主流浏览器均支持httpOnly选项，IE从IE6 SP1开始支持。为了确保安全，服务器端在设置Cookie时，应该始终坚持使用httpOnly。 操作DOM1.更新DOM 直接修改innerHTML的属性 修改innerText或textContent属性，不会修改DOM树结构 2.插入DOM 如果这个DOM节点是空的，例如，&lt;div&gt;，那么，直接使用innerHTML = &lt;span&gt;child‘就可以修改DOM节点的内容，相当于“插入”了新的DOM节点。 如果这个DOM节点不是空的，那就不能这么做，因为innerHTML会直接替换掉原来的所有子节点。 使用appendChild，把一个子节点添加到父节点的最后一个子节点。 &lt;p id=\"js\"&gt;JavaScript&lt;/p&gt;&lt;div id=\"list\"&gt;&lt;p id=\"java\"&gt;Java&lt;/p&gt;&lt;p id=\"python\"&gt;Python&lt;/p&gt;&lt;p id=\"scheme\"&gt;Scheme&lt;/p&gt;&lt;/div&gt; 使用如下js代码 var js = document.getElementById(\"js\");var list = document.getElementById(\"list\");list.appendChild(js); 创建一个节点并appendvar list = document.getElementById(\"list\");var node = document.createElement(\"p\");node.innerText = \"Scala\";node.id = \"scala\";list.appendChild(node); 下面代码实现了创建一个style节点，并把它添加到```jsvar d = document.createElement(&apos;style&apos;);d.setAttribute(&apos;type&apos;, &apos;text/css&apos;);d.innerHTML = &apos;p { color: red }&apos;;document.getElementsByTagName(&apos;head&apos;)[0].appendChild(d); 插入到指定位置 var py = document.getElementById(\"python\");var list = document.getElementById(\"list\");var scala = document.createElement(\"p\");scala.id = \"scala\";scala.innerHtml = \"Scala\";list.insertBefore(scala, py); Demo对于一个已有的HTML结构 &lt;!-- HTML结构 --&gt;&lt;ol id=\"test-list\"&gt; &lt;li class=\"lang\"&gt;Scheme&lt;/li&gt; &lt;li class=\"lang\"&gt;JavaScript&lt;/li&gt; &lt;li class=\"lang\"&gt;Python&lt;/li&gt; &lt;li class=\"lang\"&gt;Ruby&lt;/li&gt; &lt;li class=\"lang\"&gt;Haskell&lt;/li&gt;&lt;/ol&gt; 需要将其中的li按照顺序排好代码如下 var ol = document.getElementById(\"test-list\");var list = ol.getElementsByTagName(\"li\");var node_list = [];for(let item of list){ node_list.push(item.innerText);}node_list.sort();index = 0;for(let item of list){ item.innerText = node_list[index]; index++;} 3.删除DOM 删除一个DOM节点就比插入要容易得多。要删除一个节点，首先要获得该节点本身以及它的父节点，然后，调用父节点的removeChild把自己删掉。// 拿到待删除节点:var self = document.getElementById('to-be-removed');// 拿到父节点:var parent = self.parentElement;// 删除:var removed = parent.removeChild(self);removed === self; // true 操作表单 文本框，对应的&lt;input type=”text”&gt;，用于输入文本； 口令框，对应的&lt;input type=”password”&gt;，用于输入口令； 单选框，对应的&lt;input type=”radio”&gt;，用于选择一项； 复选框，对应的&lt;input type=”checkbox”&gt;，用于选择多项； 下拉框，对应的&lt;select&gt;，用于选择一项； 隐藏文本，对应的&lt;input type=”hidden”&gt;，用户不可见，但表单提交时会把隐藏文本发送到服务器。 1.获取值// &lt;input type=\"text\" id=\"email\"&gt;var input = document.getElementById('email');input.value; // '用户输入的值' 这种方式可以应用于text、password、hidden以及select。对于radio， checkbox来说，value返回的永远是实现设定好的值，所以需要使用 // &lt;label&gt;&lt;input type=\"radio\" name=\"weekday\" id=\"monday\" value=\"1\"&gt; Monday&lt;/label&gt;// &lt;label&gt;&lt;input type=\"radio\" name=\"weekday\" id=\"tuesday\" value=\"2\"&gt; Tuesday&lt;/label&gt;var mon = document.getElementById(\"monday\");var tues = document.getElementById(\"tuesday\");mon.checked // true or flase 2.设置值这个和获取值类似 // &lt;input type=\"text\" id=\"email\"&gt;var input = document.getElementById('email');input.value = \"ayang818@qq.com\"; // '用户输入的值' 提交表单1.通过&lt;form&gt;元素的submit()方法提交一个表单，例如，响应一个&lt;button&gt;的click事件，在JavaScript代码中提交表单&lt;form id=\"test-form\"&gt; &lt;input type=\"text\" name=\"test\"&gt; &lt;button type=\"button\" onclick=\"doSubmitForm()\"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function doSubmitForm() { var form = document.getElementById('test-form'); // 可以在此修改form的input... // 提交form: form.submit();}&lt;/script&gt; 这种方式的缺点是扰乱了浏览器对form的正常提交。浏览器默认点击&lt;button type=”submit”&gt;时提交表单，或者用户在最后一个输入框按回车键。 2.因此，第二种方式是响应本身的onsubmit事件，在提交form时作修改：&lt;form id=\"test-form\" onsubmit=\"return checkForm()\"&gt; &lt;input type=\"text\" name=\"test\"&gt; &lt;button type=\"submit\"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() { var form = document.getElementById('test-form'); // 可以在此修改form的input... // 继续下一步: return true;}&lt;/script&gt; 注意要return true来告诉浏览器继续提交，如果return false，浏览器将不会继续提交form，这种情况通常对应用户输入有误，提示用户错误信息后终止提交form。 3.使用&lt;input type=”hidden”&gt;间接传输数据&lt;form id=\"login-form\" method=\"post\" onsubmit=\"return checkForm()\"&gt; &lt;input type=\"text\" id=\"username\" name=\"username\"&gt; &lt;input type=\"password\" id=\"input-password\"&gt; &lt;input type=\"hidden\" id=\"md5-password\" name=\"password\"&gt; &lt;button type=\"submit\"&gt;Submit&lt;/button&gt;&lt;/form&gt;&lt;script&gt;function checkForm() { var input_pwd = document.getElementById('input-password'); var md5_pwd = document.getElementById('md5-password'); // 把用户输入的明文变为MD5: md5_pwd.value = toMD5(input_pwd.value); // 继续下一步: return true;}&lt;/script&gt; 注意到id为md5-password的&lt;input&gt;标记了name=”password”，而用户输入的id为input-password的&lt;input&gt;没有name属性。没有name属性的&lt;input&gt;的数据不会被提交。 操作文件1.提交文件&lt;input type=”file”&gt;注意：当一个表单包含&lt;input type=”file”&gt;时，表单的enctype必须指定为multipart/form-data，method必须指定为post，浏览器才能正确编码并以multipart/form-data格式发送表单的数据。 出于安全考虑，浏览器只允许用户点击&lt;input type=”file”&gt;来选择本地文件，用JavaScript对的value赋值是没有任何效果的。当用户选择了上传某个文件后，JavaScript也无法获得该文件的真实路径。 检查文件后缀名 var file = document.getElementById(\"file-update\");var fileName = file.value;if (!fileName || fileName.endWith(\".jpg\") || fileName.endWith(\"png\")){ alert(\"can only update picture\"); return false;} 2.FileAPI HTML5的File API提供了File和FileReader两个主要对象，可以获得文件信息并读取文件。 var fileInput = document.getElementById('test-image-file'), info = document.getElementById('test-file-info'), preview = document.getElementById('test-image-preview');// 监听change事件:fileInput.addEventListener('change', function () { // 清除背景图片: preview.style.backgroundImage = ''; // 检查文件是否选择: if (!fileInput.value) { info.innerHTML = '没有选择文件'; return; } // 获取File引用: var file = fileInput.files[0]; // 获取File信息: info.innerHTML = '文件: ' + file.name + '&lt;br&gt;' + '大小: ' + file.size + '&lt;br&gt;' + '修改: ' + file.lastModifiedDate; if (file.type !== 'image/jpeg' &amp;&amp; file.type !== 'image/png' &amp;&amp; file.type !== 'image/gif') { alert('不是有效的图片文件!'); return; } // 读取文件: var reader = new FileReader(); // 回调函数 reader.onload = function(e) { var data = e.target.result; // 'data:image/jpeg;base64,/9j/4AAQSk...(base64编码)...' preview.style.backgroundImage = 'url(' + data + ')'; }; // 以DataURL的形式读取文件: reader.readAsDataURL(file);}); 3.异步回调上面的代码还演示了JavaScript的一个重要的特性就是单线程执行模式。在JavaScript中，浏览器的JavaScript执行引擎在执行JavaScript代码时，总是以单线程模式执行，也就是说，任何时候，JavaScript代码都不可能同时有多于1个线程在执行。 AJAX(Asynchronous Javascript And XML) 1.使用这里了解的已经比较多了，就不详细写了，AJAX是异步执行的所以需要设置回调函数，在现代浏览器上写AJAX主要依靠XMLHttpRequest对象 var request = new XMLHttpRequest();request.onreadystatechange = function () { if (request.readyState === 4) { if (request.status === 200) { var text = request.responseText; console.log(text); } else { console.log(\"failed\"); } } else { // HTTP请求还在继续... }}request.open(\"GET\",\"https://www.baidu.com\");request.send();console.log(\"其实这是个异步请求\"); 2.安全限制上面的代码实际上若不是再百度的域名下访问，是会收到如下报错的 Access to XMLHttpRequest at &apos;https://www.baidu.com/&apos; from origin &apos;https://www.liaoxuefeng.com&apos; has been blocked by CORS policy: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. 意思就是请求被浏览器的同源策略所拦截，如图但是默认情况下，JavaScript在发送AJAX请求时，URL的域名必须和当前页面完全一致。完全一致的意思是，域名要相同（www.example.com和example.com不同），协议要相同（http和https不同），端口号要相同（默认是:80端口，它和:8080就不同）。有的浏览器口子松一点，允许端口不同，大多数浏览器都会严格遵守这个限制。所以为了解决这个问题，我们引入一个叫做跨域请求的概念。在日常使用中，比如我之前用nodejs写的前后端分离应用用的就是aros跨域方法，具体的可以参考aros文档。 Promise在JavaScript的世界中，所有代码都是单线程执行的。 由于这个“缺陷”，导致JavaScript的所有网络操作，浏览器事件，都必须是异步执行。异步执行可以用回调函数实现 参考上面的代码，AJAX就是个典型的异步操作，但是有没有比上面的代码更好用的代码呢？可以写成这样 var ajax = ajaxGet(\"https://www.baidu.com\");ajax.ifSuccess(success); .ifFail(fail); 这种链式写法的好处在于，先统一执行AJAX逻辑，不关心如何处理结果，然后，根据结果是成功还是失败，在将来的某个时候调用success函数或fail函数。 古人云：“君子一诺千金”，这种“承诺将来会执行”的对象在JavaScript中称为Promise对象。代码示例 function test(resolve, reject) { var timeOut = Math.random() * 2; log('set timeout to: ' + timeOut + ' seconds.'); setTimeout(function () { if (timeOut &lt; 1) { log('call resolve()...'); resolve('200 OK'); } else { log('call reject()...'); reject('timeout in ' + timeOut + ' seconds.'); } }, timeOut * 1000);}new Promise(test).then(function (result) { console.log('成功：' + result);}) .catch(function (reason) { console.log('失败：' + reason);}); 可见Promise最大的好处是在异步执行的流程中，把执行代码和处理结果的代码清晰地分离了，用图来表示就是 再举个栗子，执行网络请求时也是这样 function ajax(method, url, data) { var request = new XMLHttpRequest(); return new Promise(function (resolve, reject) { request.onreadystatechange = function () { if (request.readyState === 4) { if (request.status === 200) { resolve(request.responseText); } else { reject(request.status); } } }; request.open(method, url); request.send(data); });}var request = ajax(\"GET\", \"https://www.baidu.com\");request.then(function(text){ console.log(\"请求内容为\"+text);}).catch(function(result){ console.log(\"错误代码：\"+result);}); Promise还可以并行执行两个任务，使用Promise.all([promise1,promise2]).then() 浏览器章节到这里就结束了，花了差不多五天的时间，仔细读了下javascript使用。和我学过的java还有python进行比较，不得不说有惊喜的地方，也有失望的地方，js更像python和java的结合，它没有java那么繁琐，但是也没有python那么简洁，然后下一步我打算学习Vue了，当可以比较熟练的使用常用的前端技能的时候，我就又做回我的老本行后端啦~","link":"/javascript的浏览器对象/"},{"title":"快手kcode程序设计大赛初赛总结","text":"最终分数：13622.19仓库地址：https://github.com/ayang818/KCoder-First upd: 2020/7 复赛结束，最终排名 28/647复赛赛题详情及代码： https://github.com/ayang818/2020-kcode-2r复赛的文件格式和处理读入流的方式和初赛差不多，最重要的查找计算最长链路的核心代码——https://github.com/ayang818/2020-kcode-2r/blob/master/src/main/java/com/kuaishou/kcode/KcodeAlertAnalysisImpl.java#L319 ， 使用记忆化搜索完成，其余常规思路可以参照初赛（感觉自己初赛写的代码拓展性还行） 为时14天的kcode初赛算是结束了（6/17 - 7/1），由于个人的时间安排关系，我差不多是从24号开始正式开始写代码的。由于分数不算很高，排名按照封榜前大概是 （20 ~ 30） / 100，估计还有一大堆没写出来的，毕竟群里900多号人，但是前10的大佬们已经基本都是2.5w+了，但是由于爬分的过程还是非常有趣的，所以还是还是打算写一篇博客来梳理一下优化的过程。 我的爬分过程：600 -&gt; 3600 -&gt; 5000 -&gt; 9400 -&gt; 11000 -&gt; 13600 在分析优化方案之前先做一下赛题解析 题目内容实现进程内对微服务调用信息的分析和查询系统，要求包含的功能如下： 接收和分析调用信息的接口 根据给定的条件进行查询和分析，描述如下： 输入主调服务名、被调服务名和时间（分钟粒度），返回在这一分钟内主被调按ip聚合的成功率和P99； 输入被调服务名和一个时间范围（分钟粒度, ==闭区间==），返回在区间内被调的平均成功率 数据和输入输出说明：输入数据格式： 每个调用记录存储在一行，数据直接以逗号分割(,), 换行符号(\\n)主调服务名,主调方IP,被调服务名,被调方IP,结果,耗时(ms), 调用发生的时间戳(ms)commentService,172.17.60.2,userServie,172.17.60.3,true,89,1590975771020commentService,172.17.60.3,userServie,172.17.60.4,false,70,1590975771025commentService,172.17.60.2,userServie,172.17.60.3,true,103,1590975771030commentService,172.17.60.3,userServie,172.17.60.4,true,79,1590975771031commentService2,172.17.60.3,userServie,172.17.60.4,false,88,1590975771031commentService2,172.17.60.3,userServie,172.17.60.4,true,91,1590975771032 成功率定义： 单位时间内被调服务成功率 = （单位时间内被调用结果为ture的次数）/ 单位时间内总被调用次数 【结果换算成百分比，小数点后保留两位数字,不足两位补0，其余位数直接舍弃】以上示例数据计算一分钟的成功率 - （2020-06-01 09:42）userServie在被调成功率: 4/6= 66.66% - （2020-06-01 09:42）userServie在172.17.60.4机器上成功率: 2 / 4 = 50.00% 如无特殊说明，赛题中说的成功率以单位时间为一分钟计算 如果计算结果是0，请表示成 .00% 查询输出格式说明： 查询1（checkPair）：输入：主调服务名、被调服务名和时间（分钟粒度）输出：返回在这一分钟内主被调按ip聚合的成功率和P99, 无调用返回空list （不要求顺序）输入示例：commentService，userServie，2020-06-01 09:42输出示例：172.17.60.3,172.17.60.4,50.00%,79172.17.60.2,172.17.60.3,100.00%,103查询2（checkResponder）：输入： 被调服务名、开始时间和结束时间输出：平均成功率，无调用结果返回 -1.00%平均成功率 = （被调服务在区间内各分钟成功率总和）/ (存在调用的分钟数）【结果换算成百分比，小数点后保留两位数字,不足两位补0，其他位直接舍弃，不进位】输入示例：userServie, 2020-06-01 09:42, 2020-06-01 09:44输出示例：66.66% 计算过程示例：（2020-06-01 09:42）userServie被调成功率: 4/6= 66.66%（2020-06-01 09:43）userServie无调用（2020-06-01 09:44）userServie无调用 那么userServie在2020-06-01 09:42到2020-06-01 09:44的平均成功率为（66.66%）/ 1 = 66.66%【示例数据仅仅在2020-06-01 09:42有调用】 如果计算结果是0，请表示成 .00% 评测环境&amp;启动参数 JDK 版本： 1.8 jvm内存设置 : -XX:+UseG1GC -XX:MaxGCPauseMillis=500 -Xss256k -Xms6G -Xmx6G -XX:MaxDirectMemorySize=1G 评测机器硬件信息（docker）： 操作系统 CentOS 7.3 64位 CPU 8核 3.00GHz 硬盘：容量 100GB， 吞吐量 &gt; 100MB/S 如果需要输出文件，请使用 /tmp/ 目录，禁止使用其他目录 题目内容就这么些，题目是很容易读懂的，简单的来说就是读入解析一个12G的具有一定格式的日志文件，然后建立一定的便于查询的数据结构，进行两种方式的查询。主要的得分点 第一阶段快速读入解析文件 二三阶段查询的时间复杂度尽可能小 爬分过程600分baseline 600分的baseline大概花了一天不到就写完了，其实本来是一个晚上左右就写完了的，但是由于各种综合原因踩到了一个比较低级的坑，所以在线上无日志的情况下找了将近一天的BUG。 baseline的做法非常暴力 1.第一阶段。首先我的第一阶段的目标是就是在单线程环境下加速IO速度，根据我以往的优化方案，第一想法就是使用块读写。 RandomAccessFile memoryMappedFile = new RandomAccessFile(path, \"r\");FileChannel channel = memoryMappedFile.getChannel();// try to use 16KB bufferByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024 * 64);int size = 0;while (channel.read(byteBuffer) != -1) {byteBuffer.flip(); int remain = byteBuffer.remaining(); byte[] bts = new byte[remain]; byteBuffer.get(bts, 0, remain); byteBuffer.clear(); processBlock(bts); size += 64;} 这里也是我踩到的第一个坑，由于平时都没有注意文件的权限管理，我的baseline在线上死活通不过的原因就是因为顺手写了 w 权限， RandomAccessFile memoryMappedFile = new RandomAccessFile(path, \"rw\"); 但是很显然赛题方是不会给我们写权限的，所以这里线上就一直报错，由于线上的日志只会打印Exception中的信息，但是这里在线上报的Security Exception又被catch了，导致没有一点点错误痕迹。只能通过肉眼在全局代码中一行行找可疑代码。这里花了我将近一天的时间。 但是其实对于块读来说，对于需要按行解析的数据是非常不友好的，由于每行的长度并不是固定的，所以不管一次块读的大小是多少，总会有块的末尾的数据不是完整的，需要和下一个块的开头的不完整部分的数据做拼接。并且也是需要遍历所有的字节，找到所有的 \\n 换行符来构建行，从而解析行，同时解析行同样是需要花费时间的。 实测在单线程环境下，如果处理行数据不是那么快，使用块读的效率和使用 bufferedReader.readLine() 的速度基本上也差不了多少， 因为这个时候瓶颈就不是调用IO，而是CPU解析的时间了。 2.第二阶段、查询 1，第二阶段稍微麻烦点的是p99的计算，我建立了如下的数据结构来做为baseline的方案。 Map&lt;caller+responder, Map&lt;timestamp, Map&lt;callerIp+responderIp, Span&gt;&gt;Span:static class Span { int sucTime; int totalTime; List&lt;Integer&gt; list; public Span() { sucTime = 0; totalTime = 0; } } 由于需要计算p99，最简单的做法当然是把所有数据都存起来，然后需要p99时，将所有数据排序，然后取 len * 0.99 位置的数值即可。这里的时间复杂度由于需要查询p99时需要排序，并且需要遍历 Map&lt;callerIp+responderIp, Span&gt; 来构造List，所以时间复杂度为 O(n^2logn) 3.第三阶段、查询 2，第三阶段比较简单，建立的存储数据结构如下 Map&lt;responder, Map&lt;timestamp, Span&gt;&gt; 由于第三阶段是一个时间区间，所以查询的时候，只需要遍历需要收集的时间区间然后计算成功率即可。时间复杂度为 O(n)， 这样的一个快速方案原型，在我本地跑出的耗时如下，其中第二阶段查询次数为1w，第三界阶段查询次数为100w 3600分 写出baseline之后，首先优化的是第一阶段，由于线上的机器配置非常好，8核CPU，所以肯定需要尽量释放机器性能。当前的想法有两个 多线程读文件，多线程处理数据 单线程读文件，多线程处理数据 但是在使用块读的情况下，要是使用多线程块读 读文件，同步策略会变得异常复杂，编码难度也大大增加，在短暂的尝试后，我选择了单线程读文件，多线程处理数据的方案。 但是当我把每一行作为一个任务提交到 8 线程线程池中进行处理解析是，运行时发现，运行时间却大大增加，统计了每行平均处理时间后，发现每行的处理时间大概在 200-2000ns，然而根据网上搜到的资料，线程切换导致的上下文切换开销也基本是这个量级，所以虽然使用了线程池，但是还是导致了大量的线程切换。对此我的解决方案就是先收集 n 行数据，然后再一起提交到线程池中处理。 index++;while (readline()) { ... index++; if (index &gt;= threshold) { final String[] tmp = list; threadPool.execute(() -&gt; handleLines(tmp)); list = new String[threshold]; index = 0; }} 到这里我的本地prepare耗时降到了（由于速度基本没有什么差距，所以我干脆把块读换成了代码更简洁的 BufferReader.readLine()） 一阶段的优化到这里基本就结束了，线上的一阶段耗时大致在 20s 左右。 接下来是第二阶段的优化，最需要优化的肯定是 p99 的计算，其实简单思考一下就可以想出 p99 的内存和时间上的最佳方案—— 桶排序，由于 p99 统计的是调用时间，而调用时间一般都集中在 0 - 350 这个区间中，所以这里的代码就很简单了，只需要让调用时间对应下标的bucket的值+1即可。 // 解析synchronized (this) { bucket[costTime] += 1;}// 计算p99public int getP99() { int pos = (int) (totalTime.get() * 0.01) + 1; int len = bucket.length; for (int i = len - 1; i &gt;= 0; i--) { pos -= bucket[i]; if (pos &lt;= 0) return i; } return 0;} 所以获取p99的复杂度从 O(nlogn)降到了 O(1)，阶段二的总体复杂度也降到了 O(n) 本地耗时，二阶段10w次，三阶段10w次 5000分 小的优化： 重写了自定义的DateFormatter。 重写了截取两位小数的DecimalFormatter。 优化查询2数据结构 Map&lt;responder, Map&lt;timestamp, Span&gt;&gt; 变成 Map&lt;responder, Span[]&gt;，虽然这两个数组和map的复杂度都是 O(1)，但是map在get时还是会需要进行hash运算，而数组则是直接通过偏移量取值。 （本来到了5000分就不想继续优化代码了，毕竟考试太多了，但是 kcode 的 QQ 群里突然有人发了个6000分的demo，瞬间自闭。但是本着比赛期间不太想看别人的代码的意思，于是还是决定继续对着自己的代码琢磨，（考试，危！ 9400分 这里算是分数进步最大的一次优化了，虽然感觉代码上并不是很难。。。 对于阶段二，其实当前的时间复杂度为O(n)，因为需要在查询时遍历一组服务队下所有的 IP 对，但是我想了一下之后，发现其实只要在阶段一结束后，遍历收集好的整个 Map，首先将这些 IP 对中的数据直接收集到一个 List 中即可。这样查询时就可以根据服务名+时间戳直接找到对应的 List 了 checkOneMap.forEach((key, timestampMap) -&gt; { // 遍历所有时间戳 timestampMap.forEach((k, ipPairMap) -&gt; { String[] split = key.split(\",\"); String resKey = split[0] + split[1] + k; List&lt;String&gt; resList = new ArrayList&lt;&gt;(20); ipPairMap.forEach((ipPair, span) -&gt; resList.add(span.getRes())); checkOneResMap.put(resKey, resList); });}); 对于阶段三，由于需要遍历区间中所有的分钟，才可以得到区间整体的成功率，所以这里就是一个非常烦的地方，虽然可以预先生成可能的所有区间的值，但是这种做法对于实际工程来说过于离谱。所以几经斟酌后还是没有这样做。 最后感觉可能只能构建缓存来让一部分 O(n) 操作变成 O(1) @Overridepublic String checkResponder(String responder, String start, String end) { String hash = responder + start + end; String res; if ((res = checkTwoResMap.get(hash)) == null) { Span[] timestampMap = checkTwoMap.get(responder); if (timestampMap == null) { checkTwoResMap.put(hash, \"-1.00%\"); return \"-1.00%\"; } long startMil = parseDate(start); long endMil = parseDate(end); double times = 0; double sum = 0; Span span; for (long i = startMil; i &lt;= endMil; i += 60000) { span = timestampMap[minuteHash(i)] ; if (span != null &amp;&amp; span.sucRate != 0) { sum += (span.getSucRate() * 100); times++; } } if (sum == 0) { if (times == 0) { checkTwoResMap.put(hash, \"-1.00%\"); return \"-1.00%\"; } checkTwoResMap.put(hash, \".00%\"); return \".00%\"; } String value = formatDouble(sum / times) + \"%\"; checkTwoResMap.put(hash, value); return value; } return res;} 但是运气比较好，这一次构建缓存的尝试让我的分数高了不少，到达了接近1w的分数，但是进复赛还是没有很稳，所以顶着两天连续考试的压力，又继续尝试优化。 11000分这里其实没有做什么优化，单纯的把线程池的大小从 8 调到了 16，但是分数提升还挺多。 13600分 到了11000后其实感觉还不是很稳，但是实在想不到以当前的代码还有什么可以优化的，但是感觉进复赛还不是很稳。由于当前二三阶段的查询都已经优化到了 O(1) ，所以感觉可以优化的只有常数。观察原来的代码，可能比较耗时的操作应该就是 String hash = responder + start + end; 和 String resKey = caller + responder + parseDate(time); 所以最后在分数的诱惑下还是选择了写一个自定义hash函数取代拼接字符串，但是实际工程中是不可能这么做的，只能寄希望于线上不要有hash冲突。 public Integer hash(Object a, Object b, Object c) { Integer res = 1; res = 1313 * res + a.hashCode(); res = 1313 * res + b.hashCode(); res = 1313 * res + c.hashCode(); return res; }// 查询1Integer resKey = hash(caller, responder, parseDate(time));// 查询2Integer hash = hash(responder, start, end); 最后拿到了13600这个差不多稳进复赛的成绩，心累。 技术外的一些想法2020的上半年，这个大二下学期的尾巴可以说过的非常忙碌了，六月参加了两个比赛，天池的中间件大赛、快手的kcode程序设计大赛、然后还有一大堆赶不完的大作业、期末考的复习…，不过还算都完成的还能接受，运气好一点两个都进复赛，参加这两个比赛对我也有很大的锻炼（至少比写CRUD要开心多了）。 想一想放完暑假就是大三，大三上学期过完就要去找暑期实习了，这么想想感觉大学剩下来的时间也不算很多了。然而感觉大学还是有好多事情没有做过啊，没去过一直想去的日本，没谈过恋爱，连之前一直非常喜欢的羽毛球也没有继续打下去…… ，一大堆没有干过的事情让我有种到底是我太忙了还是我不想去做的错觉。下学期社团和工作室的和辅导员对接好的一堆赛事和活动我也得去组织和安排，郁闷。如果自私一点想的话，这些东西不去做也不会有啥问题吧，无非就是科协还是没有生气的老样子、工作室人也越来越少。但是这些地方都让我收获了很多东西，虽然他们变得越来越差也不会对我以后有任何影响，但总还是有一些不甘心，想尝试去挽救一下，希望人没事~ 写了快一个晚上了，还是希望下半年也能一切顺利吧，感觉会有好事发生。","link":"/kcode1/"},{"title":"maven模块化最小实践","text":"为什么要进行maven模块化在说模块化之前，不妨说说非模块化的项目是怎么样的，非模块化的项目往往是一个单体应用，他的目录结构如下 为什么说是单体的呢，事实上 上面看到的所有的包比如controller，mapper，utils，, 这些一个个应用里的功能都是业务的一部分，到时候打jar包的时候其实就是把这些所有的功能打到同一个jar包中。然后运行就可以了。 整个项目只有一个pom文件，功能与项目强耦合，代码复用能力差。 那么对于一个多模块项目来说呢，他的目录结构如下 下面是一个maven模块化项目 下面是一个maven模块化项目的一个子目录 下面是一个. net core的微服务项目 不管是第一个maven项目和第二个非maven(. net core)项目，他们都不再是以一个功能文件夹来分割，而是通过一个个模块来组织代码，每个模块有其自己继承自根目录的pom文件。 这样看来maven的模块化项目的优势就呼之欲出了 划分模块，鼓励代码多项目重用，解耦合，便于部署独立微服务 防止某一个pom文件过于庞大，所有的模块pom继承自根目录下的pom，版本控制粒度不会受到影响 最后其实写这篇博客之前，我自己又给自己挖了一个坑————Kugga Kugga的服务端，提供消息服务，授权认证，文件储存转发等功能。我打算写一个小型的聊天软件(没错，摆脱CRUD的苦海)，顺带学习NIO和Netty。但是事实上这应该算是我写过的业务最复杂的项目了，然后我参照一些微服务框架搭建的项目，比如说Kahla，Pig。发现他们都是基于模块化的应用。再想到自己很少服用自己之前的代码，总是重复造轮子，于斯我打算尝试使用模块化来搭建这次的项目。 搭建过程搭建过程参考了这篇文章，内容我不细写了。说一下基本的搭建逻辑 根目录使用spring initializr创建一个spring boot项目，然后把出了pom.xml外的文件都删了。在pom.xml中添加子模块的名称 &lt;modules&gt; &lt;module&gt;kugga-easy-server&lt;/module&gt; &lt;module&gt;kugga-starter&lt;/module&gt;&lt;/modules&gt; 在根目录下创建子模块(maven工程)，将其parent指向根目录pom的坐标，，然后可以省略模块目录的groupId和version，这两个属性会自动继承根目录pom的值 &lt;parent&gt; &lt;artifactId&gt;kugga&lt;/artifactId&gt; &lt;groupId&gt;com.ayang818&lt;/groupId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/parent&gt; 还有几个要注意的点就是要是想要解决模块下dependence的版本控制，可以在根目录下写一个 &lt;dependencyManagement&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.57&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencyManagement&gt; 然后模块下的pom就可以不写版本号了，他会递归直到找到这个依赖的版本，这种方法在一开始创建的spring boot中也会看到。 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;","link":"/maven模块化最小实践/"},{"title":"微服务技术调研","text":"","link":"/micro-service-explore/"},{"title":"mit6.824","text":"lab1 已经完工，但是遵循 Collaboration Policy…Please do not publish your code or make it available to current or future 6.824 students. github.com repositories are public by default, so please don’t put your code there unless you make the repository private. You may find it convenient to use MIT’s GitHub, but be sure to create a private repository. 所以我的代码就不开源了，所有的笔记我会在学习完所有课程，做完四个 lab 后整理后开源。 upd: 做完第一个 mapreduce 后就没时间做其他的了…","link":"/mit6-824/"},{"title":"[优化]Java中大文件IO的优化策略","text":"Java中的IO方式大致分为如下几种 普通IO，也叫做BIO，基于流模型的阻塞式IO，相关的类大部分都是InputStream，OutputStream，Reader，Writer下的子类。 NIO，也是大家认为效率较高的IO方式之一，相关的类有 ByteBuffer，FileChannel等。 mmap内存映射，这是一种将文件直接映射到内存地址的方式，是一种非常快速的IO方案，相关的类有FileChannel，MappedByteBuffer 但是在分析各种IO方式的优化策略的时，首先至少需要了解一下，使用Java进行一次磁盘读取，到底进行了那些步骤？ 标准的一次文件读肯定涉及以下几个拷贝步骤 将数据从硬件读取到内核态的内核缓冲区中 将内核缓冲区的数据读取到用户态的 JVM 中 此外，底层通过 write 、read 等函数进行 IO 系统调用时，需要传入数据所在缓冲区起始地址和长度，但是由于我们使用的是 Java，Java 中的对象存在 Java 的堆中，由于 GC 的存在，对象在堆中的位置是会不断变动的，所以在用户态的 JVM 和 内核缓冲区之间，还有一个不会被 GC 所干扰的堆外内存区作为缓冲区，所以这里又多了一个拷贝步骤。 将堆外内存区的数据读取到堆中。 整体流程如下 一次标准的文件读会经过三次数据拷贝，那么一次完整的文件读写就是六次数据拷贝，这样显然效率会比较低。这将是我们可以优化的一个点。 具体方案所有示例方案针对本地文件写入的方式，这是我在一次比赛中遇到的问题，下面也基本记录了我的调研过程 对于BIO来说，我们可以优化的往往就是为我们的输入流增加缓冲区，在 JDK 中，我们可以使用封装好的方法，用装饰器模式来补充我们的代码。示例代码如下 BufferedOutpuStream bufferedoutstream = new BufferedOutputStream(new FileOutputStream(file)); 默认的缓冲区的大小是 8KB ，你可以使用带缓冲区大小的构造方法，根据程序运行环境的大小来调整缓冲区大小。比如磁盘的最小写入单位来确认，推荐这篇文章 https://tech.meituan.com/2017/05/19/about-desk-io.html。除了字节流有缓冲区，字符流同样也有缓冲区，使用方法基本一致。 对于 mmap 内存映射技术来说，我在调研了基本原理之后，自己上手实践了一下，得出了结论——这种IO方式是真的快。贴一段示例代码 try (RandomAccessFile memoryAccessFile = new RandomAccessFile(BASE_DIR + fileName, \"rw\")) { FileChannel fileChannel = memoryAccessFile.getChannel(); MappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, TARGET_FILE_SIZE); // 设置内存初始偏移段 int offset = 0; while (true) { byte[] bytes = generateLine().getBytes(); // 计算内存偏移段+即将加入的字节数量是否超出一开始的限制 if (offset + bytes.length &gt; TARGET_FILE_SIZE) break; // 设置映射起始位置 mappedByteBuffer.position(offset); mappedByteBuffer.put(bytes); // 移动偏移段 offset += bytes.length; }} catch (IOException e) { e.printStackTrace();} 但是在后续的调研中，我又了解到mmap之所以快，事实上是因为借助了内存来进行加速，从我们的代码也可以看出，事实上 MappedByteBuffer 中的注释说的很清楚 A direct byte buffer whose content is a memory-mapped region of a file. 这就是一块堆外内存，我们的数据也是先写到这块堆外内存里面，然后依赖操作系统的定时刷盘，或者自己手动调用MappedByteBuffer.force() 方法刷盘。然后我的比赛环境内存非常有限，只有 2G 的内存，但是我的问价大小却是介于 0-8G之间，所以要是数据量一大到8G，刷盘又不及时，整个机器基本上就卡死了（aliyun 1核2G学生机实测）。所以虽然这个方案很快，但是却不适用于我当前的场景。 第三个就是我现在选择的 NIO 方案了，使用FileChannel + 多级缓存。 首先关于这里的缓存，我们上文中提到了一次文件读的额外的数据拷贝——将堆外内存区的数据拷贝到堆中，那么要是我的数据是直接通过堆外内存来操作的，那么在一次文件读写中是不是就可以减少两次次数据拷贝了呢？Java为我们提供了 DirectByteBuffer 这个类让我们可以分配操作堆外内存，我们将使用这个类作为我们的缓存。 由于我的大部分记录大小都是 192 B 左右，要是逐条写入内存，由于离磁盘的最小写入单位（调研得到大部分为 4 K，要是数据不足 4K 消耗时间和 4K相同）相差较大。 那么我将几条位于相同分组的记录作为一个文件块写入一级缓存，当一级缓存满时，将一级缓存的内容写入二级缓存，二级缓存大小可以按照磁盘配置来设定，我这里暂时取了4 * 16 = 64KB，当二级缓存满时，使用一个单线程池将其异步刷入磁盘。示例代码如下 // 申请 100条 记录的堆外内存ByteBuffer byteBuffer = ByteBuffer.allocateDirect(192 * 100);// 申请 64KB 的二级缓存ByteBuffer flushBuffer = ByteBuffer.allocateDirect(1024 * 64);try (RandomAccessFile randomAccessFile = new RandomAccessFile(BASE_DIR + fileName, \"rw\"); FileChannel channel = randomAccessFile.getChannel()) { while (true) { byte[] bytesLine = generateLine().getBytes(); if (channel.size() + bytesLine.length &gt;= TARGET_FILE_SIZE) break; int remain = byteBuffer.remaining(); if (bytesLine.length &gt; remain) { flush(byteBuffer, flushBuffer, channel); } byteBuffer.put(bytesLine); }} catch (IOException e) { e.printStackTrace();} /*** @param byteBuffer 一级缓存* @param flushBuffer 二级刷盘缓存* @param channel 管道* @description 缓冲区容量不足，写入二级缓存，若二级缓存即将慢，进行刷盘*/public void flush(ByteBuffer byteBuffer, ByteBuffer flushBuffer, FileChannel channel) { // 反转一级缓存为读Mode byteBuffer.flip(); // 剩余可读缓存 int remain = byteBuffer.remaining(); byte[] records = new byte[remain]; byteBuffer.get(records); byteBuffer.clear(); // 其他线程异步刷盘 FLUSH_THREAD.execute(() -&gt; { try { // 检查二级缓存是否足够 if (flushBuffer.remaining() &lt; records.length) { // 读出二级缓存中的内容 flushBuffer.flip(); // 写入管道 channel.write(flushBuffer); flushBuffer.clear(); } flushBuffer.put(records); } catch (IOException e) { e.printStackTrace(); } });} 速度测试这是三种形式在写入 100 MB 数据的时候的速度。 nio在没有优化前的速度是和bio基本一致的。在当前这个小内存下，这个优化速度我还是比较满意的。","link":"/large-file-I-O-in-java/"},{"title":"mybatis-generator 生成Mysql数据库映射踩到的坑","text":"问题的解决今天当我尝试使用mybatis-generator来重新接管我的数据库映射的时候，对着官网一顿操作，最后使用 mvn -Dmybatis.generator.overwrite=true mybatis-generator:generate 来生成Mapper和Model的时候，弹出了如下的错误，我一开始认为只是警告，没有什么问题，但是知道看到Model中多了一堆奇怪的字段，我才知道mybatis-generator可能把两个匹配的table都做了映射，但是事实上我一进在generatorConfig.xml中配置了schema的名称了 &lt;table schema=\"community\" tableName=\"user\" domainObjectName=\"user\"&gt; 而我认为没有什么问题，可能是没有保存，然后开始疯狂generator，然后疯狂reset，这就很自闭了。我开始查找问题的原因，查看官方文档，我认为应该是Mysql的问题，因为事实上Mysql是没有schema这个讲法，只有database，查看官网的DataBase specific information，其中确实有Mysql 里面说当我们catelog..table语法在mysql中其实错误的，并且当我们使用版本为8.x的Connect/J作为连接器，在匹配table的时候确实会产生意想不到的错误。解决这个错误只需要在jdbcConneter中加入一行 &lt;property name=\"nullCatalogMeansCurrent\" value=true\" /&gt; mybatis-generator 配置记录&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;!-- &lt;classPathEntry location=\"/Program Files/IBM/SQLLIB/java/db2java.zip\" /&gt;--&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;jdbcConnection driverClass=\"\" connectionURL=\"\" userId=\"root\" password=\"\"&gt; &lt;property name=\"nullCatalogMeansCurrent\" value=\"true\"/&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt;&lt;!-- 重建model--&gt; &lt;javaModelGenerator targetPackage=\"top.ayang818.community.community.Model\" targetProject=\"src\\main\\java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt;&lt;!-- 生成sqlMapper--&gt; &lt;sqlMapGenerator targetPackage=\"mapper\" targetProject=\"src\\main\\resources\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"top.ayang818.community.community.Mapper\" targetProject=\"src\\main\\java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaClientGenerator&gt; &lt;table schema=\"community\" tableName=\"user\" domainObjectName=\"user\"&gt; &lt;/table&gt;&lt;!-- &lt;table tableName=\"question\" domainObjectName=\"Question\"&gt;&lt;/table&gt;--&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt;","link":"/mybatis-genarator-生成Mysql数据库映射踩到的坑/"},{"title":"mysql事务初探","text":"mysql的事务平时我们经常听到mysql的事务操作，我自己在写Java的时候也经常会遇到，今天就简单的写一下，mysql事务的一些操作 什么是事务MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 事务需要满足的四个条件一般来说，事务需要满足四个条件(ACID),原子性(atomicity)，一致性(Consistency)，隔离性(Isolation)，持久性(Durability) 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 这些操作其实和git命令挺像的 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交 事务控制语句 BEGIN 或 START TRANSACTION 显式地开启一个事务； COMMIT 也可以使用 COMMIT WORK，不过二者是等价的。COMMIT 会提交事务，并使已对数据库进行的所有修改成为永久性的； ROLLBACK 也可以使用 ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier，SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT； RELEASE SAVEPOINT identifier 删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier 把事务回滚到标记点； SET TRANSACTION 用来设置事务的隔离级别。InnoDB 存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。 代码示例create table transaction_test (id int primary key auto_increment, content varchar(50) null);# 显式开启事务begin;insert into transsaction_test value('test1');insert into transsaction_test value('test2');commit;# 以下事务未执行begin;savepoint point1insert into transsaction_test value('test3');rollback to point1;","link":"/mysql事务初探/"},{"title":"python 装饰器从走路到跑路（误","text":"计时器的例子在平时工作中，我们可能需要为一些业务方法添加一些通用的功能，比如 日志打点、调用耗时、重试机制等。举个例子，我们要统计某些方法的调用耗时并上报，那么对于一个业务方法， import timedef biz_method(uid): print('processing') time.sleep(1) # 模拟业务代码运行 我们可能想到这么改造 import timedef biz_method(): start = time.time() print('processing') time.sleep(1) # 模拟业务代码运行 print ('time spent %.4fs', % (time.time() - start)) 但是这样的话，一大段业务无关的代码就混入了业务流程中，这显然很不合理，并且我们需要记录统计时间的方法也不止这一个，这个时候，我们就需要 装饰器 这个东东 python 的装饰器的用法类似于 java 的注解，使用装饰器改造上面的代码后，变成了 import timedef time_spent_count(func): def wrapper(): start = time.time() func() print ('time spent %.4fs' % (time.time() - start)) return wrapper@time_spent_countdef biz_method(): print('processing') time.sleep(1) # 模拟业务代码运行biz_method()# 输出# processing# time spent 1.0033s 这样我们就可以对业务代码无侵入地增加一个计时功能。 带参数的计时器这个时候，我们的产品有给我们提了一个需求：部分接口需要把调用耗时上传到统计平台，而不走 ELK。抽象成代码，不就是多加一个是否上传的参数嘛~ import timedef time_spent_count(report=False): def wrapper(func): def inner_wrap(): start = time.time() func() cost = time.time() - start print ('time spent %.4fs' % cost) if report: report() def report(): print(\"report to remote~\") return inner_wrap return wrapper@time_spent_count(True)def biz_method(): print('processing') time.sleep(1) # 模拟业务代码运行biz_method() 这里我们带参数的计时器就写好了，那么这里有人可能就要问了，马老师，你这个不好用….，为啥带参数的计时器比原来多了一个内部函数呀；原先的计时器是 time_spent_count -&gt; wrapper。怎么到了你这里就变成了 time_spent_count -&gt; wrapper -&gt; inner_wrap 了。 其实装饰器的就是干了下面这么一件事情：接收一个函数，返回给你一个新函数我们把装饰器的皮扒了吧 害怕 # 第一个例子中不带参的计时器等价于下面import timedef time_spent_count(func): def wrapper(): start = time.time() func() print ('time spent %.4fs' % (time.time() - start)) # 把 wrapper 函数返回 return wrapperdef biz_method(): print('processing') time.sleep(1) # 模拟业务代码运行biz_method = time_spent_count(biz_method) # 这里的这个biz_method 实际上就变成了 wrapper 函数了biz_method() # 第而个例子中带参的计时器等价于下面import timedef time_spent_count(report=False): def wrapper(func): def inner_wrap(): start = time.time() func() cost = time.time() - start print ('time spent %.4fs' % cost) if report: report() def report(): print(\"report to remote~\") return inner_wrap return wrapperdef biz_method(): print('processing') time.sleep(1) # 模拟业务代码运行biz_method = time_spent_count(report=True)(biz_method)biz_method() 带参数的业务方法为了让有些看到这里还没懂得同学有作业抄，这里定义了一个平时可能最常用的形式：装饰器带参，业务方法也带参的例子 import timeimport functoolsdef time_spent_count(report=False): def wrapper(func): @functools.wraps(func) def inner_wrap(*args, **kwargs): start = time.time() func(*args, **kwargs) cost = time.time() - start print ('time spent %.4fs' % cost) if report: report() def report(): print(\"report to remote~\") return inner_wrap return wrapper@time_spent_count(True)def biz_method(data): print('processing %s'% data) time.sleep(1) # 模拟业务代码运行biz_method(\"hahah\") 有的同学可能又要问了，不对呀，你这个突然冒出来的 @functools.wraps 又是个啥呀，这个装饰器其实对于业务的执行结果来说没有影响。 使用这个装饰器的原因是，装饰器其实返回了包含业务方法功能的另外一个函数，也就是说原有函数被狸猫换太子了耶~，原有函数的一些原信息就被丢失了，使用 functools.wraps 可以 保留原函数的元信息。 你可以分别去掉 time_spent_count 这个装饰器的 functools.wraps 测试一下 # 不使用 functools.wrapsprint(biz_method.__name__)&gt;&gt; inner_wrapper# 使用 functools.wrapsprint(biz_method.__name__)&gt;&gt; biz_method 看到这里，你总该可以说你知道装饰器是个啥了吧，好耶~","link":"/python-decorator/"},{"title":"servlet究竟是什么,servlet及子类源码分析","text":"servlet是什么好像在使用了SpringBoot后，或者说Spring后，程序员好像越来越难接触到servlet这个东西了，很多人以为隐藏在重重框架后的servlet是个超级复杂的洪水猛兽，但是并不是这样的。事实上，servlet就是一个Java接口，interface! 打开idea，ctrl + shift + n，搜索servlet，就可以看到是一个只有5个方法的interface! public interface Servlet { void init(ServletConfig var1) throws ServletException; ServletConfig getServletConfig(); void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException; String getServletInfo(); void destroy();} 所谓接口，无非是为了规范。那么对于那些实现了servlet接口的类来说呢？他们就可以处理网络请求的吗？当然是不可以的！servlet并不与客户端直接打交道，真正和客户端打交道的东西是tomcat容器，tomcat监听了端口，每过来一个http请求，tomcat根据http请求的url，将请求转发到tomcat中的对应的servlet容器中，然后servlet处理业务逻辑后返回一个response对象，tomcat再将这个response返回给客户端。 框架中的servlet其实对于框架的使用者来说，许多人其实完全不知道自己写的类，什么时候被谁调用了，你甚至没有看到这个类被new以下，但是类里面的代码就是执行了。你好像就是配了个.xml文件，然后按了下Run/Debug按钮，项目就跑了起来。 其实没什么复杂的，这些东西，抽象的讲其实就是——注入和回调，你自己的代码里或许没有一个显式入口，但是tomcat中有个main方法，假设是这样的 我们只需要写个xml，框架机会解析xml创建实例，通过接口注入实例到合适的位置来执行我们的代码，其实并不很难懂。 实现一个Servlet对于servlet接口来说，你可以发现你如果想直接实现Servlet接口，似乎很难，因为service()方法中的两个参数，一个是Request，Response。这两个东西怎么写嘛！前面说到servlet的请求其实是由tomcat传入的，所以其实tomcat会将将这两个请求封装成对象传给我们。我们往下看，servlet包中还有一个抽象类实现了servlet接口，叫做GenericServlet，但是点进源码一看，里面关于servlet接口的方法都是抽象的。所以再往下看，有一个叫做HttpServlet的抽象类继承了GenericServlet，里面也完善了servlet接口的函数。所以我们要实现一个servlet只需要继承HttpServlet方法就可以了。但是我们要重写HttpServlet里的方法也是有讲究的。不妨先看看里面service方法的源码 protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); long lastModified; if (method.equals(\"GET\")) { lastModified = this.getLastModified(req); if (lastModified == -1L) { this.doGet(req, resp); } else { long ifModifiedSince = req.getDateHeader(\"If-Modified-Since\"); if (ifModifiedSince &lt; lastModified) { this.maybeSetLastModified(resp, lastModified); this.doGet(req, resp); } else { resp.setStatus(304); } } } else if (method.equals(\"HEAD\")) { lastModified = this.getLastModified(req); this.maybeSetLastModified(resp, lastModified); this.doHead(req, resp); } else if (method.equals(\"POST\")) { this.doPost(req, resp); } else if (method.equals(\"PUT\")) { this.doPut(req, resp); } else if (method.equals(\"DELETE\")) { this.doDelete(req, resp); } else if (method.equals(\"OPTIONS\")) { this.doOptions(req, resp); } else if (method.equals(\"TRACE\")) { this.doTrace(req, resp); } else { String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[]{method}; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(501, errMsg); } } 可以看到他会根据你请求方式的不同，来调用不同的函数，拿get请求时候的方法举例子，doGet()方法的源码是这样的 protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String protocol = req.getProtocol(); String msg = lStrings.getString(\"http.method_get_not_supported\"); if (protocol.endsWith(\"1.1\")) { resp.sendError(405, msg); } else { resp.sendError(400, msg); } } 意思就是要是http/1.1的话，返回405，否则返回400，反正就是不管怎么样都是失败。但是这也正常啊，因为这段东西其实属于业务逻辑范畴，所以对于父类来说，父类无法知道业务逻辑，所以写一个模板方法，具体业务逻辑抽象成方法让子类来实现。这其实就是设计模式中的模板方法模式。","link":"/servlet究竟是什么-servlet及子类源码分析/"},{"title":"使用0xff来保证二进制补码的一致性","text":"写这篇文章的起因本来今天在写浅析分布式唯一ID生成算法——snowflake的实现这篇博客的时候，写的好好的，但是写到一种生成方式 UUID.randomUUID().toString(); 发现自己并不是很知道这个怎么实现的，然后点开了源码打算读一下。结果就发现了一段代码。 /** Private constructor which uses a byte array to construct the new UUID.*/private UUID(byte[] data) { long msb = 0; long lsb = 0; assert data.length == 16 : \"data must be 16 bytes in length\"; for (int i=0; i&lt;8; i++) msb = (msb &lt;&lt; 8) | (data[i] &amp; 0xff); for (int i=8; i&lt;16; i++) lsb = (lsb &lt;&lt; 8) | (data[i] &amp; 0xff); this.mostSigBits = msb; this.leastSigBits = lsb;} 其中有一小段(下方代码段)我不是很理解有什么作用，因为data[i]的类型实际上是byte类型的，byte的十进制范围是-128-127，而0xff的十进制是15 * 16 + 16 = 256，转化为八位二进制就是11111111，我想着data[i] &amp; 0xff的话是使用0xff做截取操作，但是byte转化为二进制的长度肯定在8位以内，所以这个截取操作第一眼看起来并没有什么用哈？ data[i] &amp; 0xff 但是看着这个写法感觉好像有些熟悉，因为之前写md5加解密好像看到过类似的代码，但那个时候是因为赶作业，所以就没有深究。我找回了当时的代码。代码地址如下——代码地址 同样也有类似的写法，但是这个代码里的写法又有些不一样。因为这里写的是0x000000ff，那就是32位。 我这才意识到原来0xff是一个int类型的值。那么完整的写就是0x000000ff，任何数与0x000000ff做截取的结果就是令高24位都为0，保留低八位。 而data[i]作为一个byte类型的值。比如data[i] = -127，并且byte类型是有符号类型。那么-127的8位二进制补码表示就是0x10000001，但是事实上byte和int做&amp;运算的时候byte若为负数，那么data[i]会转型为int，转化后的高24位都会为1，这个时候转换为int后的data[i]和原来的data[i]他们的源码十进制数虽然相同，但是事实上他们的二进制补码已经发生了改变。 用下面的代码举个例子(Integer.toHexString()的作用就是查看他们的16进制补码) byte a = -128;byte b = 127;int a1 = a &amp; 0xff;int b1 = b &amp; 0xff;int res1 = a * 200;int res2 = b * 200;int res3 = a1 * 200;int res4 = b1 * 200;System.out.println(res1);System.out.println(res2);System.out.println(res3);System.out.println(res4);System.out.println(Integer.toHexString(res1));System.out.println(Integer.toHexString(res2));System.out.println(Integer.toHexString(res3));System.out.println(Integer.toHexString(res4)); 结果为 -25600254002560025400ffff9c00633864006338 可以看到对于正数的byte类型，和int互操作不会有什么影响；但是对于负数的byte，若是不对其进行&amp; 0xff的话，转化后的值的补码前24为均为1(结果中的ffff9c00)。 所以说到这里已经很明白了，使用0xff做截取转换的作用就是防止byte为负时与int进行计算，从而令byte先转化为高24位均为1(补码)的int。虽然这样使用0xff截取后，byte转化为int后的十进制并不等于原byte的十进制，但是却保证了他们的二进制补码的一致性。","link":"/使用0xff来保证二进制补码的一致性/"},{"title":"IDEA远程调试","text":"java世界里的一切东西都是在拼Java命令行参数 Debug之前调试一切Java程序，想清楚两点 想清楚要调试的代码跑在哪个JVM中 找到要调试的源代码 随时随地Debug java -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=1044 FileName IDEA连接Remote 调试 一个鬼畜的方法，调试Java代码 export JAVA_TOOL_OPTIONS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=1044# 取消unset JAVA_TOOL_OPTIONSls -alts IDEA Debug技巧 step over ：逐行调试，跳过函数(接收结果) step into ：单步调试，进入函数体(不进入JDK原生方法) force step into ：同上，进入JDK原生方法 step out ：跳出方法 resume problem ：跳至下一个断点","link":"/万能的Java方法论/"},{"title":"从一个容器安全类引入单例模式","text":"使用客户端加锁的Vector的复合操作 在我的上一盘博文中， public class SafeContainer { private Vector&lt;Integer&gt; vector; private static SafeContainer safeContainer; private SafeContainer() { vector = new Vector&lt;&gt;(); } public static SafeContainer getSafeContainer() { if (safeContainer == null) { safeContainer = new SafeContainer(); } for (int i = 0; i &lt; 50; i++) { safeContainer.addLast(i); } return safeContainer; } public synchronized Integer deleteLast() { int lastIndex = vector.size() - 1; Integer remove = vector.remove(lastIndex); return remove; } public synchronized void addLast(Integer integer) { vector.add(integer); } public synchronized boolean isEmpty() { return vector.isEmpty(); } public synchronized Integer getLast() { int size = vector.size() - 1; Integer integer = vector.get(size); return integer; }} 在这段代码中，我并不想把我的vector直接暴露给我外界，我只想允许其它类调用这个类二次封装的操作vector的方法来修改vector里面的属性。并且其它所有的类访问的都得是同一个vector里的内容。最简单的方式就是让这个类只能有一个对象。这个时候需要考虑的就是单例模式的设计。 单例模式的特点 单例模式只能有一个实例。 单例类必须创建自己的唯一实例。 单例类必须向其他对象提供这一实例。 单例模式与静态类对比静态类据我所知用的比较多的地方就是在建造者模式中，这篇文章中写的对比很详细。建议参考该文章。 单例模式的实现 懒汉模式(Lazy loading)一开始的代码里使用的就是懒汉模式，在这个类创建的时候，并没有创建单例绑定到类的static域上，这个办法使用了非常明显的lazy load。所以叫懒汉模式，但是上面的代码不是线程安全的，所以需要处理同步。 饿汉模式 private Vector&lt;Integer&gt; vector;private static SafeContainer safeContainer = new SafeContainer();private SafeContainer() { vector = new Vector&lt;&gt;();}public static SafeContainer getSafeContainer() { for (int i = 0; i &lt; 50; i++) { safeContainer.addLast(i); } return safeContainer;} 这里就相当于是直接把单例绑定到了safeContainer上了 静态类内部加载private Vector&lt;Integer&gt; vector;private static class SingletonHelper { private static SafeContainerStaticLoad safeContainerStaticLoad= new SafeContainerStaticLoad();}public static SafeContainerStaticLoad getInstance() { return SingletonHelper.safeContainerStaticLoad;}private SafeContainerStaticLoad() { vector = new Vector&lt;&gt;();} 就是使用静态类内部的static字段来实现加载对象，使用内部类的好处是，静态内部类不会在单例加载时就加载，而是在调用getInstance()方法时才进行加载，达到了类似懒汉模式的效果，而这种方法又是线程安全的。 枚举方法这个算是最好用，也是最简单的单例模式实现了SAFE_CONTAIN_ENUM();private Vector&lt;Integer&gt; vector;SafeContainEnum() { vector = new Vector&lt;&gt;();} 莫得了。它实现了 自由序列化。 保证只有一个实例。 线程安全。 双重校验锁法public class SingletonDemo { private static volatile SingletonDemo instance; private SingletonDemo(){ System.out.println(\"Singleton has loaded\"); } public static SingletonDemo getInstance(){ if(instance==null){ synchronized (SingletonDemo.class){ if(instance==null){ instance=new SingletonDemo(); } } } return instance; }} 丢一段代码吧，这个挺好理解的，这个其实就是两个线程调用getInstance方法的时候，由于对SingletonDemo.class加锁了，然后在一个线程获得实例的时候，另一个线程由于可见性，知道了instance对象不为空，所以就得到了第一个线程返回的对象的引用。","link":"/从一个容器安全类引入单例模式/"},{"title":"使用express实现注册登陆接口,以及jwt的使用","text":"首先贴一个项目地址技术栈是express+mongodb+cors跨域方案解决+jwt token令牌 1.需求分析 注册(username唯一性) 登陆(使用bcrypt加密) jwt令牌登陆态控制 ## 2.首先是express中mongodb操作 照例是先链接数据库 const mongoose = require(\"mongoose\");mongoose.connect(\"mongodb://119.23.240.115:27017/express_login\", { useCreateIndex: true, useNewUrlParser: true }) 其次是创建User表结构，这里由于只是Demo演示，所以只是写了两个字段 const User = mongoose.models(\"User\", new mongoose.Schema({ username: {type: String, unique: true}, // 在这里使用bcrypt加密算法 password: {type: String, set(val){ return require(\"bcrypt\").hashSync(val, 10); }}}))// 导出模型module.exports = { User } 3.其次是后端api调用查询所有用户app.get(\"/api/users\", async (req, res) =&gt; { const users = await User.find(); res.send(users);}) 用户注册app.post(\"/api/register\", async (req, res) =&gt; { const user = await User.create({ username: req.body.username, password: req.body.password });}) 用户登陆app.post(\"/api/login\", async (req, res) =&gt; { const user = await User.findOne({ username: req.body.username }) if (!user) { return res.status(422).send({ message: \"用户名不存在\" }) } const isPasswordValid = require(\"bcrypt\").conpareSync(req.body.password, user.password); if (!isPasswordValid) { return res.status(422).send({ message: \"密码错误\" }) } // 接下来使用jwt(jsonwebtoken)生成令牌 const token = require(\"jsonwebtoken\").sign({ // 注意这里千万不能把密码当作令牌加密 id: String(user._id) }, \"secretKey, should be a golbal variable\") res.send({ user, token: token })}) 关于jwt，推荐一篇文章，通俗易懂 身份认证中间件编写身份认证中间件的编写的作用是为了减少代码的复用 // 这里默认每一次登陆后的api请求头的authorization字段里都含有jwtconst authorMiddleware = async (req, res, next) =&gt; { const raw = String(req.header.authorization).split(\" \").pop(); // 校验令牌 const { id } = require(\"jsonwebtoken\").verify(raw, \"secretKey\"); req.user = await User.findById(id); next();} 请求时身份认证中间件app.post(\"/api/profile\", authorMiddleware, async (req, res) =&gt; { res.send(req.user);}) 这样就实现了一套完整的注册登陆认证的服务，但是显然这套方案是有问题的。 写完我发现的一个问题就是注册时——密码是以明文传输到后端API，的这显然是不可行的，所以应该改为前端就是用bcrypt直接加密，随后将密文传输到后端API。这里没有写前端界面，所以暂且不修改。 还有一个不确定的问题在于jwt的加密方式，从代码提示看jwt像是对称加密，这里看起来在安全性上也有点问题，等过段时间仔细看下jwt的正确使用是否是我现在这样放在请求头里用来验证数据的的。","link":"/使用express实现注册登陆接口-以及jwt的使用/"},{"title":"使用JDK dynamic proxy实现动态代理模式","text":"代理模式代理模式理解起来很简单，比如说我有一个接口叫做Hello public interface Hello { void say();} 他的实现类是HelloImpl public class HelloImpl implements Hello { @Override public void say() { System.out.println(\"hello world\"); }} 但是我又想在say()调用前做些什么，这里其实很关键，因为你找到了一个切点，这就是AOP——面向方面编程的特征，这个待会再说。想加新的功能，但是我们都学过开闭原则，所以我们打算再创建一个代理类来实现这一功能(组合) public class HelloProxy implements Hello { private Hello hello; public HelloProxy() { hello = new HelloImpl(); } @Override public void say() { System.out.println(\"start\"); hello.say(); System.out.println(\"end\"); }} 然后运行试下 public static void main(String[] args) { Hello hello = new HelloProxy(); hello.say();} 结果就是 starthello worldend 这样看着既简单，又实现了需要的功能，似乎已经满足我们的需求了。这种方式叫做静态代理。 用JDK dynamic proxy实现的动态代理动态代理也是代理模式的一种实现，我们的两个基础类Hello和HelloImpl都不变，然后使用JDK给我们提供的动态代理方式来实现一下，我们创建一个ProxyHanlder 然后实现invocation接口。 public class ProxyHandler implements InvocationHandler { // 被代理对象 private Object target; public ProxyHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"start\"); Object result = method.invoke(target, args); System.out.println(\"end\"); return result; }} 然后运行 public static void main(String[] args) { // 被代理的对象 Hello hello = new HelloImpl(); ProxyHandler proxyHandler = new ProxyHandler(); Hello helloProxy = (Hello) Proxy.newProxyInstance(hello.getClass().getClassLoader(), hello.getClass().getInterfaces(), proxyHandler); helloProxy.say(); } 我们需要使用Proxy.newInstance方法获取代理对象，但是可以发现需要传入的参数太长太恶心了，你需要传入被代理对象的类加载器，接口表，和一个invocation实现类(在这里就是ProxyHandler)。所以其实可以再ProxyHandler封装一个bind方法。 @SuppressWarnings(\"unchecked\")public &lt;T&gt; T bind(T target) { this.target = target; // 返回一个被代理对象 return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);} 然后运行 public static void main(String[] args) { // 被代理的对象 Hello hello = new HelloImpl(); ProxyHandler proxyHandler = new ProxyHandler(); Hello helloProxy = proxyHandler.bind(hello); helloProxy.say();} 结果还是一样的。JDK动态代理实现比较复杂，之后的文章再解析源码。 对比动态代理和静态代理对比一下动态代理和静态代理，这么看着可能会觉得动态代理好复杂，还不如用静态代理呢。但是我们思考下要往Hello接口中加一个新的方法时，静态代理会牵涉到什么。 首先得改接口 其次要改实现类 最后要改代理类 要是加的功能多了，就是一次更新风暴，反之对比动态代理。动态代理只需要改接口和实现类，而我们的代理类是稳定不变的。这已经是很大优势了。Spring5前的中的AOP就是基于JDK的动态代理实现的。","link":"/使用JDK-dynamic-proxy实现动态代理/"},{"title":"使用CGlib实现动态代理模式","text":"前言关于代理模式和使用JDK dynamic proxy实现的动态代理模式，已经在使用JDK dynamic proxy实现动态代理模式写过了，也说了Spring5之前使用的代理就是JDK默认的动态代理。然后我自己最近也在写一个框架——Agito。在自己实现AOP特性的时候，感觉使用JDK自带的动态代理并不容易实现我的需求，所以在技术选型的时候，我选择了CGlib这个字节码增强利器来实现动态代理。 封装一个CGlib proxy使用的话，CGlib功能比JDK自带的要更强，JDK自带的动态代理只可以对实现了某个接口的对象进行增强。但是CGlib层级相当于方法拦截。还是举一个例子。对于一个没有实现接口的类，有一个say()方法 public class HelloImpl { public void say() { System.out.println(\"Hello world\"); }} 然后有一个CGlibProxy实现了CGlib中的MethodInterceptor接口，然后重写了intercept方法，这个和JDK自带的很像 public class CGlibProxy implements MethodInterceptor { private static CGlibProxy cGlibProxy = new CGlibProxy(); public static CGlibProxy getInstance() { return cGlibProxy; } @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { before(); Object result = methodProxy.invokeSuper(obj, args); after(); return result; } private void after() { System.out.println(\"finished\"); } private void before() { System.out.println(\"start\"); } @SuppressWarnings(\"unchecked\") public &lt;T&gt; T getProxy(Class&lt;T&gt; cls) { return (T) Enhancer.create(cls, this); }} 然后用泛型封装一下调用时候的方法getProxy，然后在内部封装一个单例(线程不安全)，使用一个main调用一下 public static void main(String[] args) { HelloImpl enhancedHello = CGlibProxy.getInstance().getProxy(HelloImpl.class); enhancedHello.say();} 得到的结果就是 startHello worldfinished 这就是CGlib的最小实践。之后在框架实现AOP特性的时候，也会高强度用到动态代理，到时候可以补充一些具体的例子。","link":"/使用CGlib实现动态代理模式/"},{"title":"前后端分离单页应用开发——王者荣耀手机端复刻(后台篇)","text":"聊聊前后端分离架构先来写一下我理解的前后端分离。再说前后端分离架构之前，不得不提两个已经略显过时了的名词，就是B/S架构(Browser， Server)和C/S架构(Client，Server)。这两个有着本质区别的架构方式，也是传统软件工程中常常使用的架构方式。 对于B/S架构来说，就是客户端为浏览器，浏览器负责渲染从服务端传递过来的一些HTML，CSS，Javascript代码，也就是说，所有的代码都是托管在服务端而不是浏览器中，浏览器只是起到了执行代码和一些其它作用，而在早期的软件工程中，也确实是这样的，JavaScript解释引擎决定了这个浏览器的使用体验，例如Google的V8引擎，Safari的webkit引擎，这就是早期浏览器的基本使用。 对于C/S架构来说，比较典型的就是像Office之类的桌面应用，它不依赖于浏览器，而是直接在你下载后，大部分的代码都是跑在你自己的操作系统上。 这么看来B/S架构和C/S架构其实是有非常大的区别的。他们代码的储存方式不同，运行的环境不同。但是事实上，在HTML5和Node出现的推动下，出现了非常多的Api,使得网页可以通过JavaScript做到越来越多原生的功能，例如文件操作，Notification，Canvas等功能，具体可以见下图 于是你会发现B/S和C/S之间看起来不可逾越的鸿沟被打破了，尤其是出现了Angular，React，Vue这些框架后，你会发现使用这些框架写出来的应用程序，不像是网页，而应该是一个单页应用，动态重写的方式取代了重新加载。他们在一开始加载的时候就把所有代码下载到本地，前端开发人员也不是写HTML，CSS，JS等界面的人员了，准确的来说，他们开发的叫做App。同时一些GUI框架的出现，比如Cordova,Electron(Vscode，Linux版微信)，使得前端的技术栈越来越广，这也是为什么有一句玩笑话叫做”能被JS重写的终将被JS重写”。 所以对于现在的软件开发人员来说，前后端分离项目和服务器渲染视图项目已经成为如今的现代软件工程的分类标准之一了。而我认为前后端分离比较大的优点就是解耦。 这一段主要是写写我对前后段分离的理解，我花了一周左右写的这个复刻王者荣耀后台管理的单页面应用也就是使用Vue+Node.js开发的前后端分离项目，之所以没有使用Java做后端的原因是因为做这个项目主要目的是为了学习Vue，而java后端写起来真的是太烦了。 主要功能 后台管理的登陆 jwt鉴权 后台的增删改查 技术栈 express vue-cli element-ui axios bcrypt jsonwebtoken 项目地址项目地址 : KingOfGlory 值得注意的知识点 Vue数据双向绑定可能会出现数据更新后无法实时显示 解决办法: Object.assign({}, model, data) this.$set(model, “field”, data) export default xxx对应的是import xxx from “xxxx”, module.exports = xxx() {}对应的是require(“xxx”)，前者是ES6的方法，后者是ES5的方法，但是两者在一个文件中不能混用，否则会报错误 Cannot assign to read only property &apos;exports&apos; of object &apos;#&lt;Object&gt;&apos; 我在这里栽了大坑，最后是查issue查到的，可以看图意思就是代码没有问题，就是require()和export default可以混用，但是import和module.exports不能混用。 在Vue的原型链上绑定一个axios实例，可以使用更方便哦 设置全局方法 Vue.mixin({ methods: { xxx() { return xxx; } }}) axios设置拦截器(以下http是一个axios实例) http.interceptors.response.use(res =&gt; {return res;}, err =&gt; {Vue.prototype.$message({ type: \"error\", message: err.response.data.message, })if (err.response.data.status === 401) { router.push(\"/login\");}return Promise.reject(err);});// 请求头上加入token http.interceptors.request.use(function (config) { config.headers.Authorization = \"Bearer \" + localStorage.token; return config;}, function (err) { return Promise.reject(err);}) Vue router设置导航守卫 router.beforeEach((to, form, next) =&gt; { // judge something next()}) Vue路由的meta的isPublic属性，requiresAuth属性的设置，以及路由的参数props属性的发送与接收","link":"/前后端分离单页应用开发/"},{"title":"使用枚举来定制通用的异常处理机制","text":"在我们开发一款应用时，往往会需要处理许许多多的Exception，有时候你需要把定制一些异常然后抛出，并且有些异常是需要用户知道的。这个时候手动写异常信息就显得非常的没有复用性。我们往往可以通过Enum来实现这一复用异常的需求。 栗子假设我需要为一个Web应用定制异常，我们需要为其返回许许多多不同的错误信息，这个时候我想到的是建一个Enum类，然后到时候需要某一类异常信息从其中选取一个实例就可以了。关于使用枚举类型的一些好处，其实文章写的已经很好了。下面放一下代码示例 由于枚举对象中需要message和code属性，那么我打算写一个接口，下面的枚举类需要实现这个接口 package top.ayang818.community.community.Exception;public interface ICustomizeErrorCode { String getMessage(); Integer getCode();} 然后使用一个enum类去实现这个接口，并添加我们需要的枚举值 package top.ayang818.community.community.Exception;public enum CustomizeErrorCode implements ICustomizeErrorCode { QUESTION_NOT_FOUND(4041, \"你查找的问题不在了\"), TARGET_NOT_FOUND(4042, \"未选中任意问题或评论进行回复\"), NONE_LOGIN(4221, \"请先登录\"), SYSTEM_ERROR(5001, \"服务器错误\"), TYPE_NOT_FOUND(4043, \"评论不存在或类型错误\"), COMMENT_NOT_FOUND(4043, \"评论不存在\"), ; private String message; private Integer code; CustomizeErrorCode(Integer code, String message) { this.message = message; this.code = code; } @Override public String getMessage() { return message; } @Override public Integer getCode() { return code; }} 最后定义一个继承了runTimeException的exception，接受的参数就是这个第二段代码实现的枚举类的某个值 package top.ayang818.community.community.Exception;public class CustomizeException extends RuntimeException{ private String message; private Integer code; public CustomizeException(ICustomizeErrorCode errorCode) { this.message = errorCode.getMessage(); this.code = errorCode.getCode(); } @Override public String getMessage() { return message; } public Integer getCode() { return code; }} 由于我是使用spring boot来写这个项目的，所以我是用@ControllerAdvice来实现接收抛出的错误信息并返回至页面的 package top.ayang818.community.community.Advice;import com.alibaba.fastjson.JSON;import org.springframework.http.HttpStatus;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.context.request.WebRequest;import org.springframework.web.servlet.ModelAndView;import top.ayang818.community.community.DTO.ResultDTO;import top.ayang818.community.community.Exception.CustomizeErrorCode;import top.ayang818.community.community.Exception.CustomizeException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.xml.transform.Result;import java.io.IOException;import java.io.PrintWriter;@ControllerAdvicepublic class CustomizeExceptionHandler { @ExceptionHandler(Exception.class) ModelAndView handle(HttpServletRequest request, Throwable ex, Model model, HttpServletResponse response) throws IOException { String contentType = request.getContentType(); if (\"application/json\".equals(contentType)) { ResultDTO resultDTO = new ResultDTO(); if (ex instanceof CustomizeException) { resultDTO = ResultDTO.errorOf((CustomizeException) ex); } else { resultDTO = ResultDTO.errorOf(CustomizeErrorCode.SYSTEM_ERROR); } response.setContentType(\"application/json\"); response.setStatus(200); response.setCharacterEncoding(\"UTF-8\"); PrintWriter writer = response.getWriter(); writer.write(JSON.toJSONString(resultDTO)); writer.close(); return null; } else { if (ex instanceof CustomizeException) { model.addAttribute(\"message\", ex.getMessage()); } else { model.addAttribute(\"message\", CustomizeErrorCode.SYSTEM_ERROR.getMessage()); } return new ModelAndView(\"error\"); } }}","link":"/使用枚举来定制通用的异常处理机制/"},{"title":"浅析分布式唯一ID生成算法——snowflake的实现","text":"开头先放一个snowflake的实现——仓库地址 分布式唯一Id是什么分布式唯一Id其实是一个分布式系统里面的一个不可或缺的元素，他一般具有如下几个特性 同一业务的全局唯一性(globally unique) 包含时间信息(timestamp) 递增有序性(incremented and ordered) 分布式唯一Id有什么用这样一个分布式唯一Id，在一个分布式系统中的作用都有些什么呢。 举个例子，比如说业务量大了要做分库分表了，拿MyCat这个中间件举例，你对接了MyCat这个中间件后，你是接触不到MyCat后面被取余策略或其他策略分离的表的。MyCat呈现给你的仍然是一张表，但是却是分离的表的合并。 那这个时候你后面的数据库的主键要是还是和单机的策略一样，仍然是普通的auto_increment 1的话，你的分割后的每张表都会有重复的Id。比如说有一组订单表order_1, order_2 对于order_1，有 id message 1 x 2 xx 对于order_2，有 id message 1 xxx 2 xxxx 但是MyCat呈现给你的视图却是order id message 1 xxx 2 xxxx 1 x 2 xx 由于你的应用程序对接的是MyCat，这样你的根据Id查询的策略就会出现很大的问题 select from order where id = 1; 这样一条筛选居然可以有两个结果，这就意味着一个订单号对应着两个交易，这在业务上显然是不符合实际的。这个时候我们就需要分布式唯一Id来解决这个问题。 如何实现一个分布式唯一Id最简单的实现——UUIDUUID.randomUUID().toString(); 关于UUID.randomUUID()中一些有意思的点的还可以看看我的这篇文章使用0xff来保证二进制补码的一致性 优点 : 简便缺点 : 无序非递增，对于数据库常用的B+树这种数据结构，插入的性能会比较差 数据库主键自增使用数据库主键自增的操作也很简单，假设有三个数据库，分别是db1.db2,db3 那么可以这么设置 数据库 起始id 自增不长 db1 1 3 db2 2 3 db3 3 3 他们的id%3分别为1，2，3.不会重复。这种做法的优缺点如下 优点 : 操作简单缺点 : 数据库容易成为性能瓶颈 一旦某一个数据库宕机了，整体的可用性就下降了 snowflake算法实现snowflake算法生成的ID结构并不复杂，总共有64位。 其中一共有四部分 第一位，占用1bit，其值始终为0，没有实际作用 时间戳，占用41bit，精确到毫秒，总共可以容纳约140年的时间 工作机器ID，占用10bit，其中高位5bit是数据中心ID，地位5bit是工作节点ID，最多可以容纳1024个节点 序列号，占用12bit，这个值可在同一毫秒同一节点上从0开始不断累加，最多可以累加到4095。 所以是Snowflake在同一毫秒内最多可以生成1024 * 4096 = 1 &lt;&lt; 22 = 4194304 snowflake的代码实现我自己也写一遍，已经贴在了文章的开头。 那么snowflake算法的优缺点都有什么呢 优点 ID不依赖于第三方服务，而是依赖于各个高可用的服务节点，具备高性能与高可用特性 ID的趋势是递增的，插入B+树这一数据结构的性能较好。 缺点 ID的生成依赖于工作机器的系统时钟，一旦系统时钟出现了回拨，就可能会导致ID冲突或者ID乱序。","link":"/写写分布式唯一ID-snowflake算法的实现/"},{"title":"好文分享","text":"广告技术 由于第一份工作是在字节的广告商业化部门，所以对于广告以及变现这一方向有了一些涉猎和理解 万字长文——互联网广告到底是如何运行的？ PGC, UGC, OGC 区别 UGC：User-generated Content的缩写，用户生产内容。又作UCC。 PGC：Professionally-generated Content的缩写，专业生产内容。 OGC：Occupationally-generated Content，品牌生产内容。 以快手和抖音作对比，快手推送的短视频偏向于UGC，这样的短视频更加多元下沉，对于中尾部的创作者来说更加友好，这也是快手让人感觉接地气的原因~。 而抖音更偏向于头部达人，头部达人的作品曝光率占比非常高，他们的创作水平/专业化程度也非常高，用户看到的内容PGC占比较多，所以大部分人感觉抖音的视频质量较高，内容更酷炫。 OGC内容就有很多例子，比如虎嗅网上的专业作者，他们生产专业的内容，平台为其付费，这类内容的目的在于从你的口袋里掏出钱，当然这部分内容的质量也是最高的的。","link":"/好文分享/"},{"title":"前后端分离单页应用开发——王者荣耀手机端复刻(技术篇)","text":"前言今天差不多把整个仿站项目做好并部署好了，除了一页前端界面没有写(界面太复杂，写的我心累)。本来这个项目是跟着一个教程写的，但是在看了几节课觉得看视频太拖拉了，然后就基本上自己写了。可能有一些前端组件的设计不太专业，但是我自我感觉复用性还是勉强可以接受的。但是项目中的CSS的代码确实存在很大程度的冗余。 技术点(踩坑点) Vue中使用自定义组件 Vue.component(\"Tag-Name\", component) 使用 &lt;router-link class=\"nav-link\" tag=\"div\" to=\"/\"&gt;首页&lt;/router-link&gt; 在单页面中跳转。 使用&lt;router-view&gt;&lt;/router-view&gt; 进行子路由的跳转，注意这里的跳转在不修改nginx的时候可以使用 $router.push(\"/xxx\") 若是使用a标签的链接并且vue-router的mode不是hash而是history是，在部署时会出现链接失效的状况，或者刷新后返回404，那是因为在history模式下，只是动态的通过js操作window.history来改变浏览器地址栏里的路径，并没有发起http请求，但是当我直接在浏览器里输入这个地址的时候，就一定要对服务器发起http请求，但是这个目标在服务器上又不存在，所以会返回404。 组件插槽的使用，这个使用其实很简单，在组件中写&lt;slot&gt;&lt;/slot&gt; 然后使用这个组件标签后，直接在里面写内容就可以了 组件之间数据传输，写组建时同样是使用props来接收信息，然后用组件标签的时候使用属性传递消息。 组建插槽的数据通信，对于一个组件来说，他的自身的数据是封闭的，如果其它视图想要通过插槽使用这个组件中传递出来的信息，可以这么写 &lt;slot name=\"items\" :contentData=\"item\"&gt;&lt;/slot&gt; 使用name命名插槽，:dataname绑定传输的数据，接收的时候可以这么使用 &lt;template ##items=\"{contentData}\"&gt;&lt;/template&gt; 我一开始看文档的时候，直接看晕了，什么东西传来传去的 后端数据的批量选择，其实这个map和filter是很容易理解的，但是emmm，层级嵌套一多真的晕，这里分享一段代码，写这里的时候没理清数据结构，绕晕死，估计还有可以优化的空间。router.get('/news/list', async (req, res) =&gt; { const news = await Category.find().where({ name: \"新闻资讯\" }); // 类别 const type = await Category.find().where({ parent: news }); const article = await Article.find(); const dto = type.map(item =&gt; { // 筛选同一类别的文章 let articleList = article.filter(el =&gt; el.categories.includes(item._id)).map(em =&gt; { return { categoriesName: item.name, title: em.title, date: em.updatedAt.getMonth()+\"/\"+em.updatedAt.getDay(), id: em._id, } }) return { name: item.name, newsList: articleList } }) res.send(dto); }) 一点感受通过复刻一个项目让我对业务的理解提升很大，Vue学到这里也差不多是能用了。接下来就回归我的老本行啦。","link":"/前后端分离单页应用开发——王者荣耀手机端复刻-技术篇/"},{"title":"学习计划安排","text":"How to learn python as a new beginner?Import it and run it! Keep coding!Some Tips 由于我也是个大二的学生，所以如果对编程感觉比较迷茫，可以看看我的博客以及github，可以参考一下我大一是怎么学习编程的以及学习什么的，希望也能从我的博客中学习一些东西。 博客地址 github地址 常用工具的安装 GoogleChrome：选课必备浏览器嗷！其实用来做开发也是超级好用 科学上网插件地址：提取码643q 迅雷：下载一些软件的必备加速器！ Mircrosoft Visual Studio Code：吹爆宇宙第一文本编辑器！ Anaconda：一个好用的包管理工具! Docker：(可以先不装，需要windows专业版开启Hyper-V虚拟机)：容器化工具，加速应用的部署，方便应用的使用。 基础知识 python基础：廖雪峰的博客 数据类型与变量 字符串与编码 使用list和tuple 条件判断语句 循环 使用dict和set 函数式编程 文件读写 模块 学习完上面的知识，你就可以自己写一些稍微复杂的程序了。 使用git以及github进行代码的托管 使用markdown语法写博客(强烈建议每个学习技术的人养成写博客的习惯),推荐几个不错的博客社区 CSDN，我自己的博客也在CSDN上，但是广告有点多，可以装一个ABP广告拦截插件，自己装了科学上网插件后就可以去谷歌的插件市场下载了。 博客园，博客优质内容比CSDN多，但是界面比较复古。 掘金，也是我个人看的比较多的博客。 StackOverFlow，类似于知乎的国外IT问答社区，内容质量往往比较高，也是个人常看。 思否，里面的内容比较新，这个算是我最喜欢的社区了。 简单的爬虫的使用(使用request这个网络请求库, lxml这个HTML和XML解析库])。 爬虫下来数据的处理，使用pandas存入excel或存入数据库。 进阶知识 使用docker安装mongodb数据库并使用。 windows下安装了docker之后可以去尝试着使用linux版本的docker，顺便熟悉一下linux的一些操作。 将爬虫爬下来的数据进行一些分析，可以使用numpy这个科学计算库联合matplotlib这个绘图库来将数据可视化，当然也可以直接使用excel的自带绘图。 其它方向 相信在学习完以上的知识后，你已经对编程这个概念有了一个基本的了解了，如果想要继续学习编程的话，可以选择下面几个方向 机器学习，网易云课堂上有吴恩达教授的深度学习课程，也可以学习一些常用的深度学习框架PyTouch,Tensorflow。并学习其中的机器学习算法。 Web开发，使用Python做web开发的话，比较常用的框架是Django 和 FlaskDjango和Flask的难度都不高，都可以比较容易上手，我这里也有使用Django写的一些小Demo，可以在我的github上找到。 这两个方向都算是我学习过的方向了，我现在的主力语言主要是Java，Nodejs，python，有什么这些方面的问题都可以一起交流。","link":"/学习计划安排/"},{"title":"临时博客","text":"本来已经有了一个博客博客地址了，但是还是打算使用这个hexo快速搭建的博客写一下下届数据处理小组的新生教程。","link":"/博客搬家/"},{"title":"学习阶段总结","text":"学习阶段总结学了这么久，感觉其实对Java的学习已经进入了一个快乐的快车期了，许多东西都已经串联到了一起。这里我想列举一下我学习Java的一些资料。 Java核心技术·卷一 这本书算是给我从Python转到Java快速打了基础吧，但是其实感觉这本书没用的东西也挺多的，想里面的Swing啥的我都选择了跳过。但是书的质量还行 Spring Boot，Spring MVC，Mybatis实战项目 Github上的阿里员工的开源项目，我对着学习了并且自己复刻了一个类似的项目(计划开源)。这个项目让我对于系统的开发，源码的阅读，以及数据库的设计，以及IDEA的使用，Git的一些高级操作都更加熟练 Bilibili上的一些硬核公开课 Debug能力增强，毕竟看别人代码看多了 网易云课堂·高级Java开发公开课 这里的课让我对高并发的处理，一些并发包源码，手写XX锁的编程能力，以及对于解决并发问题的思维有了一个体系化的认知，算是我从Java初级成长到Java中级的一个良好过渡吧 阿里巴巴·Java开发手册·第四版 这本书质量真的很好，属于常读常新的一本书，里面虽然并没有很深的知识，都是一个个的知识点，但是每个知识点都深究下去，都会挖到一些底层的有意思的东西。里面除了Java还有MySQL的一些知识，让我对于MySQL的理解也上升了一个高度，通过这本书我还通过了阿里云的Java技能认证 Java并发编程实战 这本书的话是我系统学习Concurrent包源码，以及处理并发机制的书籍。书籍的内容有些繁琐，有些也很抽象。但是我也仔仔细细的看了一遍，这本书让我对Java线程，并发包，以及并发工具类等的使用熟悉了很多，并且搭配着学习了很多设计模式 深入理解Java虚拟机·JVM高级特性与最佳实践 有一说一，这本书对我帮助很大，它在一定程度上串联了我看过的一些零零散散的博客，但是有些过于涉及字节码等底层的内容我并没有仔细去看，只草草翻了一下。我仔细的看了一下的几个部分。估计这本书我之后还会多去读几遍 Java内存区域与内存溢出异常 垃圾收集器与内存分配策略 .class文件结构 虚拟机类加载机制 编译期优化 Java内存模型与线程(volatile可以贯穿这个) 线程安全与锁优化 MySQL 最简单的SQL语句，我在菜鸟教程上学习 SQL优化，大概是MySQL官方文档的Optimize章节搭配博客食用 阿里巴巴Java开发手册 —————————分割线 2020/2/11—————————- 接下来关于Kotlin的部分，是见过的比较好的学习资源（比Kotlin的官方文档好多了），这给我快速上手Kotlin代码提供的很好的知识总结 Kotlin 的变量、函数和类型 Kotlin 里那些不是那么写的——面向对象部分 Kotlin 里那些更方便的——甜甜的语法糖 Kotlin 的协程-1 Kotlin 的协程-2 协程的挂起 Kotlin 的协程-3 协程的非阻塞式","link":"/学习阶段总结/"},{"title":"巧妙使用位运算","text":"巧妙使用位运算 &amp;&amp; Leetcode 421 Maximum XOR of Two Numbers in an Array 部分参考 ： 全网把Map中的hash()分析的最透彻的文章，别无二家。 在学习ConcurrentHashMap的分段锁机制时，对于根据hashcode的一些操作结果，分配锁数组中的锁对象的机制不是很理解。于是看了看开头提到的文章，确实理解了很多。中间看着有些磕磕绊绊，主要是不是很明白其中一些位运算道理在做什么。举个栗子 在使用HashMap的indexFor()将hash生成的整形转化为数组下标的时候使用了如下位运算 static int indexFor(int h, int length) { return h &amp; (length - 1);} 但是推理后可以发现 在HashMap中由于length始终为$2^n$, 那么假设n=3，那么length=8，原式子就为h &amp; 7, 8转化为二进制是1000，那么7就是0111。我们拿h和0111做&amp;操作，那么就是相当于截取了h的后三位二进制数。从二进制的角度来看，h/8 == h &gt;&gt; 3, 而移掉的部分其实就是h%8得到的余数。所以代码中的h &amp; (length - 1) == h % length。所以我们其实可以得出这样一个结论—— h % (2n ) == h &amp; (2n - 1) JDK中类似这样做了位运算优化的代码还有很多，位运算主要有 &gt;&gt; 右移 &lt;&lt; 左移 &gt;&gt;&gt; 无符号右移，空位不管正负以0补齐，正数时等于&gt;&gt;，负数时会将负数变为正数 &amp; 相当于单位数乘法 | ^ 相当于不进位加法 然后又去做了一下Leetcode上关于位运算的题——421. 数组中两个数的最大异或值 给定一个非空数组，数组中元素为 a0, a1, a2, … , an-1，其中 0 ≤ ai &lt; 231 。 找到 ai 和aj 最大的异或 (XOR) 运算结果，其中0 ≤ i, j &lt; n 。 你能在O(n)的时间解决这个问题吗？ 示例: 输入: [3, 10, 5, 25, 2, 8] 输出: 28 解释: 最大的结果是 5 ^ 25 = 28. 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/maximum-xor-of-two-numbers-in-an-array著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目要求时间复杂度在O(n)，所以暴力肯定是不可以的，思考一下，可以得出以下三个结论 若a ^ b = c, 那么c ^ a = b，例如1 ^ 1 = 0, 0 ^ 1 = 1 既然要求最大的结果，对于二进制来说，越高位为1，这个数就越大 不妨从左到右通过取前缀来查看每位最大可以取到1还是0 我们使用掩码与数字做&amp;运算来得到前缀 1000 &amp; 0011 = 0000 1000 &amp; 0110 = 0000 1000 &amp; 0101 = 0000 1000 &amp; 1101 = 1000 1000 &amp; 0010 = 0000 将前缀放到一个集合中，然后假设答案res在该位为1，使用该位为1的答案和集合中的前缀做异或，要是答案还在集合中，那么该位可以为1，否则就不可以(根据3)。基本思路就是这样。代码如下 class Solution { public int findMaximumXOR(int[] nums) { int res = 0; int mask = 0; Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); for (int i = 31; i &gt;= 0; i--) { mask = mask ^ (1 &lt;&lt; i); for (int j = 0; j &lt; nums.length; j++) {// 取前缀32-i位 set.add(mask &amp; nums[j]); } int temp = res ^ (1 &lt;&lt; i); for (Integer num : set) { if (set.contains(num ^ temp)) { res = temp; } } set.clear(); } return res; }}","link":"/巧妙使用位运算/"},{"title":"寒假开始啦! 开始进行Kugga的基础设施建设了!","text":"寒假博客应该不怎么会更新了。我的Kugga计划也提上日程了。寒假里的一些知识记录部分会以文档的形式更新在Kugga-wiki上面，感兴趣也可以关注下。","link":"/寒假开始啦-开始进行Kugga的基础设施建设了/"},{"title":"将Hexo博客从github迁移到gitee","text":"将Hexo博客从github迁移到gitee由于原来基于Github Page的Hexo博客访问速度实在是太慢了，我把博客迁移到了Gitee上，加载速度算是大大提高了。下一步可能就是等这段时间忙完后，再把博客迁移到我的新的企鹅云的服务器上。 小插曲在把SSH公钥部署到Gitee上的时候，不小心把自己的私钥给修改了。导致我GitHub都没法Remote Push。这里记录一下重新创建SSH Key的命令 ssh-keygen -t rsa -C &quot;your_email@example.com&quot;","link":"/将Hexo博客从github迁移到gitee/"},{"title":"常用的一些算法板子(持续更新)","text":"持续更新的一些算法板子 更详细的题目或题解可以查看我的刷题仓库 快速幂public static long quickPow(long x, long n) { long res = 1L; while (n &gt; 0) { if ((n &amp; 1) == 1) { res*=x; } x *= x; n &gt;&gt;=1; } return res;} 并查集int[] list = new int[205];public int findCircleNum(int[][] M) { for (int i = 0; i&lt;list.length; i++) { list[i] = i; } for (int i = 0; i &lt; M.length ; i ++) { for (int j = 0; j &lt; M.length; j++) { if (M[i][j] == 1 &amp;&amp; i != j) { merge(i, j); } } } int ans = 0; for (int i = 0; i&lt; M.length ; i++) { if(list[i] == i) { ans++; } } return ans;}// 合并连通块public void merge(int x, int y) { int fx = find(x); int fy = find(y); if (fx != fy) { list[fx] = list[fy]; }}// 查找祖先分类public int find(int x) { while (x != list[x]) { x = list[x]; } return x;} 字典树class TrieTree { TreeNode root; public TrieTree() { root = new TreeNode(); } public int insert(String str) { char[] xhars = str.toCharArray(); TreeNode tmp = root; boolean newstr = false; for (int i = xhars.length-1; i &gt;= 0; i--) { if (tmp.children[xhars[i] - 'a'] == null) { tmp.children[xhars[i] - 'a'] = new TreeNode(); newstr = true; } tmp.children[xhars[i] - 'a'].val = xhars[i]; tmp = tmp.children[xhars[i] - 'a']; } return newstr ? str.length() + 1 : 0; }}class TreeNode { char val; TreeNode[] children; public TreeNode() { children = new TreeNode[26]; }} DFS(可使用栈实现)// 行数private static int x;// 列数private static int y;// 目标矩阵private static char[][] grid = new char[105][105];// 八个不同方向private static int[][] direcion = new int[][]{{0, -1}, {1,-1}, {1,0}, {1,1}, {0, 1}, {-1, 1}, {-1, 0 }, {-1, -1}};public static int dfs(int i, int j) { if (grid[i][j] == '@') { grid[i][j] = '*'; for (int i1 = 0; i1 &lt; direcion.length ; i1++) { if (i+direcion[i1][0] &gt;= 0 &amp;&amp; j+direcion[i1][1] &gt;= 0 &amp;&amp; i + direcion[i1][0] &lt; x &amp;&amp; j + direcion[i1][1] &lt; y) { dfs(i+direcion[i1][0], j+direcion[i1][1]); } } return 1; } return 0;} BFS(可使用队列实现)public void leafSimilar(TreeNode root1, TreeNode root2) { Queue queue1 = new LinkedBlockingQueue&lt;&gt;(); List&lt;TreeNode&gt; list2 = new ArrayList&lt;&gt;(); bfs(queue1, list1, root1); list1.forEach(item -&gt; {System.out.println(item.val);});}public void bfs(Queue&lt;TreeNode&gt; queue, List&lt;TreeNode&gt; list,TreeNode node1) { queue.offer(node1); while (queue.peek() != null) { TreeNode node = queue.poll(); if (node.left == null &amp;&amp; node.right == null) { list.add(node); } if (node.left != null) { queue.offer(node.left); } if (node.right != null) { queue.offer(node.right); } }} 二分(旋转二分，搜左边界，搜右边界)参考文章 public int left(int[] nums, int target) { int left = 0; int right = nums.length; if (right == 0) { return -1; } int mid = -1; // 先算左边界 while (left &lt; right) { mid = left + (right - left) /2; if (nums[mid] &lt; target) { left = mid + 1; } else if (nums[mid] &gt; target) { right = mid; } else if (nums[mid] == target) { right = mid; } } return left &lt; nums.length &amp;&amp; nums[left] == target ? left : -1;} public int right(int[] nums, int target) { int left = 0; int right = nums.length; if (right == 0) { return -1; } int mid = -1; while (left &lt; right) { mid = (left + right) / 2; if (nums[mid] == target) { left = mid + 1; // 注意 } else if (nums[mid] &lt; target) { left = mid + 1; } else if (nums[mid] &gt; target) { right = mid; } } return left -1 &gt;=0 &amp;&amp; left -1 &lt; nums.length &amp;&amp; nums[left - 1] == target ? left -1 : -1;} 滑动窗口public int lengthOfLongestSubstring(String s) { int ans = 0; HashMap&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int leftWindow=0,rightWindow = 0; for (; rightWindow &lt; s.length(); rightWindow++) { if (map.containsKey(s.charAt(rightWindow))){ leftWindow = Math.max(leftWindow, map.get(s.charAt(rightWindow))+1); } map.put(s.charAt(rightWindow), rightWindow); ans = Math.max(ans, rightWindow-leftWindow+1); } return ans;} 背包public class Main { public static void main(String[] args) { Scanner scan = new Scanner(System.in); while (scan.hasNext()) { int num = scan.nextInt(); int size = scan.nextInt(); int[] sizeList = new int[num+1]; int[] valueList = new int[num+1]; int[][] dp = new int[num+1][size+1]; for (int i = 1 ; i &lt;= num ; i++) { sizeList[i] = scan.nextInt(); valueList[i] = scan.nextInt(); } dp[0][0] = 0; for (int i = 1; i &lt;= num; i++) { for (int j = 1; j &lt;= size ; j++) { if (j &gt;= sizeList[i]) { dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-sizeList[i]]+valueList[i]); } else { dp[i][j] = dp[i-1][j]; } } } System.out.println(dp[num][size]); } }} 快速排序 这里需要注意的是，由于 quickSort(l, right, array)quickSort(right+1, r, array) 我们需要让l和right的距离缩小（尤其是当只剩下两个元素的时候，并且这两个元素相等），所以for array[right] &gt;= sig &amp;&amp; left &lt; right需要当数值和标兵相等时，right仍然可以变小，这样就不会导致死循环 package mainimport ( \"fmt\")func main() { var array []int array = append(array, 5, 1, 1, 2, 0, 0) quickSort(0, len(array)-1, array) fmt.Println(array)}func quickSort(left int, right int, array []int) { if right-left &lt; 1 { return } l, r := left, right fmt.Println(l, r) fmt.Println(array[l], array[r]) sig := array[left] for left &lt; right { for array[right] &gt;= sig &amp;&amp; left &lt; right { right-- } array[left] = array[right] for array[left] &lt; sig &amp;&amp; left &lt; right { left++ } array[right] = array[left] } array[right] = sig quickSort(l, right, array) quickSort(right+1, r, array)} 归并排序 首先分，其次治，说的通俗点就是先调用递归，再进行计算。 递归的条件是区间只有1个或2个数，让他们有序。 其次是治，使用一个临时数组，里面记录一段有序的区间，结束后将其拷贝到原数组中。 import java.util.Arrays;class Solution { public int[] mergeSort(int[] nums) { // want to get two sorted list int[] tmp = new int[nums.length]; forkJoin(nums, 0, nums.length - 1, tmp); return nums; } public void forkJoin(int[] nums, int start, int end, int[] tmp) { if (end - start &lt;= 1) { if (nums[end] &lt; nums[start]) { swap(nums, start, end); } return; } forkJoin(nums, start, (start + end) &gt;&gt; 1, tmp); forkJoin(nums, ((start + end) &gt;&gt; 1) + 1, end, tmp); int idxl = start; int idxr = ((start + end) &gt;&gt; 1) + 1; int total = start; for (; total &lt;= end; ) { if (nums[idxl] &gt; nums[idxr]) { tmp[total] = nums[idxr++]; total++; } else { tmp[total] = nums[idxl++]; total++; } if (idxl &gt; ((start + end) &gt;&gt; 1) || idxr &gt; end) { break; } } while (idxl &lt;= ((start+end) &gt;&gt; 1)) { tmp[total++] = nums[idxl++]; } while(idxr &lt;= end) { tmp[total++] = nums[idxr++]; } for (int i = start; i&lt;=end; i++) { nums[i] = tmp[i]; } } public void swap(int[] nums, int a, int b) { int tmp = nums[a]; nums[a] = nums[b]; nums[b] = tmp; } public static void main(String[] args) { int[] list = {3, 1, 6, 2, 4, 2, 5, 9, 8}; System.out.println(Arrays.toString(new Solution().mergeSort(list))); }} 堆排序 选取最后一个非叶子节点，开始n– 堆化 整个数组堆化后，交换第一个和逻辑上堆的最后一个元素。 重复直到堆中只有一个元素。class Solution { public List&lt;Integer&gt; sortArray(int[] nums) { heapSort(nums, nums.length); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int num : nums ) { list.add(num); } return list; } public void heapfy(int[] arr, int root, int length) { if (root &gt;= length) { return; } int left = root*2+1, right = root*2+2; int max = arr[root]; if (right &lt; length &amp;&amp; arr[right] &gt; max) { max = arr[right]; } if (left &lt; length &amp;&amp; max &lt; arr[left]) { max = arr[left]; } if (max != arr[root]) { if (right &lt; length &amp;&amp; max == arr[right]) { arr[right] = arr[root]; heapfy(arr, right, length); } else if (left &lt; length &amp;&amp; max == arr[left]) { arr[left] = arr[root]; heapfy(arr, left, length); } arr[root] = max; } } public void heapSort(int[] arr, int length) { if (length == 1) return; for (int i = length / 2 - 1; i &gt;= 0; i--) { heapfy(arr, i, length); } for (int i = 0; i &lt; arr.length - 1; i++) { length--; swap(arr, 0, length); heapfy(arr, 0, length); } } public void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } public static void main(String[] args) { Solution solution = new Solution(); int[] nums = new int[]{5,1,1,2,0,0}; solution.sortArray(nums); System.out.println(Arrays.toString(nums)); }} TOP-N有大量数据n个，要求取出这组数据中最大的K个值。对于这个问题，解法有很多如排序，不过效率最高的要数最小堆。 做法如下 取出数组的前n个元素，创建长度为n的最小堆。 从n开始循环数组的剩余元素，如果元素(a)比最小堆的根节点大，将a设置成最小堆的根节点，并让堆保持最小堆的特性。 循环完成后，最小堆中的所有元素就是需要找的最大的n个元素。 开根号牛顿迭代法，开n次根对于 一个数 T，要求他的平方根 N，也就是说求 f(x)=N2-T 与 X轴的交点，那么很容易得到这个曲线对应的切线斜率为2N， 那么这条曲线与x轴的交点所在的切线就可以表示为 2N*(x-N)=y-(N2-T)，那么当 y=0时，x=(N-T/N)/2 func Sqrt(x float64) float64 { root := x min := 1e-9 for math.Abs(x-root*root) &gt; min { fmt.Println(time, root) root = (root + x/root) / 2 } return root}","link":"/常用的一些算法板子-持续更新/"},{"title":"彻底搞懂 Git-Rebase","text":"彻底搞懂 Git-Rebase使用 Git 已经好几年了，却始终只是熟悉一些常用的操作。对于 Git Rebase 却很少用到，直到这一次，不得不用。 一、起因上线构建的过程中扫了一眼代码变更，突然发现，commit 提交竟然多达 62 次。我们来看看都提交了什么东西： 这里我们先不说 git 提交规范，就单纯这么多次无用的 commit 就很让人不舒服。可能很多人觉得无所谓，无非是多了一些提交纪录。 然而，并非如此，你可能听过破窗效应，编程也是如此！ 二、导致问题1.不利于代码 review设想一下，你要做 code review ，结果一个很小的功能，提交了 60 多次，会不会有一些崩溃？ 2.会造成分支污染你的项目充满了无用的 commit 纪录，如果有一天线上出现了紧急问题，你需要回滚代码，却发现海量的 commit 需要一条条来看。 遵循项目规范才能提高团队协作效率，而不是随心所欲。 三、Rebase 场景一：如何合并多次提交纪录？基于上面所说问题，我们不难想到：每一次功能开发， 对多个 commit 进行合并处理。 这时候就需要用到 git rebase 了。这个命令没有太难，不常用可能源于不熟悉，所以我们来通过示例学习一下。 1.我们来合并最近的 4 次提交纪录，执行： git rebase -i HEAD~4 2.这时候，会自动进入 vi 编辑模式： s cacc52da add: qrcodes f072ef48 update: indexeddb hacks 4e84901a feat: add indexedDB floders 8f33126c feat: add test2.js# Rebase 5f2452b2..8f33126c onto 5f2452b2 (4 commands)## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like &quot;squash&quot;, but discard this commit&apos;s log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.# 有几个命令需要注意一下： p, pick = use commit r, reword = use commit, but edit the commit message e, edit = use commit, but stop for amending s, squash = use commit, but meld into previous commit f, fixup = like “squash”, but discard this commit’s log message x, exec = run command (the rest of the line) using shell d, drop = remove commit 按照如上命令来修改你的提交纪录： s cacc52da add: qrcodes f072ef48 update: indexeddb hacks 4e84901a feat: add indexedDB floderp 8f33126c feat: add test2.js 3.如果保存的时候，你碰到了这个错误： error: cannot &apos;squash&apos; without a previous commit 注意不要合并先前提交的东西，也就是已经提交远程分支的纪录。 4.如果你异常退出了 vi 窗口，不要紧张： git rebase --edit-todo 这时候会一直处在这个编辑的模式里，我们可以回去继续编辑，修改完保存一下： git rebase --continue 5.查看结果 git log 三次提交合并成了一次，减少了无用的提交信息。 四、Rebase 场景二：分支合并1.我们先从 master 分支切出一个 dev 分支，进行开发： git:(master) git checkout -b feature1 2.这时候，你的同事完成了一次 hotfix，并合并入了 master 分支，此时 master 已经领先于你的 feature1 分支了：3.恰巧，我们想要同步 master 分支的改动，首先想到了 merge，执行： git:(feature1) git merge master 图中绿色的点就是我们合并之后的结果，执行： git:(feature1) git log 就会在记录里发现一些 merge 的信息，但是我们觉得这样污染了 commit 记录，想要保持一份干净的 commit，怎么办呢？这时候，git rebase 就派上用场了。 4.让我们来试试 git rebase ，先回退到同事 hotfix 后合并 master 的步骤：5.使用 rebase 后来看看结果： git:(feature1) git rebase master 这里补充一点：rebase 做了什么操作呢？ 首先，git 会把 feature1 分支里面的每个 commit 取消掉；其次，把上面的操作临时保存成 patch 文件，存在 .git/rebase 目录下；然后，把 feature1 分支更新到最新的 master 分支；最后，把上面保存的 patch 文件应用到 feature1 分支上； 从 commit 记录我们可以看出来，feature1 分支是基于 hotfix 合并后的 master ，自然而然的成为了最领先的分支，而且没有 merge 的 commit 记录，是不是感觉很舒服了。 6.在 rebase 的过程中，也许会出现冲突 conflict。在这种情况，git 会停止 rebase 并会让你去解决冲突。在解决完冲突后，用 git add 命令去更新这些内容。 注意，你无需执行 git-commit，只要执行 continue git rebase --continue 这样 git 会继续应用余下的 patch 补丁文件。 7.在任何时候，我们都可以用 --abort 参数来终止 rebase 的行动，并且分支会回到 rebase 开始前的状态。 git rebase —abort 五、更多 Rebase 的使用场景git-rebase 存在的价值是：对一个分支做「变基」操作。 1.当我们在一个过时的分支上面开发的时候，执行 rebase 以此同步 master 分支最新变动；2.假如我们要启动一个放置了很久的并行工作，现在有时间来继续这件事情，很显然这个分支已经落后了。这时候需要在最新的基准上面开始工作，所以 rebase 是最合适的选择。 六、为什么会是危险操作？根据上文来看，git-rebase 很完美，解决了我们的两个问题：1.合并 commit 记录，保持分支整洁；2.相比 merge 来说会减少分支合并的记录； 如果你提交了代码到远程，提交前是这样的： 提交后远程分支变成了这样： 而此时你的同事也在 feature1 上开发，他的分支依然还是： 那么当他 pull 远程 master 的时候，就会有丢失提交纪录。这就是为什么我们经常听到有人说 git rebase 是一个危险命令，因为它改变了历史，我们应该谨慎使用。 除非你可以肯定该 feature1 分支只有你自己使用，否则请谨慎操作。 结论：只要你的分支上需要 rebase 的所有 commits 历史还没有被 push 过，就可以安全地使用 git-rebase来操作。 七、参考：rebasegit-rebase 使用总结git 中的 rebase操作git-rebase vs git-merge 详解","link":"/彻底搞懂 Git-Rebase/"},{"title":"无状态服务,有状态服务与CAP定理","text":"运维的一些职责 安全 稳定 满负荷 长周期 优于拓展 无状态服务无状态服务包括api服务，订单服务，购物车服务，图片服务，消息队列服务，负载均衡服务。无状态服务指的是，在整个系统运行过程中，在任意时刻，你将他销毁并重新创建一个全新的这种服务，他仍然可以完整的进行之前的工作。这就意味着同一个无状态服务是可以分到不同的计算节点上的。比如说我们可以创建十个API服务，当外部服务请求这个API的时候，我们需要使用反向代理技术(Nginx)，将这些用户请求都代理给负载均衡，负载均衡通过负载均衡算法，例如源地址hash，cookie，或者轮转法来讲这些请求分配给一个随机的计算节点，这样这10个计算节点压力都不会太大！这其实就是经典的无状态服务负载均衡的部署方式，也是运维的满负荷职责体现！而随着服务开的越来越多，服务占用的计算资源也越来越多。那又如何实现优于拓展呢？我们可以在请求量大的时候，将我们的服务缩放到更多的服务，而业务量小的时候，就压缩回一个服务，在这个过程中，我们需要删除或增加大量的计算节点，这会非常麻烦，使用传统的物理机几乎是不可能的，而使用虚拟机事实上也是又非常浪费内存资源。其实最近几年诞生的一些新的技术，比如说容器，kubernetes，他们其实就有这种功能，他们可以根据业务量计算需求自动的缩放你的无状态服务数量。其实这个还涉及到健康监视的内容。这里不细写，因为我自己也不是很了解。 有状态服务有状态服务包括数据库系统，存储系统，这些都是有状态的服务。有状态服务和无状态服务不同，有状态服务比如数据库，你把他之前的数据库删了，然后又创建了一个新的数据库，那你的数据库内容就丢光了！一般为了让服务变成无状态服务，需要在开发层做很多工作，比如说避免使用session。对于有状态服务来说我们一般将服务复制成三四个节点，保证其中一个节点坏了的时候，立刻会有另一个节点顶替上来。而我们要保证多个节点间的数据一致。因为有状态服务是要存住数据的，所以有状态服务是不可以做全局的负载均衡的。不可以有的时候往节点A里写数据，有的时候往节点B里写数据，这就会导致数据的不一致。而我们一般解决的办法是读写分离，其中一些节点只用来写，其中一些节点只用来读，只用来读的节点可以做负载均衡，只用来写的节点则不可以做负载均衡，写的节点在写入数据后要立马进行数据同步，同步给用来读的节点 CAP定理可用性，一致性，分区容忍性不可兼得，假设将一个有状态服务分到了三个节点上，那么就要在满足分区容忍性的前提下，要么放弃可用性，要么放弃一致性，两者不可兼得。放弃可用性就是说当服务需要工作时，要优先保证一致性(三个节点同步数据后返回)；放弃一致性的方法就是优先保证可用性，一个数据节点返回成功信息，就返回数据信息，数据将在后台慢慢同步，可能导致数据不同步","link":"/无状态服务-有状态服务与CAP定理/"},{"title":"序列化动态规划解题技巧","text":"序列化动态规划解题技巧总结序列化动态规划属于动态规划中的基础题，这类题目通常是一组序列。 这类题目一般有一种比较通用的状态转移方程$$dp[i][aa]=Option_1^{i-1}(dp[i-1][bb])+cast_i$$其实这种题目在代码上也有一些小技巧 如果使用递推时间代码，让动态规划有效状态的下表从 1 开始，把下表 0 让给一步决策都没有做的初始状态。通常这样做，可以让边界处理简单不少。 其次是主动转移和被动转移，主动转移是从一个状态去找这个这个状态可以转移到什么状态；被动转移是去找这个状态是由什么状态转移来的。 以Leetcode70 爬楼梯来看，动态规划的做法很简单。我们很容易有一个状态转移方程 dp[1] = 1dp[i] = dp[i-1] + dp[i-2] 那么我们的动态规划代码就很容易写了 class Solution { public int climbStairs(int n) { if (n == 0) return 0; if (n == 1) return 1; int res = 1; int a0 = 1; for (int i = 1; i &lt; n ;i++) { int temp = res; res = a0+res; a0 = temp; } return res; }} 但是就像很多其他动态规划题目一样，要是想不出动态规划怎么做，其实可以使用记忆化搜索来做。 class Solution { int[] dp = new int[2000]; public int climbStairs(int n) { Arrays.fill(dp,-1); return dfs(n); } public int dfs(int num) { if (num == 0) return 1; if (num &lt; 0) return 0; if (dp[num] != -1) return dp[num]; dp[num] = dfs(num-1)+dfs(num-2); return dp[num]; }} 再拿Leetcode198打家劫舍来说，我们设定一个dp数组，dp[i][j]，其中dp[i][0]表示第i间房子不偷时的最大所得，dp[i][1]表示第i间房子偷时我们的最大所得，那么我们很容易得到如下的动态转移方程 dp[0][0] = 0dp[0][1] = nums[0]dp[i][0] = Math.max(dp[i-1][1], dp[i-1][0])dp[i][1] = dp[i-1][0]+nums[i] 代码如下 class Solution { public int rob(int[] nums) { if (nums.length == 0) return 0; int[][] dp = new int[nums.length][2]; dp[0][0] = 0; dp[0][1] = nums[0]; for (int i = 1; i &lt; nums.length; i++) { dp[i][0] = Math.max(dp[i-1][1], dp[i-1][0]); dp[i][1] = dp[i-1][0]+nums[i]; } return Math.max(dp[nums.length-1][0], dp[nums.length-1][1]); }} 那我们需要计算动态规划的时间复杂度怎么办？ 有一个通用的计算方法就是 时间复杂度 = 状态数量 * 后继决策数量 * 转移代价。 部分总结来自 WNJXYK`blog ，Thanks a lot.","link":"/序列化动态规划解题技巧总结/"},{"title":"并发容器","text":"并发容器与同步容器同步容器类包括Vector与HashTable，他们实现线程安全的方法是——将他们的状态封装起来，并会每一个公有方法都是用synchronize进行同步，使得每次只有一个线程可以访问容器的状态。但是同步容器同样存在着不安全因素，所以需要客户端加锁的行为，详情可以看我的上篇博客。而相比对于并发容器来说，同步容器将所有对容器状态的访问都串行化，以保证线程安全性，但是也严重严重降低了并发性。而并发容器是针对多个线程并发访问设计的， 比如使用ConcurrentHashMap来代替HashMap，ConcurrentHashMap实现了ConcurrentMap这一接口，实现了一些computeIfAbset,getOrDefault,putIfAbsent这些方法 Java5中增加了两种容器类型，Queue和BlockingQueue，他的并发容器提供了这么些实现包括，ConcurrentLinkedQueue(传统的FIFO队列)，PriorityQueue(优先队列)。Queue一族不会阻塞，如果队列为空，那么获取元素的操作将返回空值。 BlockingQueue拓展了Queue，增加了可阻塞的插入和获取等操作，也就是阻塞队列。在生产者——消费者这种设计模式下，阻塞队列十分有用。 ConcurrentHashMap和HashMap一样，ConcurrentHashMap也是一个基于散列的Map，但是它使用了一种完全不同的加锁机制来提供更高的并发性和伸缩性，他不是把每个方法都再同一个锁上同步么认识使用一种粒度更细的加锁机制来实现更大程度上的共享，这种机制叫做分段锁在这种机制下 任意数量的读取线程可以并发的访问Map(可见性) 执行读取和写入的线程可以并发的访问Map 一定数量的写入线程可以并发的修改Map 他最终带来的结果是并发环境下将实现更高的吞吐量，而单线程环境下也只会损失很少的性能 ConcurrentHashMap操作由于锁的机制不同倒是无法使用客户端加锁来执行独占访问，但是它也提供了一些原子性的接口，比如实现的ConcurrentMap接口V putIfAbsent(K key, V value);boolean remove(Object key, Object value);boolean replace(K key, V oldValue, V newValue);V replace(K key, V value);V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction)V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) CopyOnWriteArrayList字面意思就是写入时复制，他的线程安全性实现在于，只要正确的发布一个事实不变的对象，那么在访问该对象时就不用再进行进一步的同步。但是每次需要修改该对象的时候，都会创建并重新发布一个容器副本，从而实现可变性。所以事实上再迭代次数远远大于写入次数，可以考虑使用CopyOnWriteArrayList。否则当容器内部的数组数量过大时，会造成比较大的额外开销。可以看下add方法的源码 public boolean add(E e) { synchronized (lock) { Object[] es = getArray(); int len = es.length; es = Arrays.copyOf(es, len + 1); es[len] = e; setArray(es); return true; }}","link":"/并发容器/"},{"title":"浅析Java中的反射机制","text":"作用反射机制属于Java中的常用的高级机制之一，他的功能非常强大，反射机制可以用来 在运行时分析类的能力 在运行时查看对象，如编写一个toString方法供所有类使用 实现通用的数组操作代码 利用Method对象，这个对象很像C++中的函数指针 Class类在运行期间，Java始终为所有对象维护一个被称为运行时的类型标识，这个信息跟踪着每个对象所属的类。虚拟机利用运行时类型信息选择相应的方法执行。然而我们可以使用专门的Java类访问这些信息。保存这些信息的类就被称为Class。关于如何获得这个Class对象有如下方法 getClass方法和它的getName方法Object类中的getClass方法就会返回一个Class类型的实例 import java.util.ArrayList;public class Main { public static void main(String[] args) { ArrayList&lt;String&gt; strings = new ArrayList&lt;&gt;(); System.out.println(strings.getClass()); System.out.println(strings.getClass().getName()); }}&gt;&gt;&gt; class java.util.ArrayList&gt;&gt;&gt; java.util.ArrayList 静态方法forNameClass类的静态方法forName可以获得对应的Class对象 public class Main { public static void main(String[] args) { String string = \"java.util.Random\"; try { Class&lt;?&gt; aClass = Class.forName(string); } catch (ClassNotFoundException e) { e.printStackTrace(); } }} 直接使用.classpublic class Main { public static void main(String[] args) { System.out.println(String.class.getName()); }}&gt;&gt;&gt; java.lang.String 注意其实一个Class对象实际上表示的是一个类型，而这个类型未必是一个类，例如int不是类，但是int.class是一个Class类型的对象 ==实现类对象的比较public class Main { public static void main(String[] args) { String string = \"hello\"; System.out.println(string.getClass() == String.class); }} 使用newInstance()动态创建一个类的实例 使用Class中的newInstance创建一个无参实例 使用java.lang.reflect.Constructor中的newInstance创建一个有参实例public class Main { public static void main(String[] args) { String string = \"java.lang.String\"; try { Object object = Class.forName(string).newInstance(); if (object.getClass() == String.class) { String string2 = (String) object; System.out.println(string2.isEmpty()); } } catch (InstantiationException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (ClassNotFoundException e) { e.printStackTrace(); } }}&gt;&gt;&gt; true 使用反射分析类的能力反射机制最重要的内容就是，检查类的结构，在java.lang.reflect包下，有三个类，Field,Method,Constructor，可以用来查看类的结构，如下一段程序使用这个特性完成了打印一个类的Field，Method,Constructor的功能 import java.lang.reflect.*;import java.util.Scanner;public class Main { public static void main(String[] args) { String name; if (args.length != 0) { name = args[0]; } else { Scanner scanner = new Scanner(System.in); name = scanner.nextLine(); } try { Class&lt;?&gt; aClass = Class.forName(name); Class&lt;?&gt; superclass = aClass.getSuperclass(); String string = Modifier.toString(aClass.getModifiers()); if(string.length() &gt; 0) System.out.print(string+\" \"); System.out.print(\"class \"+ name); if (superclass != null &amp;&amp; superclass != Object.class) System.out.println(\" extends \"+superclass.getName()); System.out.print(\"\\n{\\n\"); printConstructors(aClass); System.out.println(); printMethod(aClass); System.out.println(); printField(aClass); System.out.println(); System.out.println(\"}\"); } catch (Exception e) { e.printStackTrace(); } } private static void printField(Class&lt;?&gt; aClass) { // getDeclareField获得这个类的所有域，getField获得这个类和他的超类的所有域 Field[] fields = aClass.getDeclaredFields(); for (Field field : fields) { String string = Modifier.toString(field.getModifiers()); System.out.print(string + \" \"); System.out.print(field.getType()); System.out.print(\" \"+field.getName()); System.out.println(); } } private static void printMethod(Class&lt;?&gt; aClass) { Method[] methods = aClass.getDeclaredMethods(); for (Method method : methods) { String string = Modifier.toString(method.getModifiers()); System.out.print(string + \" \"); System.out.print(method.getReturnType()+ \" \"); System.out.print(method.getName()); System.out.print(\"(\"); Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); for (int i = 0; i &lt; parameterTypes.length; i++) { if (i &gt; 0) { System.out.print(\",\"); } System.out.print(parameterTypes[i].getName()); } System.out.println(\");\"); } } public static void printConstructors(Class c) { Constructor[] declaredConstructors = c.getDeclaredConstructors(); for (Constructor declaredConstructor : declaredConstructors) { String name = c.getName(); System.out.println(\" \"); String string = Modifier.toString(c.getModifiers()); if(string.length() &gt; 0) System.out.print(string+\" \"); System.out.print(name + \"(\"); // 打印参数类型 Class[] parameterTypes = declaredConstructor.getParameterTypes(); for (int i = 0; i &lt; parameterTypes.length; i++) { if (i&gt;0) { System.out.print(\" ,\"); } System.out.print(parameterTypes[i].getName()); } System.out.print(\");\"); } }} 在运行时使用反射分析对象上面的代码主要用于这个类还没有运行的时候对于类的分析，下面就是使用反射对一个已经运行的实例的分析与修改。下面的代码对一个Employee实例，进行了修改 getDeclaredFields获取域 使用setAccessible将其设置为true,否则当遇到Modifier为private的属性，将抛出IllegalAccessException 使用Field.get查看某个实例对应域的值 使用field.set(object, value) 关于getComponentType,如果是Array类型,他会返回数组中的内容类型，否则会返回null 你可以通过这种形式加上递归调用实现一个通用的toString方法import java.lang.reflect.Field;public class Main { public static void main(String[] args) { Employee ayang919 = new Employee(\"ayang919\", \"homework\"); Class&lt;? extends Employee&gt; aClass = ayang919.getClass(); try { Field[] fields = aClass.getDeclaredFields(); for (Field field : fields) { field.setAccessible(true); System.out.println(field.get(ayang919)); field.set(ayang919, \"new work\"); } System.out.println(); System.out.println(ayang919.task); System.out.println(ayang919.getName()); } catch (IllegalAccessException e) { e.printStackTrace(); } }}class Employee { private String name; public String task; public Employee(String name, String task) { this.name = name; this.task = task; } public String getName() { return name; }} import java.lang.reflect.AccessibleObject;import java.lang.reflect.Array;import java.lang.reflect.Field;import java.lang.reflect.Modifier;import java.util.ArrayList;import java.util.List;/** * @author rambo.pan * 2016年10月10日 */public class ObjectAnalyzer { private static final String NULL_STRING = \"null\"; private static final String VISITED_STRING = \"...\"; //该数组用来记录已解析过的对象类型 private List&lt;Object&gt; visited = new ArrayList&lt;Object&gt;(); /** * 递归方法，object是个数组，则遍历其元素，递归调用该方法；否则是个类实例，则遍历其所有字段 * @param obj * @return */ public String toString(Object obj){ //如果对象为空，则返回null if (obj == null) { return NULL_STRING; } //如果对象已被处理过，则返回，针对于 A、B对象相互组合的情况，否则会循环递归，导致StackOverFlow if (visited.contains(obj)) { return VISITED_STRING; } visited.add(obj); //获取对象的Class实例，同一个类的对象，共有一个相应的Class实例，在类被加载到虚拟机时就存储在方法区中了 Class&lt;?&gt; cl = obj.getClass(); //如果对象正好是String对象，则强转后直接返回 if (cl == String.class) { return (String)obj; } //如果object是个数组，则遍历其元素，对元素进行toString(Object)递归调用 if (cl.isArray()) { //获取数组的元素类型 String r = cl.getComponentType() + \"[]{\"; for (int i = 0; i &lt; Array.getLength(obj); i++) { if (i &gt; 0) { r += \",\"; } //获取指定下标的数组元素 Object val = Array.get(obj, i); //如果元素是原始/基本类型(Java共8种基本类型),则直接输出 if (cl.getComponentType().isPrimitive()) { r += val; }else {//否则递归调用，直到其为原始类型 r += toString(val); } } //对数组元素遍历完成，返回。 return r + \"}\"; } //object不是数组类型，首先获取其类型Name String r = cl.getName(); //遍历object的所有字段，然后获取字段的Name和Value，之后再遍历其父类，直到遍历到父类为Object do{ r += \"[\"; //获取object的所有字段，无论访问限制符是public还是private，但不包括其从父类继承来的字段 Field[] fields = cl.getDeclaredFields(); //设置字段的访问权限为可访问 AccessibleObject.setAccessible(fields, true); for (Field field : fields) { //忽略static属性 if (Modifier.isStatic(field.getModifiers())) { continue; } if (!r.endsWith(\"[\")) { r += \",\"; } r += field.getName() + \"=\"; try{ //获取字段类型和字段的值 Class&lt;?&gt; t = field.getType(); Object val = field.get(obj); //如果字段类型是原始类型，则直接输出；否则递归调用toString(Object) if (t.isPrimitive()) { r += val; }else { r += toString(val); } }catch (Exception e) { e.printStackTrace(); } } //一个类型的字段遍历结束 r += \"]\"; //获取该类型的父类Class实例，然后继续该循环 cl = cl.getSuperclass(); }while(cl != null); //类型遍历完成，返回object的字符串结果 return r; }}","link":"/浅析Java中的反射机制/"},{"title":"系统复杂度到底是什么","text":"“没有什么是增加一个层解决不了的，如果有，那就再抽一层” 这算是计算机界一句非常经典的话了 今天突然想到了一个比较理论的解释，代码里随着业务的膨胀，接入的业务也来越多，不同系统间的交互也越来越多。 TODO","link":"/系统复杂度到底是什么/"},{"title":"设计模式(1)","text":"什么是设计模式在软件工程中，设计模式是对软件设计中普遍存在的问题，所提出的解决方案。使用设计模式是为了可重用代码，让代码更有可读性，同时具有更好的可靠性。 设计模式原则 开闭原则开闭原则的意思是：对拓展开放，对修改封闭。在程序需要拓展时，不能去修改或影响已有的代码，实现一个热插拔的效果，达到了增强程序的拓展性的效果。想要达到这种效果，我们需要使用接口和抽象类。 里氏代换原则里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。里氏代换原则是继承复用的基石，只有当子类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而且子类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。我个人理解多态事实上就体现了里氏代换原则，因为实现多态需要实现以下三点 存在继承关系 子类方法重写基类方法 基类的数据类型指向子类引用而这个也是里氏代换原则的体现 依赖倒转原则这个原则是开闭原则的基础，核心内容：针对接口编程，高层模块不应该依赖底层模块，二者都应该依赖抽象而不依赖于具体。 接口隔离原则这个原则的意思是：使用多个隔离的接口，比使用单个庞大的接口要好。其目的在于降低耦合度。由此可见，其实设计模式就是从大型软件架构出发，便于升级和维护软件的设计思想。它强调低依赖、低耦合。这个可以理解，就是使用多个简单的接口优于一个实现复杂的接口。接口隔离原则注重的是对接口依赖之间的隔离，主要针对抽象。 单一职责原则类的职责不能太多，要单一，个人认为他和接口隔离原则的区别在于单一职责原则注重的是程序具体上的实现，是职责，是类。而接口隔离原则注重的是接口，是抽象。 最少知道原则最少知道原则也叫迪米特法则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 一个对象应该对其他对象保持最少的了解。类与类之间的关系越密切，耦合度越大，当一个类发生改变时，对另一个类的影响也越大。如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。所以在类的设计上，每一个类都应当尽量降低成员的访问权限。这个现在我还是没有特别理解，我可以想到一个类似的场景来勉强类比，比如说我想使用一个Util类中的方法功能，但是我并不想和Util这个类产生直接联系，于是我把Util类中的这个方法的Modifier写成static。 合成复用原则(组合优于继承)合成复用原则就是在一个新的对象里通过关联关系（组合关系、聚合关系）来使用一些已有的对象，使之成为新对象的一部分；新对象通过委派调用已有对象的方法达到复用功能的目的。简而言之，尽量多使用 组合/聚合 的方式，尽量少使用甚至不使用继承关系。 设计模式分类设计模式大致可以分为三类 创建型模式 工厂模式 抽象工厂模式 单例模式 建造者模式 原型模式 结构型模式 适配器模式 装饰器模式 代理模式 外观模式 桥接模式 组合模式 享元模式 行为型模式 策略模式 模板方法模式 观察者模式 迭代子模式 责任链模式 命令模式 备忘录模式 状态模式 访问者模式 中介者模式 解释器模式 小结由于我也是初学设计模式，有些设计模式我也一直在用，比如说单例模式，建造者模式，工厂模式等。但是写的东西确实也是结合书籍和我个人的理解，若有错误，也欢迎指正交流，个人邮箱yfc1004210191@gmail.com。","link":"/设计模式-1/"},{"title":"设计模式(2)——工厂模式","text":"为什么要有工厂模式工厂模式属于设计模式中创建型模式中的一种。 他的主要目的还是用来创建对象。只是工厂方法不会对调用者暴露创建的逻辑，只要你调用了某个工厂方法方法，我就根据参数返回你需要的对象。工厂模式分为三类， 普通工厂模式 多个工厂模式 静态工厂模式 抽象工厂模式 举例例如我先在有两个类，一个是Man，一个是Women，他们都直接实现了Human这一接口 Human.javapublic interface Human { void eat(); void run();} Man.javapublic class Man implements Human { @Override public void eat() { System.out.println(\"man eat\"); } @Override public void run() { System.out.println(\"man run\"); }} Women.javapublic class Women implements Human{ @Override public void eat() { System.out.println(\"women eat\"); } @Override public void run() { System.out.println(\"women run\"); }} 然后我们需要使用工厂模式创建并返回Women和Man的实例。 FactoryPattern.javapublic class FactoryPattern { public static Human getHuman(String type) { if (type.equals(\"man\")) { return new Man(); } if (type.equals(\"woman\")) { return new Women(); } return null; } public static Man getMan() { return new Man(); } public static Women getWomen() { return new Women(); } // 看到getInstance突然想到newInstance，下面的代码没啥关系 public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException { ArrayList&lt;Object&gt; list1 = new ArrayList&lt;&gt;(); list1.add(1); ArrayList list = ArrayList.class.getDeclaredConstructor(Collection.class).newInstance(list1); list.add(1); System.out.println(list); }} 以上就实现了普通工厂模式和多个工厂模式。但是我们在日常使用中并不想new一个XXXFactory，所以一般工厂方法我们会用static修饰。这就是静态工厂方法。 抽象工厂方法但是静态工厂方法还不够，因为考虑到开闭原则，添加而不修改，静态工厂方法显然是不满足需求的，以上面的代码为例，实现Human接口类的创建都依赖于工厂类，这意味着我们一旦想拓展程序，我们就要对工厂类进行修改，这很不好呀朋友。所以我们打算把工厂基类也做成抽象的接口。 Provider.javapublic interface Provider { Human produce();} 所有的工厂类都要基于Provider接口 ManFactory.javapublic class ManFactory implements Provider{ @Override public Human produce() { return new Man(); }} public class WomenFactory implements Provider{ @Override public Human produce() { return new Women(); }} 这样设计的话，之后我们想要添加新的工厂，只需要重新创一个实现了Factory接口的类就可以了。除了这种减少耦合的功能，抽象工厂方法还适合一种情景，就是某一类工厂返回的内容是由强相关性的。比如说下面的一张图其中工厂类是两个厨房，然后商品有Food和TableWare两个接口，具体的商品假设有Apple，Milk，Knife，Cup，显而易见Apple和Knife是对应的，Milk和Cup是对应的，这个使用两个厨房，KitchenA和KitchenB就可以分别分发这两组商品。抽象工厂模式特别适合于这样的一种产品结构：产品分为几个系列，在每个系列中，产品的布局都是类似的，在一个系列中某个位置的产品，在另一个系列中一定有一个对应的产品。这样的产品结构是存在的，这几个系列中同一位置的产品可能是互斥的，它们是针对不同客户的解决方案，每个客户都只选择其一。这就是抽象工厂的典型使用。","link":"/设计模式-2/"},{"title":"设计模式(4)——装饰器模式","text":"装饰器模式在接触Java之前，我接触过Python，在python中其实就有装饰器这个说法，装饰器模式的意思也差不多，就是动态的将新的职能附加到已有对象上，实现功能拓展。在阿里巴巴Java开发手册中其实有这么一段话他告诉我们聚合和组合是要优先于继承的，若要使用继承，必须符合里氏代换原则。目的就是方便解耦。 举个栗子我们有如下的类结构试想，如果我们不使用装饰者模式，那么这意味着我们像创建一个新的Girl的时候，他们有不同的功能，我们就需要重新创建一个类。这可能会引起类的爆炸。而使用了装饰器模式，我们的代码是这样的。 代码Girl.javapublic abstract class Girl { String description = \"No particular\"; public String getDescription() { return description; }} ChineseGirl.javapublic class ChineseGirl extends Girl { public ChineseGirl() { StringBuilder stringBuilder = new StringBuilder(description); stringBuilder.append(\" Chinese Girl\"); description = stringBuilder.toString(); }} AmericanGirl.javapublic class AmericanGirl extends Girl { public AmericanGirl() { description += \" American Girl\"; }} GirlDecoration.javapublic abstract class GirlDecoration extends Girl { @Override public abstract String getDescription();} GoldenHair.javapublic class GoldenHair extends GirlDecoration { Girl girl; public GoldenHair(Girl g) { girl = g; } @Override public String getDescription() { return girl.getDescription()+\" with golden hair\"; }} Tall.javapublic class Tall extends GirlDecoration { Girl girl; public Tall(Girl girl) { this.girl = girl; } @Override public String getDescription() { return girl.getDescription()+\" is very tall\"; }} Test.javapublic class Test { public static void main(String[] args) { Girl americanGirl = new AmericanGirl(); Girl decoratedGirl = new Tall(new GoldenHair(americanGirl)); System.out.println(decoratedGirl.getDescription()); }} JDK中的应用当你需要动态地给一个对象添加功能，实现功能扩展的时候，就可以使用装饰者模式。 Java IO 类中有一个经典的装饰者模式应用， BufferedReader 装饰了 InputStreamReader. BufferedReader input = new BufferedReader(new InputStreamReader(System.in)); InputStreamReader(InputStream in) - InputSteamReader 读取 bytes 字节内容，然后转换成 characters 流 输出。 BufferedReader(Reader in) - 从 characters 流 中读取内容并缓存。 他们都继承了Reader这个抽象类 装饰者模式和适配器模式的比较关于新职责：适配器也可以在转换时增加新的职责，但其主要目的并不在此；而装饰者模式主要目的，就是给被装饰者增加新职责用的。 关于原接口：适配器模式是用新接口来调用原接口，原接口对新系统来说是不可见或者说不可用的；而装饰者模式原封不动的使用原接口，系统对装饰的对象也通过原接口来完成使用。 关于其包裹的对象：适配器是知道被适配者的详细情况的（就是那个类或那个接口）；而装饰者只知道其接口是什么，至于其具体类型（是基类还是其他派生类）只有在运行期间才知道。","link":"/设计模式-4/"},{"title":"设计模式(3)——适配器模式","text":"什么场景需要使用适配器模式？顾名思义，适配器模式（Adapter Pattern）当然是用来适配的啦。当你想使用一个已有的类，但是这个类的接口跟你的又不一样，不能拿来直接用，这个时候你就需要一个适配器来帮你了。 怎么使用适配器模式？一般来说，比如说拿充电器举例子，你只有一个三角插座，但是三角插座只能实现为三角插头充电的职能。但是这个时候我只有两脚插头的充电器，这个时候我就需要一个转接器来帮我把两脚插头转化为三角插头，所以这里转化为代码结构是这样一个逻辑他的功能其实就是完成二脚插头和三角插头之间的转化。 适配器模式的三个特点 适配器对象实现原有接口 适配器对象组合一个实现新接口的对象（这个对象也可以不实现一个接口，只是一个单纯的对象） 对适配器原有接口方法的调用被委托给新接口的实例的特定方法 代码实现ThreePins.javapublic interface ThreePins { void chargeWithThreePins();} TwoPins.javapublic interface TwoPins { void chargeWithTwoPins();} ChargeBoard.javapublic class ChargeBoard implements ThreePins { ThreePins threePins; ChargeBoard(ThreePins threePins) { this.threePins = threePins; } @Override public void chargeWithThreePins() { System.out.println(\"charge with three pins!\"); charge(); } private void charge() { System.out.println(\"charge success\"); }} TwoToThreeAdapter.javapublic class TwoToThreeAdapter implements ThreePins{ TwoPins twoPins = () -&gt; System.out.println(\"charge with two pins\"); @Override public void chargeWithThreePins() { twoPins.chargeWithTwoPins(); }} AdapterTest.javapublic class AdapterTest { public static void main(String[] args) { TwoToThreeAdapter twoToThreeAdapter = new TwoToThreeAdapter(); ChargeBoard chargeBoard = new ChargeBoard(twoToThreeAdapter); chargeBoard.chargeWithThreePins(); }}","link":"/设计模式-3/"},{"title":"设计模式(5)——观察者模式","text":"观察者模式是什么一句话，观察者模式（Observer Pattern）就是一种 “发布者-订阅者” 的模式。有时也被称为 “模型-视图”模式、“源-监听者”模式等。在这种模式中，由一个目标对象来管理所有依赖与它的观察者对象，并且当这个目标对象自身发生改变时，会主动向它的观察者们发出通知。 类比举例比如你最近在追一个美剧《生活大爆炸》，假设著名在线视频网站某狐买下独家版权，在线更新与播放。于是你天天等啊等啊，等它的更新通知一来，你就去看那些最新的视频。 代码public interface Subject { void registerObserver(Observer observer); void removeObserver(Observer observer); void notifyObserver();} public class VideoSite implements Subject { private ArrayList&lt;Observer&gt; userList; private ArrayList&lt;String&gt; videos; public VideoSite() { userList = new ArrayList&lt;&gt;(); videos = new ArrayList&lt;&gt;(); } @Override public void registerObserver(Observer observer) { userList.add(observer); } @Override public void removeObserver(Observer observer) { userList.remove(observer); } @Override public void notifyObserver() { for (Observer observer : userList) { observer.update(this); } } public void addVideos(String video) { this.videos.add(video); notifyObserver(); } public ArrayList&lt;String&gt; getVideos() { return videos; } public String toString(){ return videos.toString(); }} public interface Observer { void update(Subject subject);} public class VideoFans implements Observer{ private String name; public VideoFans(String name) { this.name = name; } @Override public void update(Subject subject) { System.out.println(this.name + \", new videos are available! \"); // print video list System.out.println(subject); }} public class Test { public static void main(String[] args) { VideoSite vs = new VideoSite(); vs.registerObserver(new VideoFans(\"LiLei\")); vs.registerObserver(new VideoFans(\"HanMeimei\")); vs.registerObserver(new VideoFans(\"XiaoMing\")); // add videos vs.addVideos(\"Video 1\"); }} 这样就完成了在一方更新的时候，观察者可以收到信息。","link":"/设计模式-5/"},{"title":"Java的几种同步工具类(闭锁的实现)","text":"什么是闭锁闭锁是一种同步工具类，可以延迟线程的进度知道其进入终止状态。闭锁的作用就像是一扇门，在闭锁结束状态之前，这扇门就是关闭的，没有任何线程可以通过。当这扇门开启的时候，闭锁将不会改变状态，会一直维持开启的状态。闭锁可以用来确保某些活动直到其他活动都完成后才可以继续执行。 CountDownLatch实现CountDownLatch主要有两个重要的方法。 // 次数减去1#countDown();// 等待直到次数为0#await(); 下面的栗子体现了闭锁的等待作用 public static Long timeTasks(Integer taskNum) throws InterruptedException { final CountDownLatch startGate = new CountDownLatch(1); final CountDownLatch endGate = new CountDownLatch(taskNum); for (int i = 0; i &lt; taskNum; i++) { int finalI = i; new Thread(() -&gt; { try { System.out.println(Thread.currentThread().getName() +\" is ready\"); startGate.await(); try { Thread.sleep(2000); System.out.println(Thread.currentThread().getName() + \" thread is start\"); } finally { endGate.countDown(); } } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } long start = System.currentTimeMillis(); // 在主线程中一起释放 startGate.countDown(); endGate.await(); long end = System.currentTimeMillis(); return end - start;} FutureTaskFutureTask也可以做闭锁。而FutureTask表示的计算是通过Callable来实现的，相当于一种可生成结果的Runnable，并且可以处于一下三种状态 等待运行 正在运行 运行完成 而执行完成表示计算的所有可能结束方式，包括正常结束，由于取消而结束和由于异常而结束等。当FutureTask进入完成状态后，他会永远停止在这个状态。 Future.get的行为取决于任务的状态。如果任务已经完成，那么get将返回计算出的值，反之则将阻塞直到任务进入完成状态，然后返回结果挥着抛出异常。FutureTask将计算结果从执行计算的线程传递到获取这个结果的线程，而FutureTask的规范确保了在这个传递过程中的结果的安全发布。 public class FutureTaskPreloader { private final FutureTask&lt;Object&gt; future = new FutureTask&lt;&gt;(new Callable&lt;Object&gt;() { @Override public Object call() throws Exception { return loadProductList(); } }); private final Thread thread = new Thread(future); public void start() { thread.start(); } public Object get() throws ExecutionException, InterruptedException { try { return future.get(); } catch (ExecutionException e) { Throwable cause = e.getCause(); if (cause instanceof DataLoaderException) { throw (DataLoaderException) cause; } else { throw laundeThrowable(cause); } } } private RuntimeException laundeThrowable(Throwable cause) { if (cause instanceof RuntimeException) { return (RuntimeException) cause; } else if (cause instanceof Error) { throw (Error) cause; } else { throw new IllegalStateException(\"Not unchecked\", cause); } }} 信号量(Counting Semaphore)技术信号量用来控制同时访问某个特定资源的操作数；或者执行某个指定操作的数量；技术信号量还可以用来实现某种资源池，或者对容器施加边界。Semaphore中管理这一组虚拟的许可，许可的初始数量可通过构造函数来指定。在执行操作的时候可以首先获取许可，只要还有剩余的许可，并在使用以后释放许可，如果没有许可，那么acquire将阻塞到有许可为止。release方法将返回一个许可给信号量。下面的代码出自一道题目，Leetcode 1115 : 交替打印FooBar class FooBar { private int n; private final Semaphore semFoo = new Semaphore(1); private final Semaphore semBar = new Semaphore(0); private volatile boolean flag = true; public FooBar(int n) { this.n = n; } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i &lt; n; i++) { semFoo.acquire(); // printFoo.run() outputs \"foo\". Do not change or remove this line. printFoo.run(); semBar.release(); } } public void bar(Runnable printBar) throws InterruptedException { for (int i = 0; i &lt; n; i++) { semBar.acquire(); // printBar.run() outputs \"bar\". Do not change or remove this line. printBar.run(); semFoo.release(); } }}","link":"/闭锁的几种实现/"},{"title":"通过js解析获取B站弹幕发送者","text":"代码地址B站弹幕下载,查找发送者工具需要python环境才能使用。 Why？ 感觉暑假刷B站刷的比较多，有时候看到一些嘴臭的弹幕就想把那些人从屏幕后面揪出来嘴臭回去，然后就想这可不可以通过弹幕找到发送者。 手机流量限速到1M，刷B站的时候卡的要死，心里想着把弹幕关了会不会加载的快一点(一开始没仔细想，以为B站的的弹幕是轮询的，然后认为既然是每隔一段时间请求一次，关闭弹幕应该会终止轮询行为)，但是后来抓包的时候发现，显然不会加载的快一点啊QAQ！！！ How？抓包一开始懒得去查B站的弹幕应该怎么获取，然后自己寻思着弹幕估计也是从一个接口里获取的，然后就开始自己抓包。显然请求弹幕接口是在XHR(XMLHttpRequest)中, 然后其实很容易就能找到这个Api upd（2020/11/11）：更新接口为 https://comment.bilibili.com/252509655.xml ，其中数字部分为视频加密后的id号，可以通过抓包得到 就是这个请求，然后其中的接口中就包含了弹幕的所有信息，是一个XML文件为了确认这里的弹幕是否齐全，我对照了d标签的数量和B站视频实时显示的弹幕数是否相同最后确认没有数据遗漏。 查找用户确认数据没有被投毒或者缺失以后，就是开始根据弹幕查找用户了，我很确认得到的数据中肯定是有用户信息的，并且就是接口的XML的d标签的p属性中的某一个。因为我们知道B站是有屏蔽某个用户弹幕的功能的，那么肯定需要一个唯一标识符，那么肯定是用户ID。然后我就开始手动屏蔽弹幕(对着某条弹幕右键就可以了)。然后惊喜的发现这么容易就找到了，也就是说d标签的p属性的第七个属性应该就是ID之类的东西。然后我兴高采烈的复制的这串ID，结果。。。搜不到嗷！那么显然这个就是加密后的ID了。然后我就开始试了试比较常用的hash加密方法，没有试出来，然后去Google一下，是一种我没有用过的hash算法，叫ITU I.363.5 算法，然后还找到了个Api， (http://biliquery.typcn.com/api/user/hash/[用户Hash] 最后就美滋滋的找到了Hash前的的用户ID。 在B站的搜索栏中搜索 UID:用户ID 即可搜索到该用户 兼容性为了兼容每一个视频，并且考虑到一些用户不知道怎么抓包，我又分析了一下怎么根据每个视频的av号找到弹幕接口，首先分析每个视频的弹幕接口 https://api.bilibili.com/x/v1/dm/list.so?oid=62627218 我发现每条请求的都有一个param叫做oid，那我想这个应该就是每个视频唯一表示符，但是这个视频的av号又不相同。所以我就开始再网页没有渲染过的源代码里找oid，先把这个一个确定的oid在源代码里查找发现这个叫做cid，emmmm…，这个是什么鬼，对比多个视频源代码，发现第一个cid对应的数字就是我们需要的oid，所以这里选择使用正则暴力筛选出来oid。这样我们就完成了一次查询流程假设 用户输入av号 &gt; 根据av号找到视频网址 &gt; 使用正则解析出oid &gt; 携带oid去请求弹幕接口 &gt; 解析弹幕接口返回的出来的弹幕中hashed的用户ID &gt; 携带hashed的用户ID去请求rehash接口得到弹幕发送者的真实ID &gt; 将弹幕内容及弹幕发送者写入文件 这样子就大功告成了！","link":"/通过js解析获取b站弹幕发送者/"}],"tags":[{"name":"DevOps","slug":"DevOps","link":"/tags/DevOps/"},{"name":"js","slug":"js","link":"/tags/js/"},{"name":"并发编程","slug":"并发编程","link":"/tags/并发编程/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"灵感","slug":"灵感","link":"/tags/灵感/"},{"name":"android","slug":"android","link":"/tags/android/"},{"name":"jetpack","slug":"jetpack","link":"/tags/jetpack/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"big-data","slug":"big-data","link":"/tags/big-data/"},{"name":"工具","slug":"工具","link":"/tags/工具/"},{"name":"IDEA","slug":"IDEA","link":"/tags/IDEA/"},{"name":"性能挑战赛","slug":"性能挑战赛","link":"/tags/性能挑战赛/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"微服务","slug":"微服务","link":"/tags/微服务/"},{"name":"分布式理论","slug":"分布式理论","link":"/tags/分布式理论/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"I/O","slug":"I-O","link":"/tags/I-O/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"JavaWeb","slug":"JavaWeb","link":"/tags/JavaWeb/"},{"name":"源码","slug":"源码","link":"/tags/源码/"},{"name":"老代码","slug":"老代码","link":"/tags/老代码/"},{"name":"express","slug":"express","link":"/tags/express/"},{"name":"前后端分离","slug":"前后端分离","link":"/tags/前后端分离/"},{"name":"自我提升","slug":"自我提升","link":"/tags/自我提升/"},{"name":"Vue","slug":"Vue","link":"/tags/Vue/"},{"name":"部门教程","slug":"部门教程","link":"/tags/部门教程/"},{"name":"阶段总结","slug":"阶段总结","link":"/tags/阶段总结/"},{"name":"Kotlin","slug":"Kotlin","link":"/tags/Kotlin/"},{"name":"Kugga","slug":"Kugga","link":"/tags/Kugga/"},{"name":"随笔","slug":"随笔","link":"/tags/随笔/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"转载","slug":"转载","link":"/tags/转载/"},{"name":"日常技能","slug":"日常技能","link":"/tags/日常技能/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"反射","slug":"反射","link":"/tags/反射/"},{"name":"自嗨","slug":"自嗨","link":"/tags/自嗨/"}],"categories":[]}